@incollection{aignerTouchingSimplices2018,
  title = {Touching Simplices},
  booktitle = {Proofs from {{THE BOOK}}},
  year = {2018},
  pages = {107--110},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-662-57265-8_16},
  url = {https://doi.org/10.1007/978-3-662-57265-8_16},
  urldate = {2025-02-14},
  abstract = {This is an old and very natural question. We shall call f(d) the answer to this problem, and record f(1) = 2, which is trivial. For d = 2 the configuration of four triangles in the margin shows f(2) ≥ 4. There is no similar configuration with five triangles, because from this the dual graph construction, which for our example with four triangles yields a planar drawing of K4, would give a planar embedding of K5, which is impossible (see page 91).},
  isbn = {978-3-662-57265-8},
  langid = {english},
  file = {/Users/lhydave/Zotero/storage/3L7JM5G2/Aigner和Ziegler - 2018 - Touching simplices.pdf},
  author = {Aigner, Martin and Ziegler, Günter M.},
  editor = {Aigner, Martin and Ziegler, Günter M.}
}

@article{anscombeDefinitionSubjectiveProbability1963,
  title = {A Definition of Subjective Probability},
  year = {1963},
  journal = {Annals of mathematical statistics},
  volume = {34},
  number = {1},
  pages = {199--205},
  url = {https://pages.stern.nyu.edu/~dbackus/Exotic/1Ambiguity/AnscombeAumann%20AMS%2063.pdf},
  urldate = {2025-02-15},
  file = {/Users/lhydave/Zotero/storage/Y3F9QE7S/Anscombe和Aumann - 1963 - A definition of subjective probability.pdf},
  author = {Anscombe, Francis J. and Aumann, Robert J.}
}

@article{aumannAgreeingDisagree1976,
  title = {Agreeing to {{Disagree}}},
  year = {1976},
  month = nov,
  journal = {The Annals of Statistics},
  volume = {4},
  number = {6},
  pages = {1236--1239},
  publisher = {Institute of Mathematical Statistics},
  issn = {0090-5364, 2168-8966},
  doi = {10.1214/aos/1176343654},
  url = {https://projecteuclid.org/journals/annals-of-statistics/volume-4/issue-6/Agreeing-to-Disagree/10.1214/aos/1176343654.full},
  urldate = {2025-02-15},
  abstract = {Two people, 1 and 2, are said to have common knowledge of an event \$E\$ if both know it, 1 knows that 2 knows it, 2 knows that 1 knows is, 1 knows that 2 knows that 1 knows it, and so on. THEOREM. If two people have the same priors, and their posteriors for an event \$A\$ are common knowledge, then these posteriors are equal.},
  keywords = {62A15,62C05,90A05,90D35,concensus,Game theory,Harsanyi doctrine,Information,Posterior,revising probabilities,statistics,subjective probability},
  file = {/Users/lhydave/Zotero/storage/H6C9TLZN/Aumann - 1976 - Agreeing to Disagree.pdf},
  author = {Aumann, Robert J.}
}

@article{aumannCorrelatedEquilibriumExpression1987,
  title = {Correlated Equilibrium as an Expression of {{Bayesian}} Rationality},
  year = {1987},
  journal = {Econometrica: Journal of the Econometric Society},
  eprint = {1911154},
  eprinttype = {jstor},
  pages = {1--18},
  publisher = {JSTOR},
  url = {https://www.jstor.org/stable/1911154},
  urldate = {2025-02-15},
  file = {/Users/lhydave/Zotero/storage/X8QB3A2S/Aumann - 1987 - Correlated equilibrium as an expression of Bayesian rationality.pdf},
  author = {Aumann, Robert J.}
}

@article{aumannEpistemicConditionsNash1995,
  title = {Epistemic {{Conditions}} for {{Nash Equilibrium}}},
  year = {1995},
  journal = {Econometrica},
  volume = {63},
  number = {5},
  eprint = {2171725},
  eprinttype = {jstor},
  pages = {1161--1180},
  publisher = {[Wiley, Econometric Society]},
  issn = {0012-9682},
  doi = {10.2307/2171725},
  url = {https://www.jstor.org/stable/2171725},
  urldate = {2024-05-15},
  abstract = {Sufficient conditions for Nash equilibrium in an n-person game are given in terms of what the players know and believe--about the game, and about each other's rationality, actions, knowledge, and beliefs. Mixed strategies are treated not as conscious randomizations, but as conjectures, on the part of other players, as to what a player will do. Common knowledge plays a smaller role in characterizing Nash equilibrium than had been supposed. When n = 2, mutual knowledge of the payoff functions, of rationality, and of the conjectures implies that the conjectures form a Nash equilibrium. When n ≥ 3 and there is a common prior, mutual knowledge of the payoff functions and of rationality, and common knowledge of the conjectures, imply that the conjectures form a Nash equilibrium. Examples show the results to be tight.},
  file = {/Users/lhydave/Zotero/storage/WBHSHYKU/Aumann and Brandenburger - 1995 - Epistemic Conditions for Nash Equilibrium.pdf;/Users/lhydave/Zotero/storage/YHKYUJ44/Aumann和Brandenburger - 1995 - Epistemic conditions for Nash equilibrium.pdf},
  author = {Aumann, Robert and Brandenburger, Adam}
}

@book{aumannLecturesGameTheory1989,
  title = {Lectures on Game Theory},
  year = {1989},
  publisher = {Westview Press},
  address = {Boulder},
  isbn = {978-0-8133-7578-6},
  langid = {english},
  keywords = {Economics Mathematical.,Game theory.},
  annotation = {Open Library ID: OL2035021M},
  author = {Aumann, Robert J.}
}

@article{aumannRationalityBoundedRationality1997,
  title = {Rationality and Bounded Rationality},
  year = {1997},
  journal = {Games and Economic behavior},
  volume = {21},
  number = {1-2},
  pages = {2--14},
  publisher = {Elsevier},
  url = {https://www.sciencedirect.com/science/article/pii/S0899825697905856},
  urldate = {2025-02-15},
  file = {/Users/lhydave/Zotero/storage/LUQCGFTT/Aumann - 1997 - Rationality and bounded rationality.pdf},
  author = {Aumann, Robert J.}
}

@article{aumannWhatGameTheory1985,
  title = {What Is Game Theory Trying to Accomplish?},
  year = {1985},
  month = jan,
  journal = {Frontiers of economics},
  url = {https://www.academia.edu/78583058/What_is_game_theory_trying_to_accomplish},
  urldate = {2024-04-16},
  abstract = {What is game theory trying to accomplish?},
  author = {Aumann, Robert J.}
}

@article{bacharachExtensionsClaimAumann1985,
  title = {Some Extensions of a Claim of {{Aumann}} in an Axiomatic Model of Knowledge},
  year = {1985},
  month = oct,
  journal = {Journal of Economic Theory},
  volume = {37},
  number = {1},
  pages = {167--190},
  issn = {0022-0531},
  doi = {10.1016/0022-0531(85)90035-3},
  url = {https://www.sciencedirect.com/science/article/pii/0022053185900353},
  urldate = {2025-02-15},
  abstract = {The paper begins by presenting an axiomatic model of simple and iterated knowledge. A formal definition of the intuitive notion of common knowledge is given and shown equivalent to previous characterizations. It is shown that agents have information partitions. The second part generalizes Aumann's (Ann. Statist. 4 (1976), 1236–1239) well-known propositions about common knowledge between two rational agents of each other's probability assignments. It is shown that: common knowledge of decisions—if these are rational—implies a common decision for like-minded agents; and that a “dialogue” in decisions leads to a common decision. A “no-trade” theorem is given which includes trade under complete uncertainty.},
  file = {/Users/lhydave/Zotero/storage/7CHRBKXC/0022053185900353.html},
  author = {Bacharach, Michael}
}

@article{banachOperationsDansEnsembles1922,
  title = {{Sur les opérations dans les ensembles abstraits et leur application aux équations intégrales}},
  year = {1922},
  journal = {Fundamenta Mathematicae},
  volume = {3},
  pages = {133--181},
  publisher = {Instytut Matematyczny Polskiej Akademii Nauk},
  issn = {0016-2736, 1730-6329},
  doi = {10.4064/fm-3-1-133-181},
  url = {https://www.impan.pl/pl/wydawnictwa/czasopisma-i-serie-wydawnicze/fundamenta-mathematicae/all/3/0/92453/sur-les-operations-dans-les-ensembles-abstraits-et-leur-application-aux-equations-integrales},
  urldate = {2025-02-15},
  abstract = {Le but de cette note est d'établir quelques théorèmes valables pour différents champs fonctionnels.},
  langid = {polish},
  file = {/Users/lhydave/Zotero/storage/89XPUNND/Banach - 1922 - Sur les opérations dans les ensembles abstraits et leur application aux équations intégrales.pdf},
  author = {Banach, Stefan}
}

@article{bar-hillelBaserateFallacyProbability1980,
  title = {The Base-Rate Fallacy in Probability Judgments},
  year = {1980},
  month = may,
  journal = {Acta Psychologica},
  volume = {44},
  number = {3},
  pages = {211--233},
  issn = {0001-6918},
  doi = {10.1016/0001-6918(80)90046-3},
  url = {https://www.sciencedirect.com/science/article/pii/0001691880900463},
  urldate = {2025-02-13},
  abstract = {The base-rate fallacy is people's tendency to ignore base rates in favor of, e.g., individuating information (when such is available), rather than integrate the two. This tendency has important implications for understanding judgment phenomena in many clinical, legal, and social-psychological settings. An explanation of this phenomenon is offered, according to which people order information by its perceived degree of relevance, and let high-relevance information dominate low-relevance information. Information is deemed more relevant when it relates more specifically to a judged target case. Specificity is achieved either by providing information on a smaller set than the overall population, of which the target case is a member, or when information can be coded, via causality, as information about the specific members of a given population. The base-rate fallacy is thus the result of pitting what seem to be merely coincidental, therefore low-relevance, base rates against more specific, or causal, information. A series of probabilistic inference problems is presented in which relevance was manipulated with the means described above, and the empirical results confirm the above account. In particular, base rates will be combined with other information when the two kinds of information are perceived as being equally relevant to the judged case.},
  file = {/Users/lhydave/Zotero/storage/2ZHYKUEN/0001691880900463.html},
  author = {{Bar-Hillel}, Maya}
}

@article{baumStatisticalInferenceProbabilistic1966,
  title = {Statistical {{Inference}} for {{Probabilistic Functions}} of {{Finite State Markov Chains}}},
  year = {1966},
  month = dec,
  journal = {The Annals of Mathematical Statistics},
  volume = {37},
  number = {6},
  pages = {1554--1563},
  publisher = {Institute of Mathematical Statistics},
  issn = {0003-4851, 2168-8990},
  doi = {10.1214/aoms/1177699147},
  url = {https://projecteuclid.org/journals/annals-of-mathematical-statistics/volume-37/issue-6/Statistical-Inference-for-Probabilistic-Functions-of-Finite-State-Markov-Chains/10.1214/aoms/1177699147.full},
  urldate = {2025-02-13},
  abstract = {The Annals of Mathematical Statistics},
  file = {/Users/lhydave/Zotero/storage/AWSZ6JWG/Baum和Petrie - 1966 - Statistical Inference for Probabilistic Functions of Finite State Markov Chains.pdf},
  author = {Baum, Leonard E. and Petrie, Ted}
}

@book{bauschkeConvexAnalysisMonotone2017,
  title = {Convex {{Analysis}} and {{Monotone Operator Theory}} in {{Hilbert Spaces}}},
  year = {2017},
  series = {{{CMS Books}} in {{Mathematics}}},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-48311-5},
  url = {https://link.springer.com/10.1007/978-3-319-48311-5},
  urldate = {2025-02-14},
  copyright = {https://www.springernature.com/gp/researchers/text-and-data-mining},
  isbn = {978-3-319-48310-8 978-3-319-48311-5},
  langid = {english},
  keywords = {Convex analysis,convex optimization,fixed point algorithm,monotone operator,nonexpansive operator,operator splitting algorithm,proximal algorithm},
  file = {/Users/lhydave/Zotero/storage/5HGY79FM/Bauschke和Combettes - 2017 - Convex Analysis and Monotone Operator Theory in Hilbert Spaces.pdf},
  author = {Bauschke, Heinz H. and Combettes, Patrick L.}
}

@article{bellmanTheoryDynamicProgramming1952,
  title = {On the {{Theory}} of {{Dynamic Programming}}},
  year = {1952},
  month = aug,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {38},
  number = {8},
  pages = {716--719},
  publisher = {Proceedings of the National Academy of Sciences},
  doi = {10.1073/pnas.38.8.716},
  url = {https://www.pnas.org/doi/abs/10.1073/pnas.38.8.716},
  urldate = {2025-02-13},
  file = {/Users/lhydave/Zotero/storage/XCDSWJHP/Bellman - 1952 - On the Theory of Dynamic Programming.pdf},
  author = {Bellman, Richard}
}

@article{bickelSexBiasGraduate1975,
  title = {Sex {{Bias}} in {{Graduate Admissions}}: {{Data}} from {{Berkeley}}},
  shorttitle = {Sex {{Bias}} in {{Graduate Admissions}}},
  year = {1975},
  month = feb,
  journal = {Science},
  volume = {187},
  number = {4175},
  pages = {398--404},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/science.187.4175.398},
  url = {https://www.science.org/doi/10.1126/science.187.4175.398},
  urldate = {2025-02-13},
  abstract = {Examination of aggregate data on graduate admissions to the University of California, Berkeley, for fall 1973 shows a clear but misleading pattern of bias against female applicants. Examination of the disaggregated data reveals few decision-making units that show statistically significant departures from expected frequencies of female admissions, and about as many units appear to favor women as to favor men. If the data are properly pooled, taking into account the autonomy of departmental decision making, thus correcting for the tendency of women to apply to graduate departments that are more difficult for applicants of either sex to enter, there is a small but statistically significant bias in favor of women. The graduate departments that are easier to enter tend to be those that require more mathematics in the undergraduate preparatory curriculum. The bias in the aggregated data stems not from any pattern of discrimination on the part of admissions committees, which seem quite fair on the whole, but apparently from prior screening at earlier levels of the educational system. Women are shunted by their socialization and education toward fields of graduate study that are generally more crowded, less productive of completed degrees, and less well funded, and that frequently offer poorer professional employment prospects.},
  author = {Bickel, P. J. and Hammel, E. A. and O'Connell, J. W.}
}

@article{bishopMaximumLikelihoodAlignment1986,
  title = {Maximum Likelihood Alignment of {{DNA}} Sequences},
  year = {1986},
  month = jul,
  journal = {Journal of Molecular Biology},
  volume = {190},
  number = {2},
  pages = {159--165},
  issn = {0022-2836},
  doi = {10.1016/0022-2836(86)90289-5},
  url = {https://www.sciencedirect.com/science/article/pii/0022283686902895},
  urldate = {2025-02-13},
  abstract = {The optimal alignment problem for pairs of molecular sequences under a probabilistic model of evolutionary change is equivalent to the problem of estimating the maximum likelihood time required to transform one sequence to the other. When this time has been estimated, various alignments of high posterior probability may be written down. A simple model with two parameters is presented and a method is described by which the likelihood may be computed. Maximum likelihood estimates for some pairs of tRNA genes illustrate the method and allow us to obtain the best alignments under the model.},
  file = {/Users/lhydave/Zotero/storage/2NN4LHXK/0022283686902895.html},
  author = {Bishop, M. J. and Thompson, E. A.}
}

@book{boydConvexOptimization2004,
  title = {Convex {{Optimization}}},
  year = {2004},
  edition = {第 1st 版},
  publisher = {Cambridge University Press},
  address = {Cambridge New York Melbourne New Delhi Singapore},
  abstract = {Convex optimization problems arise frequently in many different fields. A comprehensive introduction to the subject, this book shows in detail how such problems can be solved numerically with great efficiency. The focus is on recognizing convex optimization problems and then finding the most appropriate technique for solving them. The text contains many worked examples and homework exercises and will appeal to students, researchers and practitioners in fields such as engineering, computer science, mathematics, statistics, finance, and economics.},
  isbn = {978-0-521-83378-3},
  author = {Boyd, Stephen and Vandenberghe, Lieven}
}

@article{breimanIndividualErgodicTheorem1957,
  title = {The {{Individual Ergodic Theorem}} of {{Information Theory}}},
  year = {1957},
  journal = {The Annals of Mathematical Statistics},
  volume = {28},
  number = {3},
  eprint = {2237247},
  eprinttype = {jstor},
  pages = {809--811},
  publisher = {Institute of Mathematical Statistics},
  issn = {0003-4851},
  url = {https://www.jstor.org/stable/2237247},
  urldate = {2023-07-10},
  author = {Breiman, Leo}
}

@article{brouwerUeberAbbildungMannigfaltigkeiten1911,
  title = {{Über Abbildung von Mannigfaltigkeiten}},
  year = {1911},
  month = mar,
  journal = {Mathematische Annalen},
  volume = {71},
  number = {1},
  pages = {97--115},
  issn = {1432-1807},
  doi = {10.1007/BF01456931},
  url = {https://doi.org/10.1007/BF01456931},
  urldate = {2025-02-15},
  langid = {ngerman},
  file = {/Users/lhydave/Zotero/storage/JMEIGD46/Brouwer - 1911 - Über Abbildung von Mannigfaltigkeiten.pdf},
  author = {Brouwer, L. E. J.}
}

@article{brownAdmissibleEstimatorsRecurrent1971,
  title = {Admissible {{Estimators}}, {{Recurrent Diffusions}}, and {{Insoluble Boundary Value Problems}}},
  year = {1971},
  month = jun,
  journal = {The Annals of Mathematical Statistics},
  volume = {42},
  number = {3},
  pages = {855--903},
  publisher = {Institute of Mathematical Statistics},
  issn = {0003-4851, 2168-8990},
  doi = {10.1214/aoms/1177693318},
  url = {https://projecteuclid.org/journals/annals-of-mathematical-statistics/volume-42/issue-3/Admissible-Estimators-Recurrent-Diffusions-and-Insoluble-Boundary-Value-Problems/10.1214/aoms/1177693318.full},
  urldate = {2025-02-14},
  abstract = {The Annals of Mathematical Statistics},
  file = {/Users/lhydave/Zotero/storage/7JCC6CHV/Brown - 1971 - Admissible Estimators, Recurrent Diffusions, and Insoluble Boundary Value Problems.pdf},
  author = {Brown, L. D.}
}

@article{brownGeometricalExplanationStein2012,
  title = {A {{Geometrical Explanation}} of {{Stein Shrinkage}}},
  year = {2012},
  journal = {Statistical Science},
  volume = {27},
  number = {1},
  eprint = {23208821},
  eprinttype = {jstor},
  pages = {24--30},
  publisher = {Institute of Mathematical Statistics},
  issn = {0883-4237},
  url = {https://www.jstor.org/stable/23208821},
  urldate = {2025-02-14},
  abstract = {Shrinkage estimation has become a basic tool in the analysis of high-dimensional data. Historically and conceptually a key development toward this was the discovery of the inadmissibility of the usual estimator of a multivariate normal mean. This article develops a geometrical explanation for this inadmissibility. By exploiting the spherical symmetry of the problem it is possible to effectively conceptualize the multidimensional setting in a two-dimensional framework that can be easily plotted and geometrically analyzed. We begin with the heuristic explanation for inadmissibility that was given by Stein [In Proceedings of the Third Berkeley Symposium on Mathematical Statistics and Probability, 1954—1955, Vol. I (1956) 197—206, Univ. California Press]. Some geometric figures are included to make this reasoning more tangible. It is also explained why Stein's argument falls short of yielding a proof of inadmissibility, even when the dimension, p, is much larger than p = 3. We then extend the geometric idea to yield increasingly persuasive arguments for inadmissibility when p ≤ 3, albeit at the cost of increased geometric and computational detail.},
  file = {/Users/lhydave/Zotero/storage/R7KI5L3X/Brown和Zhao - 2012 - A Geometrical Explanation of Stein Shrinkage.pdf},
  author = {Brown, Lawrence D. and Zhao, Linda H.}
}

@misc{ChatGPTOpenAI,
  title = {{{ChatGPT}} | {{OpenAI}}},
  url = {https://openai.com/chatgpt/overview/},
  urldate = {2025-02-13},
  note = {(accessed 2025-02-13)},
  howpublished = {\url{https://openai.com/chatgpt/overview/}}
}

@article{chebyshevQuestionsSmallestQuantities1947,
  title = {Questions on Smallest Quantities Connected with the Approximate Representation of Functions (1859)},
  year = {1947},
  journal = {Collected works},
  volume = {2},
  pages = {151--235},
  author = {Chebyshev, P. L.}
}

@article{cisekCorticalMechanismsAction2007,
  title = {Cortical Mechanisms of Action Selection: The Affordance Competition Hypothesis},
  shorttitle = {Cortical Mechanisms of Action Selection},
  year = {2007},
  month = sep,
  journal = {Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences},
  volume = {362},
  number = {1485},
  pages = {1585--1599},
  issn = {0962-8436},
  doi = {10.1098/rstb.2007.2054},
  abstract = {At every moment, the natural world presents animals with two fundamental pragmatic problems: selection between actions that are currently possible and specification of the parameters or metrics of those actions. It is commonly suggested that the brain addresses these by first constructing representations of the world on which to build knowledge and make a decision, and then by computing and executing an action plan. However, neurophysiological data argue against this serial viewpoint. In contrast, it is proposed here that the brain processes sensory information to specify, in parallel, several potential actions that are currently available. These potential actions compete against each other for further processing, while information is collected to bias this competition until a single response is selected. The hypothesis suggests that the dorsal visual system specifies actions which compete against each other within the fronto-parietal cortex, while a variety of biasing influences are provided by prefrontal regions and the basal ganglia. A computational model is described, which illustrates how this competition may take place in the cerebral cortex. Simulations of the model capture qualitative features of neurophysiological data and reproduce various behavioural phenomena.},
  langid = {english},
  pmcid = {PMC2440773},
  pmid = {17428779},
  keywords = {Animals,Cerebral Cortex,Computer Simulation,Decision Making,Models Neurological,Visual Perception},
  file = {/Users/lhydave/Zotero/storage/IN92C9GE/Cisek - 2007 - Cortical mechanisms of action selection the affordance competition hypothesis.pdf},
  author = {Cisek, Paul}
}

@article{cortesSupportvectorNetworks1995,
  title = {Support-Vector Networks},
  year = {1995},
  month = sep,
  journal = {Machine Learning},
  volume = {20},
  number = {3},
  pages = {273--297},
  issn = {1573-0565},
  doi = {10.1007/BF00994018},
  url = {https://doi.org/10.1007/BF00994018},
  urldate = {2025-02-14},
  abstract = {Thesupport-vector network is a new learning machine for two-group classification problems. The machine conceptually implements the following idea: input vectors are non-linearly mapped to a very high-dimension feature space. In this feature space a linear decision surface is constructed. Special properties of the decision surface ensures high generalization ability of the learning machine. The idea behind the support-vector network was previously implemented for the restricted case where the training data can be separated without errors. We here extend this result to non-separable training data.},
  langid = {english},
  keywords = {Artificial Intelligence,efficient learning algorithms,neural networks,pattern recognition,polynomial classifiers,radial basis function classifiers},
  file = {/Users/lhydave/Zotero/storage/23NFJEJN/Cortes和Vapnik - 1995 - Support-vector networks.pdf},
  author = {Cortes, Corinna and Vapnik, Vladimir}
}

@book{coverElementsInformationTheory2012,
  title = {Elements of {{Information Theory}}},
  year = {2012},
  publisher = {John Wiley \& Sons},
  author = {Cover, Thomas M. and Thomas, Joy A.}
}

@article{coxProbabilityFrequencyReasonable1946,
  title = {Probability, {{Frequency}} and {{Reasonable Expectation}}},
  year = {1946},
  month = jan,
  journal = {American Journal of Physics},
  volume = {14},
  number = {1},
  pages = {1--13},
  issn = {0002-9505},
  doi = {10.1119/1.1990764},
  url = {https://doi.org/10.1119/1.1990764},
  urldate = {2025-02-13},
  file = {/Users/lhydave/Zotero/storage/HXPEU3L4/Probability-Frequency-and-Reasonable-Expectation.html},
  author = {Cox, R. T.}
}

@inproceedings{cuffDifferentialPrivacyMutual2016,
  title = {Differential {{Privacy}} as a {{Mutual Information Constraint}}},
  booktitle = {Proceedings of the 2016 {{ACM SIGSAC Conference}} on {{Computer}} and {{Communications Security}}},
  year = {2016},
  month = oct,
  pages = {43--54},
  publisher = {ACM},
  address = {Vienna Austria},
  doi = {10.1145/2976749.2978308},
  url = {https://dl.acm.org/doi/10.1145/2976749.2978308},
  urldate = {2025-02-14},
  isbn = {978-1-4503-4139-4},
  langid = {english},
  file = {/Users/lhydave/Zotero/storage/LFDB9HBK/Cuff和Yu - 2016 - Differential Privacy as a Mutual Information Constraint.pdf},
  author = {Cuff, Paul and Yu, Lanqing}
}

@article{debreuNonnegativeSquareMatrices1953,
  title = {Nonnegative {{Square Matrices}}},
  year = {1953},
  journal = {Econometrica},
  volume = {21},
  number = {4},
  eprint = {1907925},
  eprinttype = {jstor},
  pages = {597--607},
  publisher = {[Wiley, Econometric Society]},
  issn = {0012-9682},
  doi = {10.2307/1907925},
  url = {https://www.jstor.org/stable/1907925},
  urldate = {2025-02-14},
  file = {/Users/lhydave/Zotero/storage/D39CWSDM/Debreu和Herstein - 1953 - Nonnegative Square Matrices.pdf},
  author = {Debreu, Gerard and Herstein, I. N.}
}

@article{debreuSocialEquilibriumExistence1952,
  title = {A {{Social Equilibrium Existence Theorem}}*},
  year = {1952},
  month = oct,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {38},
  number = {10},
  pages = {886--893},
  publisher = {Proceedings of the National Academy of Sciences},
  doi = {10.1073/pnas.38.10.886},
  url = {https://www.pnas.org/doi/10.1073/pnas.38.10.886},
  urldate = {2025-02-15},
  file = {/Users/lhydave/Zotero/storage/IXIJKKVV/Debreu - 1952 - A Social Equilibrium Existence Theorem.pdf},
  author = {Debreu, Gerard}
}

@book{definettiTheoryProbabilityCritical2017,
  title = {Theory of {{Probability}}: {{A Critical Introductory Treatment}}},
  shorttitle = {Theory of {{Probability}}},
  year = {2017},
  month = feb,
  series = {Wiley {{Series}} in {{Probability}} and {{Statistics}}},
  edition = {1},
  publisher = {Wiley},
  doi = {10.1002/9781119286387},
  url = {https://onlinelibrary.wiley.com/doi/book/10.1002/9781119286387},
  urldate = {2025-02-13},
  abstract = {Part 7 A preliminary survey: heads and tails - preliminary considerations heads and tails - the random process laws of "large numbers" the "central limit theorem". Part 8 Random processes with independent increments: the case of asymptotic normality the Wiener-Levy process behaviour and asymptotic behaviour ruin problems ballot problems. Part 9 An introduction to other types of stochastic process: Markov processes stationary processes. Part 10 Problems in higher dimensions: second-order characteristics and the normal distribution the discrete case the continuous case the case of spherical symmetry. Part 11 Inductive reasoning, statistical inference: the basic formulation and preliminary clarifications the case of independence and the case of dependence exchangeability. Part 12 Mathematical statistics: the scope and limits of the treatment the likelihood principle and sufficient statistics a Bayesian approach to "estimation" and "hypothesis testing" the connections with decision theory.},
  copyright = {http://doi.wiley.com/10.1002/tdm\_license\_1.1},
  isbn = {978-1-119-28637-0 978-1-119-28638-7},
  langid = {english},
  author = {{de Finetti}, Bruno},
  editor = {Machí, Antonio and Smith, Adrian}
}

@article{dekelStandardStateSpaceModels1998,
  title = {Standard {{State-Space Models Preclude Unawareness}}},
  year = {1998},
  month = jan,
  journal = {Econometrica},
  volume = {66},
  number = {1},
  eprint = {2998545},
  eprinttype = {jstor},
  pages = {159},
  issn = {00129682},
  doi = {10.2307/2998545},
  url = {https://www.jstor.org/stable/2998545?origin=crossref},
  urldate = {2025-02-15},
  langid = {english},
  file = {/Users/lhydave/Zotero/storage/29V2DP26/Dekel 等 - 1998 - Standard State-Space Models Preclude Unawareness.pdf},
  author = {Dekel, Eddie and Lipman, Barton L. and Rustichini, Aldo}
}

@article{delongPrimateModelsMovement1990,
  title = {Primate Models of Movement Disorders of Basal Ganglia Origin},
  year = {1990},
  month = jul,
  journal = {Trends in Neurosciences},
  volume = {13},
  number = {7},
  pages = {281--285},
  issn = {0166-2236},
  doi = {10.1016/0166-2236(90)90110-V},
  url = {https://www.sciencedirect.com/science/article/pii/016622369090110V},
  urldate = {2024-08-06},
  abstract = {Movement disorders associated with basal ganglia dysfunction comprise a spectrum of abnormalities that range from the hypokinetic disorders (of which Parkinson's disease is the best-known example) at one extreme to the hyperkinetic disorders (exemplified by Huntington's disease and hemiballismus) at the other. Both extremes of this movement disorder spectrum can be accounted for by postulating specific disturbances within the basal ganglia-thalamocortical ‘motor’ circuit. In this paper, Mahlon DeLong describes the changes in neuronal activity in the motor circuit in animal models of hypo- and hyperkinetic disorders.},
  file = {/Users/lhydave/Zotero/storage/BXPNR5CA/016622369090110V.html},
  author = {DeLong, Mahlon R.}
}

@article{dengComplexityComputingMarkov2023,
  title = {On the Complexity of Computing {{Markov}} Perfect Equilibrium in General-Sum Stochastic Games},
  year = {2023},
  month = jan,
  journal = {National Science Review},
  volume = {10},
  number = {1},
  pages = {nwac256},
  issn = {2095-5138},
  doi = {10.1093/nsr/nwac256},
  url = {https://doi.org/10.1093/nsr/nwac256},
  urldate = {2025-02-15},
  abstract = {Similar to the role of Markov decision processes in reinforcement learning, Markov games (also called stochastic games) lay down the foundation for the study of multi-agent reinforcement learning and sequential agent interactions. We introduce approximate Markov perfect equilibrium as a solution to the computational problem of finite-state stochastic games repeated in the infinite horizon and prove its PPAD-completeness. This solution concept preserves the Markov perfect property and opens up the possibility for the success of multi-agent reinforcement learning algorithms on static two-player games to be extended to multi-agent dynamic games, expanding the reign of the PPAD-complete class.},
  file = {/Users/lhydave/Zotero/storage/2AI573UJ/Deng 等 - 2023 - On the complexity of computing Markov perfect equilibrium in general-sum stochastic games.pdf;/Users/lhydave/Zotero/storage/PE4Z4CVA/6840228.html},
  author = {Deng, Xiaotie and Li, Ningyuan and Mguni, David and Wang, Jun and Yang, Yaodong}
}

@article{diaconisFiniteExchangeableSequences1980,
  title = {Finite {{Exchangeable Sequences}}},
  year = {1980},
  month = aug,
  journal = {The Annals of Probability},
  volume = {8},
  number = {4},
  pages = {745--764},
  publisher = {Institute of Mathematical Statistics},
  issn = {0091-1798, 2168-894X},
  doi = {10.1214/aop/1176994663},
  url = {https://projecteuclid.org/journals/annals-of-probability/volume-8/issue-4/Finite-Exchangeable-Sequences/10.1214/aop/1176994663.full},
  urldate = {2025-02-13},
  abstract = {Let \$X\_1, X\_2,\textbackslash cdots, X\_k, X\_\{k+1\},\textbackslash cdots, X\_n\$ be exchangeable random variables taking values in the set \$S\$. The variation distance between the distribution of \$X\_1, X\_2,\textbackslash cdots, X\_k\$ and the closest mixture of independent, identically distributed random variables is shown to be at most \$2 ck/n\$, where \$c\$ is the cardinality of \$S\$. If \$c\$ is infinite, the bound \$k(k - 1)/n\$ is obtained. These results imply the most general known forms of de Finetti's theorem. Examples are given to show that the rates \$k/n\$ and \$k(k - 1)/n\$ cannot be improved. The main tool is a bound on the variation distance between sampling with and without replacement. For instance, suppose an urn contains \$n\$ balls, each marked with some element of the set \$S\$, whose cardinality \$c\$ is finite. Now \$k\$ draws are made at random from this urn, either with or without replacement. This generates two probability distributions on the set of \$k\$-tuples, and the variation distance between them is at most \$2 ck/n\$.},
  keywords = {60G10,60J05,De Finetti's theorem,Exchangeable,extreme points,presentable,representable,sampling with and without replacement,Symmetric,variation distance},
  file = {/Users/lhydave/Zotero/storage/WVSTIJEM/Diaconis和Freedman - 1980 - Finite Exchangeable Sequences.pdf},
  author = {Diaconis, P. and Freedman, D.}
}

@book{durrettProbabilityTheoryExamples2019,
  title = {Probability: {{Theory}} and {{Examples}}},
  shorttitle = {Probability},
  year = {2019},
  series = {Cambridge {{Series}} in {{Statistical}} and {{Probabilistic Mathematics}}},
  edition = {5},
  publisher = {Cambridge University Press},
  address = {Cambridge},
  doi = {10.1017/9781108591034},
  url = {https://www.cambridge.org/core/books/probability/DD9A1907F810BB14CCFF022CDFC5677A},
  urldate = {2025-02-13},
  abstract = {This lively introduction to measure-theoretic probability theory covers laws of large numbers, central limit theorems, random walks, martingales, Markov chains, ergodic theorems, and Brownian motion. Concentrating on results that are the most useful for applications, this comprehensive treatment is a rigorous graduate text and reference. Operating under the philosophy that the best way to learn probability is to see it in action, the book contains extended examples that apply the theory to concrete applications. This fifth edition contains a new chapter on multidimensional Brownian motion and its relationship to partial differential equations (PDEs), an advanced topic that is finding new applications. Setting the foundation for this expansion, Chapter 7 now features a proof of Itô's formula. Key exercises that previously were simply proofs left to the reader have been directly inserted into the text as lemmas. The new edition re-instates discussion about the central limit theorem for martingales and stationary sequences.},
  isbn = {978-1-108-47368-2},
  file = {/Users/lhydave/Zotero/storage/98H96AK9/DD9A1907F810BB14CCFF022CDFC5677A.html},
  author = {Durrett, Rick}
}

@article{dworkAlgorithmicFoundationsDifferential2013,
  title = {The {{Algorithmic Foundations}} of {{Differential Privacy}}},
  year = {2013},
  journal = {Foundations and Trends® in Theoretical Computer Science},
  volume = {9},
  number = {3-4},
  pages = {211--407},
  issn = {1551-305X, 1551-3068},
  doi = {10.1561/0400000042},
  url = {http://www.nowpublishers.com/articles/foundations-and-trends-in-theoretical-computer-science/TCS-042},
  urldate = {2025-02-14},
  langid = {english},
  file = {/Users/lhydave/Zotero/storage/EG6HXKMJ/Dwork和Roth - 2013 - The Algorithmic Foundations of Differential Privacy.pdf;/Users/lhydave/Zotero/storage/ZCD5FCNG/Dwork和Roth - 2013 - The Algorithmic Foundations of Differential Privacy.pdf},
  author = {Dwork, Cynthia and Roth, Aaron}
}

@article{dworkCalibratingNoiseSensitivity2016,
  title = {Calibrating {{Noise}} to {{Sensitivity}} in {{Private Data Analysis}}},
  year = {2016},
  journal = {Journal of Privacy and Confidentiality},
  volume = {7},
  number = {3},
  pages = {17--51},
  issn = {2575-8527},
  doi = {10.29012/jpc.v7i3.405},
  url = {https://journalprivacyconfidentiality.org/index.php/jpc/article/view/405},
  urldate = {2025-02-14},
  abstract = {We continue a line of research initiated in Dinur and Nissim (2003); Dwork and Nissim (2004); and Blum et al. (2005) on privacy-preserving statistical databases. Consider a trusted server that holds a database of sensitive information. Given a query function \$f\$ mapping databases to reals, the so-called \{\textbackslash em true answer\} is the result of applying \$f\$ to the database. To protect privacy, the true answer is perturbed by the addition of random noise generated according to a carefully chosen distribution, and this response, the true answer plus noise, is returned to the user. Previous work focused on the case of noisy sums, in which \$f = \textbackslash sum\_i g(x\_i)\$, where \$x\_i\$ denotes the \$i\$th row of the database and \$g\$ maps database rows to \$[0,1]\$. We extend the study to general functions \$f\$, proving that privacy can be preserved by calibrating the standard deviation of the noise according to the \{\textbackslash em sensitivity\} of the function \$f\$. Roughly speaking, this is the amount that any single argument to \$f\$ can change its output. The new analysis shows that for several particular applications substantially less noise is needed than was previously understood to be the case. The first step is a very clean definition of privacy---now known as differential privacy---and measure of its loss. We also provide a set of tools for designing and combining differentially private algorithms, permitting the construction of complex differentially private analytical tools from simple differentially private primitives. Finally, we obtain separation results showing the increased value of interactive statistical release mechanisms over non-interactive ones.},
  copyright = {Copyright (c) 2016 the authors},
  langid = {english},
  keywords = {differential privacy,noise addition,private data analysis,statistical data privacy},
  file = {/Users/lhydave/Zotero/storage/9FBDE2XM/Dwork 等 - 2016 - Calibrating Noise to Sensitivity in Private Data Analysis.pdf},
  author = {Dwork, Cynthia and McSherry, Frank and Nissim, Kobbi and Smith, Adam}
}

@article{fanFixedPointMinimaxTheorems1952,
  title = {Fixed-{{Point}} and {{Minimax Theorems}} in {{Locally Convex Topological Linear Spaces}}},
  year = {1952},
  journal = {Proceedings of the National Academy of Sciences of the United States of America},
  volume = {38},
  number = {2},
  eprint = {88613},
  eprinttype = {jstor},
  pages = {121--126},
  publisher = {National Academy of Sciences},
  issn = {0027-8424},
  url = {https://www.jstor.org/stable/88613},
  urldate = {2025-02-15},
  file = {/Users/lhydave/Zotero/storage/B9XPAHSY/Fan - 1952 - Fixed-Point and Minimax Theorems in Locally Convex Topological Linear Spaces.pdf},
  author = {Fan, Ky}
}

@article{frobeniusUberMatrizenAus1912,
  title = {Über {{Matrizen}} Aus Nicht Negativen {{Elementen}}},
  year = {1912},
  publisher = {Königliche Akademie der Wissenschaften Berlin},
  url = {https://upload.wikimedia.org/wikipedia/commons/4/44/Ueber_Matrizen_aus_nicht_negativen_Elementen.pdf},
  urldate = {2025-02-15},
  file = {/Users/lhydave/Zotero/storage/AEK87T9B/Frobenius 等 - 1912 - Über Matrizen aus nicht negativen Elementen.pdf},
  author = {Frobenius, Georg and Frobenius, Ferdinand Georg and Frobenius, Ferdinand Georg and Frobenius, Ferdinand Georg and Mathematician, Germany}
}

@book{fudenbergGameTheory1991,
  title = {Game {{Theory}}},
  year = {1991},
  month = aug,
  publisher = {The MIT Press},
  url = {https://book.douban.com/subject/1473880/},
  urldate = {2023-09-14},
  isbn = {978-0-262-06141-4},
  keywords = {Game theory},
  author = {Fudenberg, Drew and Tirole, Jean}
}

@book{gamowPuzzlemath1958,
  title = {Puzzle-Math},
  year = {1958},
  month = feb,
  edition = {First Edition},
  publisher = {Viking Adult},
  abstract = {Book by George Gamow, Marvin Stern},
  isbn = {978-0-670-58335-5},
  langid = {english},
  author = {Gamow, George and Stern, Marvin}
}

@book{gazzanigaCognitiveNeuroscienceBiology2018,
  title = {Cognitive {{Neuroscience}}: {{The Biology}} of the {{Mind}}},
  shorttitle = {Cognitive {{Neuroscience}}},
  year = {2018},
  month = dec,
  edition = {Fifth edition},
  publisher = {W. W. Norton \& Company},
  abstract = {Authoritative, applied, and accessible Written by world-renowned researchers, including Michael Gazzaniga, Cognitive Neuroscience remains the gold standard in its field, showcasing the latest discoveries and clinical applications. In its new Fifth Edition, updated material is woven into the narrative of each chapter and featured in new Hot Science and Lessons from the Clinic sections. The presentation is also more accessible and focused as the result of Anatomical Orientation figures, Take-Home Message features, and streamlined chapter openers.},
  isbn = {978-0-393-60317-0},
  langid = {english},
  author = {Gazzaniga, Michael and Ivry, Richard B. and Ph.D, George R. Mangun}
}

@article{glicksbergFurtherGeneralizationKakutani1952,
  title = {A {{Further Generalization}} of the {{Kakutani Fixed Point Theorem}}, with {{Application}} to {{Nash Equilibrium Points}}},
  year = {1952},
  month = feb,
  journal = {Proceedings of the American Mathematical Society},
  volume = {3},
  number = {1},
  eprint = {2032478},
  eprinttype = {jstor},
  pages = {170},
  issn = {00029939},
  doi = {10.2307/2032478},
  url = {https://www.jstor.org/stable/2032478?origin=crossref},
  urldate = {2025-02-15},
  langid = {english},
  file = {/Users/lhydave/Zotero/storage/HSZUEY68/Glicksberg - 1952 - A Further Generalization of the Kakutani Fixed Point Theorem, with Application to Nash Equilibrium P.pdf},
  author = {Glicksberg, I. L.}
}

@inproceedings{goldwasserKnowledgeComplexityInteractive1985,
  title = {The Knowledge Complexity of Interactive Proof-Systems},
  booktitle = {Proceedings of the Seventeenth Annual {{ACM}} Symposium on {{Theory}} of Computing},
  year = {1985},
  month = dec,
  series = {{{STOC}} '85},
  pages = {291--304},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/22145.22178},
  url = {https://dl.acm.org/doi/10.1145/22145.22178},
  urldate = {2025-02-14},
  isbn = {978-0-89791-151-1},
  file = {/Users/lhydave/Zotero/storage/3H7URK67/Goldwasser 等 - 1985 - The knowledge complexity of interactive proof-systems.pdf},
  author = {Goldwasser, S and Micali, S and Rackoff, C}
}

@inproceedings{goodfellowGenerativeAdversarialNets2014,
  title = {Generative {{Adversarial Nets}}},
  booktitle = {Proceedings of the 28th {{International Conference}} on {{Neural Information Processing Systems}} - {{Volume}} 2},
  year = {2014},
  volume = {27},
  publisher = {Curran Associates, Inc.},
  url = {https://proceedings.neurips.cc/paper/2014/hash/5ca3e9b122f61f8f06494c97b1afccf3-Abstract.html},
  urldate = {2023-12-19},
  abstract = {We propose a new framework for estimating generative models via adversarial nets, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to 1/2 everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitatively evaluation of the generated samples.},
  author = {Goodfellow, Ian and {Pouget-Abadie}, Jean and Mirza, Mehdi and Xu, Bing and {Warde-Farley}, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua}
}

@article{greenbergUnrelatedQuestionRandomized1969,
  title = {The {{Unrelated Question Randomized Response Model}}: {{Theoretical Framework}}},
  shorttitle = {The {{Unrelated Question Randomized Response Model}}},
  year = {1969},
  month = jun,
  journal = {Journal of the American Statistical Association},
  volume = {64},
  number = {326},
  pages = {520--539},
  publisher = {ASA Website},
  issn = {0162-1459},
  doi = {10.1080/01621459.1969.10500991},
  url = {https://www.tandfonline.com/doi/abs/10.1080/01621459.1969.10500991},
  urldate = {2025-02-14},
  abstract = {This paper develops a theoretical framework for the unrelated question randomized response technique suggested by Walt R. Simmons. The statistical efficiency of this technique is compared with the Warner technique under situations of both truthful and untruthful responses. Methods of allocating the total sample to each of two subsamples required by the unrelated question approach are developed. Recommendations are made concerning choices of values for those parameters which can be assigned at the discretion of the investigator.},
  author = {Greenberg, Bernard G. and {Abul-Ela}, Abdel-Latif A. and Simmons, Walt R. and Horvitz, Daniel G.}
}

@incollection{hajekInterpretationsProbability2023,
  title = {Interpretations of {{Probability}}},
  booktitle = {The {{Stanford Encyclopedia}} of {{Philosophy}}},
  year = {2023},
  edition = {Winter 2023},
  publisher = {Metaphysics Research Lab, Stanford University},
  url = {https://plato.stanford.edu/archives/win2023/entries/probability-interpret/},
  urldate = {2025-02-13},
  abstract = {One regularly reads and hears probabilistic claims like the following:},
  keywords = {Carnap Rudolf,causal models,causation: probabilistic,chance: versus randomness,decision theory,disagreement,Dutch book arguments,epistemology: Bayesian,information,Laplace Pierre Simon,logic: inductive,Popper Karl,probability in medieval and Renaissance philosophy,quantum theory: philosophical issues in,Ramsey Frank,Reichenbach Hans,self-locating beliefs,statistics philosophy of},
  file = {/Users/lhydave/Zotero/storage/E6AWNSUX/probability-interpret.html},
  author = {Hájek, Alan},
  editor = {Zalta, Edward N. and Nodelman, Uri}
}

@book{hamiltonLogicMathematicians1988,
  title = {Logic for {{Mathematicians}}},
  year = {1988},
  month = oct,
  publisher = {Cambridge University Press},
  url = {https://book.douban.com/subject/1783332/},
  urldate = {2025-02-13},
  abstract = {Here is an introductory textbook which is designed to be useful not only to intending logicians but also to mathematicians in general. Based on Dr Hamilton's lectures to third and fourth year undergraduate mathematicians at the University of Stirling it has been written to introduce student or professional mathematicians, whose background need cover no more than a typical first..., (展开全部)},
  isbn = {978-0-521-36865-0},
  author = {Hamilton, A. G.}
}

@article{hanusChimpanzeeProblemsolvingContrasting2011,
  title = {Chimpanzee Problem-Solving: Contrasting the Use of Causal and Arbitrary Cues},
  shorttitle = {Chimpanzee Problem-Solving},
  year = {2011},
  month = nov,
  journal = {Animal Cognition},
  volume = {14},
  number = {6},
  pages = {871--878},
  issn = {1435-9456},
  doi = {10.1007/s10071-011-0421-6},
  url = {https://doi.org/10.1007/s10071-011-0421-6},
  urldate = {2025-02-15},
  abstract = {Humans are able to benefit from a causally structured problem-solving context rather than arbitrarily structured situations. In order to better understand nonhuman causal cognition, it is therefore important to isolate crucial factors that might differentiate between events that follow a purely spatial and temporal contingency and those that hold a “true” causal relationship. In the first of two experiments, chimpanzee subjects were required to detect a bottle containing juice from five opaque bottles of equal shape and size. In the causal condition, the juice bottle looked identical to the other four bottles, only it was much heavier than the others. In the arbitrary condition, the weight of all five bottles was identical, but the juice bottle was color-marked differently. Since bottle opening was made difficult (and therefore costly), the question was whether subject’s manipulative behavior would be random or somehow influenced by the nature of the provided information. Our results show that subjects detected and opened the juice bottle significantly faster when weight was the discriminating feature (causal condition) compared to situations in which the discrimination was necessarily based on a color-cue (arbitrary condition). Experiment 2 ruled out the possibility of a general learning bias toward tactile rather than visual information in chimpanzees. When tested in a simple exchange paradigm that prevented any use of causal information, no predominance of a tactile cue (weight) over a visual cue (color) could be found. Furthermore—and in contrast to the causal condition in Experiment 1—no learning occurred during the course of Experiment 2, neither in the weight nor in the color condition. We therefore conclude that chimpanzees can more easily determine the content of an object based on its causal properties compared to situations in which the only available information is a pure arbitrary regularity. This supports the view that chimpanzees’ causal cognition does not rely on mere perceptual information but also on structural abstraction about their physical environment.},
  langid = {english},
  keywords = {Arbitrary cues,Causal cognition,Causal cues,Chimpanzees,Problem-solving},
  author = {Hanus, Daniel and Call, Josep}
}

@article{harsanyiGamesIncompleteInformation1967,
  title = {Games with {{Incomplete Information Played}} by "{{Bayesian}}" {{Players}}, {{I-III}}. {{Part I}}. {{The Basic Model}}},
  year = {1967},
  journal = {Management Science},
  volume = {14},
  number = {3},
  eprint = {2628393},
  eprinttype = {jstor},
  pages = {159--182},
  publisher = {INFORMS},
  issn = {0025-1909},
  url = {https://www.jstor.org/stable/2628393},
  urldate = {2025-02-15},
  abstract = {The paper develops a new theory for the analysis of games with incomplete information where the players are uncertain about some important parameters of the game situation, such as the payoff functions, the strategies available to various players, the information other players have about the game, etc. However, each player has a subjective probability distribution over the alternative possibilities. In most of the paper it is assumed that these probability distributions entertained by the different players are mutually "consistent", in the sense that they can be regarded as conditional probability distributions derived from a certain "basic probability distribution" over the parameters unknown to the various players. But later the theory is extended also to cases where the different players' subjective probability distributions fail to satisfy this consistency assumption. In cases where the consistency assumption holds, the original game can be replaced by a game where nature first conducts a lottery in accordance with the basic probablity distribution, and the outcome of this lottery will decide which particular subgame will be played, i.e., what the actual values of the relevant parameters will be in the game. Yet, each player will receive only partial information about the outcome of the lottery, and about the values of these parameters. However, every player will know the "basic probability distribution" governing the lottery. Thus, technically, the resulting game will be a game with complete information. It is called the Bayes-equivalent of the original game. Part I of the paper describes the basic model and discusses various intuitive interpretations for the latter. Part II shows that the Nash equilibrium points of the Bayes-equivalent game yield "Bayesian equilibrium points" for the original game. Finally, Part III considers the main properties of the "basic probablity distribution".},
  file = {/Users/lhydave/Zotero/storage/QL4WTSKA/Harsanyi - 1967 - Games with Incomplete Information Played by Bayesian Players, I-III. Part I. The Basic Model.pdf},
  author = {Harsanyi, John C.}
}

@article{harsanyiGamesIncompleteInformation1968,
  title = {Games with {{Incomplete Information Played}} by “{{Bayesian}}” {{Players Part II}}. {{Bayesian Equilibrium Points}}},
  year = {1968},
  month = jan,
  journal = {Management Science},
  volume = {14},
  number = {5},
  pages = {320--334},
  publisher = {INFORMS},
  issn = {0025-1909},
  doi = {10.1287/mnsc.14.5.320},
  url = {https://pubsonline.informs.org/doi/10.1287/mnsc.14.5.320},
  urldate = {2025-02-15},
  abstract = {Part I of this paper has described a new theory for the analysis of games with incomplete information. It has been shown that, if the various players' subjective probability distributions satisfy a certain mutual-consistency requirement, then any given game with incomplete information will be equivalent to a certain game with complete information, called the “Bayes-equivalent” of the original game, or briefly a “Bayesian game.” Part II of the paper will now show that any Nash equilibrium point of this Bayesian game yields a “Bayesian equilibrium point” for the original game and conversely. This result will then be illustrated by numerical examples, representing two-person zero-sum games with incomplete information. We shall also show how our theory enables us to analyze the problem of exploiting the opponent's erroneous beliefs. However, apart from its indubitable usefulness in locating Bayesian equilibrium points, we shall show it on a numerical example (the Bayes-equivalent of a two-person cooperative game) that the normal form of a Bayesian game is in many cases a highly unsatisfactory representation of the game situation and has to be replaced by other representations (e.g., by the semi-normal form). We shall argue that this rather unexpected result is due to the fact that Bayesian games must be interpreted as games with “delayed commitment” whereas the normal-form representation always envisages a game with “immediate commitment.”},
  file = {/Users/lhydave/Zotero/storage/YV5MPDG6/mnsc.14.5.html},
  author = {Harsanyi, John C.}
}

@article{harsanyiGamesIncompleteInformation1968a,
  title = {Games with {{Incomplete Information Played}} by ‘{{Bayesian}}’ {{Players}}, {{Part III}}. {{The Basic Probability Distribution}} of the {{Game}}},
  year = {1968},
  month = mar,
  journal = {Management Science},
  volume = {14},
  number = {7},
  pages = {486--502},
  publisher = {INFORMS},
  issn = {0025-1909},
  doi = {10.1287/mnsc.14.7.486},
  url = {https://pubsonline.informs.org/doi/10.1287/mnsc.14.7.486},
  urldate = {2025-02-15},
  abstract = {Parts I and II of this paper have described a new theory for the analysis of games with incomplete information. Two cases have been distinguished: consistent games in which there exists some basic probability distribution from which the players' subjective probability distributions can be derived as conditional probability distributions; and inconsistent games in which no such basic probability distribution exists. Part III will now show that in consistent games, where a basic probability distribution exists, it is essentially unique. It will also be argued that, in the absence of special reasons to the contrary, one should try to analyze any given game situation with incomplete information in terms of a consistent-game model. However, it will be shown that our theory can be extended also to inconsistent games, in case the situation does require the use of an inconsistent-game model.},
  author = {Harsanyi, John C.}
}

@article{harsanyiGamesRandomlyDisturbed1973,
  title = {Games with Randomly Disturbed Payoffs: {{A}} New Rationale for Mixed-Strategy Equilibrium Points},
  shorttitle = {Games with Randomly Disturbed Payoffs},
  year = {1973},
  month = dec,
  journal = {International Journal of Game Theory},
  volume = {2},
  number = {1},
  pages = {1--23},
  issn = {1432-1270},
  doi = {10.1007/BF01737554},
  url = {https://doi.org/10.1007/BF01737554},
  urldate = {2025-02-15},
  abstract = {Equilibrium points in mixed strategies seem to be unstable, because any player can deviate without penalty from his equilibrium strategy even if he expects all other players to stick to theirs. This paper proposes a model under which most mixed-strategy equilibrium points have full stability. It is argued that for any gameΓ the players' uncertainty about the other players' exact payoffs can be modeled as a disturbed gameΓ*, i.e., as a game with small random fluctuations in the payoffs. Any equilibrium point inΓ, whether it is in pure or in mixed strategies, can “almost always” be obtained as a limit of a pure-strategy equilibrium point in the corresponding disturbed gameΓ* when all disturbances go to zero. Accordingly, mixed-strategy equilibrium points are stable — even though the players may make no deliberate effort to use their pure strategies with the probability weights prescribed by their mixed equilibrium strategies — because the random fluctuations in their payoffs willmake them use their pure strategies approximately with the prescribed probabilities.},
  langid = {english},
  keywords = {Economic Theory,Equilibrium Point,Game Theory,Mixed Strategy,Pure Strategy},
  file = {/Users/lhydave/Zotero/storage/UJF4U2BU/Harsanyi - 1973 - Games with randomly disturbed payoffs A new rationale for mixed-strategy equilibrium points.pdf},
  author = {Harsanyi, John C.}
}

@book{hastieElementsStatisticalLearning2009,
  title = {The {{Elements}} of {{Statistical Learning}}},
  year = {2009},
  series = {Springer {{Series}} in {{Statistics}}},
  publisher = {Springer},
  address = {New York, NY},
  doi = {10.1007/978-0-387-84858-7},
  url = {http://link.springer.com/10.1007/978-0-387-84858-7},
  urldate = {2025-02-14},
  copyright = {http://www.springer.com/tdm},
  isbn = {978-0-387-84857-0 978-0-387-84858-7},
  keywords = {Averaging,Boosting,classification,clustering,data mining,machine learning,Projection pursuit,Random Forest,supervised learning,Support Vector Machine,unsupervised learning},
  file = {/Users/lhydave/Zotero/storage/HQCC8KY6/Hastie 等 - 2009 - The Elements of Statistical Learning.pdf},
  author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome}
}

@book{hatcherAlgebraicTopology2001,
  title = {Algebraic {{Topology}}},
  year = {2001},
  month = dec,
  edition = {1st edition},
  publisher = {Cambridge University Press},
  address = {Cambridge},
  abstract = {In most major universities one of the three or four basic first year graduate mathematics courses is algebraic topology. This introductory text is suitable for use in a course on the subject or for self study, featuring broad coverage and a readable exposition, with many examples and exercises. The four main chapters present the basics: fundamental group and covering spaces, homology and cohomology, higher homotopy groups, and homotopy theory generally. The author emphasizes the geometric aspects of the subject, which helps students gain intuition. A unique feature is the inclusion of many optional topics not usually part of a first course due to time constraints: Bockstein and transfer homomorphisms, direct and inverse limits, H spaces and Hopf algebras, the Brown representability theorem, the James reduced product, the Dold Thom theorem, and Steenrod squares and powers.},
  isbn = {978-0-521-79540-1},
  langid = {english},
  author = {Hatcher, Allen}
}

@inproceedings{hoDenoisingDiffusionProbabilistic2020,
  title = {Denoising {{Diffusion Probabilistic Models}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  year = {2020},
  volume = {33},
  pages = {6840--6851},
  publisher = {Curran Associates, Inc.},
  url = {https://proceedings.neurips.cc/paper/2020/hash/4c5bcfec8584af0d967f1ab10179ca4b-Abstract.html},
  urldate = {2024-02-28},
  abstract = {We present high quality image synthesis results using diffusion probabilistic models, a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. Our best results are obtained by training on a weighted variational bound designed according to a novel connection between diffusion probabilistic models and denoising score matching with Langevin dynamics, and our models naturally admit a progressive lossy decompression scheme that can be interpreted as a generalization of autoregressive decoding. On the unconditional CIFAR10 dataset, we obtain an Inception score of 9.46 and a state-of-the-art FID score of 3.17. On 256x256 LSUN, we obtain sample quality similar to ProgressiveGAN.},
  file = {/Users/lhydave/Zotero/storage/PDDC4I3A/Ho 等 - 2020 - Denoising Diffusion Probabilistic Models.pdf},
  author = {Ho, Jonathan and Jain, Ajay and Abbeel, Pieter}
}

@book{huangHiddenMarkovModels1990,
  title = {Hidden {{Markov Models}} for {{Speech Recognition}}},
  year = {1990},
  publisher = {Columbia University Press},
  address = {USA},
  isbn = {978-0-7486-0162-2},
  author = {Huang, Xuedong and Ariki, Yasuo and Jack, Mervyn}
}

@article{huffmanMethodConstructionMinimumRedundancy1952,
  title = {A {{Method}} for the {{Construction}} of {{Minimum-Redundancy Codes}}},
  year = {1952},
  month = sep,
  journal = {Proceedings of the IRE},
  volume = {40},
  number = {9},
  pages = {1098--1101},
  issn = {2162-6634},
  doi = {10.1109/JRPROC.1952.273898},
  abstract = {An optimum method of coding an ensemble of messages consisting of a finite number of members is developed. A minimum-redundancy code is one constructed in such a way that the average number of coding digits per message is minimized.},
  keywords = {Transmitters},
  author = {Huffman, David A.}
}

@incollection{jamesEstimationQuadraticLoss1961,
  title = {Estimation with {{Quadratic Loss}}},
  booktitle = {Proceedings of the {{Fourth Berkeley Symposium}} on {{Mathematical Statistics}} and {{Probability}}, {{Volume}} 1: {{Contributions}} to the {{Theory}} of {{Statistics}}},
  year = {1961},
  month = jan,
  volume = {4.1},
  pages = {361--380},
  publisher = {University of California Press},
  url = {https://projecteuclid.org/ebooks/berkeley-symposium-on-mathematical-statistics-and-probability/Proceedings-of-the-Fourth-Berkeley-Symposium-on-Mathematical-Statistics-and/chapter/Estimation-with-Quadratic-Loss/bsmsp/1200512173},
  urldate = {2025-02-14},
  file = {/Users/lhydave/Zotero/storage/Z39V7RQ8/James和Stein - 1961 - Estimation with Quadratic Loss.pdf},
  author = {James, W. and Stein, Charles}
}

@book{jaynesProbabilityTheoryLogic2002,
  title = {Probability {{Theory}}: {{The Logic}} of {{Science}}},
  shorttitle = {Probability {{Theory}}},
  year = {2002},
  publisher = {Cambridge University Press},
  abstract = {The standard rules of probability can be interpreted as uniquely valid principles in logic. In this book, E. T. Jaynes dispels the imaginary distinction between 'probability theory' and 'statistical inference', leaving a logical unity and simplicity, which provides greater technical power and flexibility in applications. This book goes beyond the conventional mathematics of probability theory, viewing the subject in a wider context. New results are discussed, along with applications of probability theory to a wide variety of problems in physics, mathematics, economics, chemistry and biology. It contains many exercises and problems, and is suitable for use as a textbook on graduate level courses involving data analysis. The material is aimed at readers who are already familiar with applied mathematics at an advanced undergraduate level or higher. The book will be of interest to scientists working in any area where inference from incomplete information is necessary.},
  googlebooks = {ZWVvkQEACAAJ},
  langid = {english},
  author = {Jaynes, Edwin T.}
}

@article{jelinekDesignLinguisticStatistical1975,
  title = {Design of a Linguistic Statistical Decoder for the Recognition of Continuous Speech},
  year = {1975},
  month = may,
  journal = {IEEE Transactions on Information Theory},
  volume = {21},
  number = {3},
  pages = {250--256},
  issn = {1557-9654},
  doi = {10.1109/TIT.1975.1055384},
  url = {https://ieeexplore.ieee.org/document/1055384},
  urldate = {2025-02-13},
  abstract = {Most current attempts at automatic speech recognition are formulated in an artificial intelligence framework. In this paper we approach the problem from an information-theoretic point of view. We describe the overall structure of a linguistic statistical decoder (LSD) for the recognition of continuous speech. The input to the decoder is a string of phonetic symbols estimated by an acoustic processor (AP). For each phonetic string, the decoder finds the most likely input sentence. The decoder consists of four major subparts: 1) a statistical model of the language being recognized; 2) a phonemic dictionary and statistical phonological rules characterizing the speaker; 3) a phonetic matching algorithm that computes the similarity between phonetic strings, using the performance characteristics of the AP; 4) a word level search control. The details of each of the subparts and their interaction during the decoding process are discussed.},
  file = {/Users/lhydave/Zotero/storage/MVJRKIK9/Jelinek 等 - 1975 - Design of a linguistic statistical decoder for the recognition of continuous speech.pdf},
  author = {Jelinek, F. and Bahl, L. and Mercer, R.}
}

@article{johnsonExtensionsLipschitzMappings1984,
  title = {Extensions of {{Lipschitz}} Mappings into a {{Hilbert}} Space},
  year = {1984},
  journal = {Contemporary Mathematics},
  volume = {26},
  pages = {189--206},
  publisher = {American Mathematical Society},
  address = {Providence, Rhode Island},
  doi = {10.1090/conm/026/737400},
  url = {http://www.ams.org/conm/026/},
  urldate = {2025-02-14},
  abstract = {(Here ll\&lltip is the Lipschitz constant of the function g.) A classical result of Kirszbraun's [14, p. 48] states that L(t2, n) = 1 for all n, but it is easy to see that L(X, n) \textasciitilde{} \textasciitilde{} as n \textasciitilde{} \textasciitilde{} for many metric spaces X. Marcus and Pisier [10] initiated the study of L(X, n) for X = Lp. (For brevity, we will use hereafter the notation L(p, n) for L(Lp(O,l), n).) They prove that for each 1 {$<$} p {$<$} 2 there is a constant C(p) so that for n = 2, 3, 4, , , ,},
  isbn = {9780821850305 9780821876114},
  langid = {english},
  author = {Johnson, William B. and Lindenstrauss, Joram},
  editor = {Beals, Richard and Beck, Anatole and Bellow, Alexandra and Hajian, Arshag}
}

@article{jungFixedPointViewGradient2017,
  title = {A {{Fixed-Point}} of {{View}} on {{Gradient Methods}} for {{Big Data}}},
  year = {2017},
  month = sep,
  journal = {Frontiers in Applied Mathematics and Statistics},
  volume = {3},
  publisher = {Frontiers},
  issn = {2297-4687},
  doi = {10.3389/fams.2017.00018},
  url = {https://www.frontiersin.org/journals/applied-mathematics-and-statistics/articles/10.3389/fams.2017.00018/full},
  urldate = {2025-02-14},
  abstract = {{$<$}p{$>$}Interpreting gradient methods as fixed-point iterations, we provide a detailed analysis of those methods for minimizing convex objective functions. Due to their conceptual and algorithmic simplicity, gradient methods are widely used in machine learning for massive data sets (big data). In particular, stochastic gradient methods are considered the de-facto standard for training deep neural networks. Studying gradient methods within the realm of fixed-point theory provides us with powerful tools to analyze their convergence properties. In particular, gradient methods using inexact or noisy gradients, such as stochastic gradient descent, can be studied conveniently using well-known results on inexact fixed-point iterations. Moreover, as we demonstrate in this paper, the fixed-point approach allows an elegant derivation of accelerations for basic gradient methods. In particular, we will show how gradient descent can be accelerated by a fixed-point preserving transformation of an operator associated with the objective function.{$<$}/p{$>$}},
  langid = {english},
  keywords = {big data,convex optimization,First order methods,Fixed-point iterations,Gradient methods,heavy balls,machine learning},
  file = {/Users/lhydave/Zotero/storage/RUYCUQXZ/Jung - 2017 - A Fixed-Point of View on Gradient Methods for Big Data.pdf},
  author = {Jung, Alexander}
}

@article{kahnemanPsychologyPrediction1973,
  title = {On the Psychology of Prediction},
  year = {1973},
  journal = {Psychological Review},
  volume = {80},
  number = {4},
  pages = {237--251},
  publisher = {American Psychological Association},
  address = {US},
  issn = {1939-1471},
  doi = {10.1037/h0034747},
  abstract = {Considers that intuitive predictions follow a judgmental heuristic-representativeness. By this heuristic, people predict the outcome that appears most representative of the evidence. Consequently, intuitive predictions are insensitive to the reliability of the evidence or to the prior probability of the outcome, in violation of the logic of statistical prediction. The hypothesis that people predict by representativeness was supported in a series of studies with both naive and sophisticated university students (N = 871). The ranking of outcomes by likelihood coincided with the ranking by representativeness, and Ss erroneously predicted rare events and extreme values if these happened to be representative. The experience of unjustified confidence in predictions and the prevalence of fallacious intuitions concerning statistical regression are traced to the representativeness heuristic. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Intuition,Judgment,Prediction,Statistical Probability},
  file = {/Users/lhydave/Zotero/storage/QCUCH4XN/doiLanding.html},
  author = {Kahneman, Daniel and Tversky, Amos}
}

@article{kanekoGameLogicIts1996,
  title = {Game Logic and Its Applications {{I}}},
  year = {1996},
  month = oct,
  journal = {Studia Logica},
  volume = {57},
  number = {2-3},
  pages = {325--354},
  issn = {0039-3215, 1572-8730},
  doi = {10.1007/BF00370838},
  url = {http://link.springer.com/10.1007/BF00370838},
  urldate = {2023-05-07},
  abstract = {This paper provides a logic framework for investigations of game theoretical problems. We adopt an infinitary extension of classical predicate logic as the base logic of the framework. The reason for an infinitary extension is to express the common knowledge concept explicitly. Depending upon the choice of axioms on the knowledge operators, there is a hierarchy of logics. The limit case is an infinitary predicate extension of modal propositional logic KD\textasciitilde, and is of special interest in applications. In Part I, we develop the basic framework, and show some applications: an epistemic axiomatization of Nash equilibrium and formal undecidability on the playability of a game. To show the formal undecidability, we use a term existence theorem, which will be proved in Part II.},
  langid = {english},
  author = {Kaneko, Mamoru and Nagashima, Takashi}
}

@article{kanekoGameLogicIts1997,
  title = {Game {{Logic}} and Its {{Applications II}}},
  year = {1997},
  month = mar,
  journal = {Studia Logica},
  volume = {58},
  number = {2},
  pages = {273--303},
  issn = {1572-8730},
  doi = {10.1023/A:1004975724824},
  url = {https://doi.org/10.1023/A:1004975724824},
  urldate = {2025-02-15},
  abstract = {This paper provides a Genzten style formulation of the game logic framework GLm (0 ≤ m ≤ ω), and proves the cut-elimination theorem for GLm. As its application, we prove the term existence theorem for GLω used in Part I.},
  langid = {english},
  keywords = {common knowledge,infinitary predicate KD4,Nash equilibrium,undecidability on playability},
  file = {/Users/lhydave/Zotero/storage/4GMLV9JQ/Kaneko和Nagashima - 1997 - Game Logic and its Applications II.pdf},
  author = {Kaneko, Mamoru and Nagashima, Takashi}
}

@article{kantorovichBestUseEconomic1965,
  title = {The Best Use of Economic Resources.},
  year = {1965},
  url = {https://www.cabidigitallibrary.org/doi/full/10.5555/19651803150},
  urldate = {2025-02-14},
  author = {Kantorovich, Leonid Vitalʹevich}
}

@phdthesis{karushMinimaFunctionsSeveral1939,
  title = {Minima of Functions of Several Variables with Inequalities as Side Conditions},
  year = {1939},
  url = {https://catalog.lib.uchicago.edu/vufind/Record/4111654},
  urldate = {2025-02-15},
  keywords = {Functions},
  annotation = {OCLC: 43268508},
  author = {Karush, William}
}

@book{kearnsEthicalAlgorithmScience2019,
  title = {The {{Ethical Algorithm}}: {{The Science}} of {{Socially Aware Algorithm Design}}},
  shorttitle = {The {{Ethical Algorithm}}},
  year = {2019},
  month = oct,
  publisher = {Oxford University Press, Inc.},
  address = {USA},
  abstract = {Over the course of a generation, algorithms have gone from mathematical abstractions to powerful mediators of daily life. Algorithms have made our lives more efficient, more entertaining, and, sometimes, better informed. At the same time, complex algorithms are increasingly violating the basic rights of individual citizens. Allegedly anonymized datasets routinely leak our most sensitive personal information; statistical models for everything from mortgages to college admissions reflect racial and gender bias. Meanwhile, users manipulate algorithms to "game" search engines, spam filters, online reviewing services, and navigation apps. Understanding and improving the science behind the algorithms that run our lives is rapidly becoming one of the most pressing issues of this century. Traditional fixes, such as laws, regulations and watchdog groups, have proven woefully inadequate. Reporting from the cutting edge of scientific research, The Ethical Algorithm offers a new approach: a set of principled solutions based on the emerging and exciting science of socially aware algorithm design. Michael Kearns and Aaron Roth explain how we can better embed human principles into machine code - without halting the advance of data-driven scientific exploration. Weaving together innovative research with stories of citizens, scientists, and activists on the front lines, The Ethical Algorithm offers a compelling vision for a future, one in which we can better protect humans from the unintended impacts of algorithms while continuing to inspire wondrous advances in technology.},
  isbn = {978-0-19-094820-7},
  author = {Kearns, Michael and Roth, Aaron}
}

@article{kernsDefinettisTheoremAbstract2006,
  title = {Definetti’s {{Theorem}} for {{Abstract Finite Exchangeable Sequences}}},
  year = {2006},
  month = dec,
  journal = {Journal of Theoretical Probability},
  volume = {19},
  number = {3},
  pages = {589--608},
  issn = {1572-9230},
  doi = {10.1007/s10959-006-0028-z},
  url = {https://doi.org/10.1007/s10959-006-0028-z},
  urldate = {2025-02-13},
  abstract = {We show that a finite collection of exchangeable random variables on an arbitrary measurable space is a signed mixture of i.i.d. random variables. Two applications of this idea are examined, one concerning Bayesian consistency, in which it is established that a sequence of posterior distributions continues to converge to the true value of a parameter θ under much wider assumptions than are ordinarily supposed, the next pertaining to Statistical Physics where it is demonstrated that the quantum statistics of Fermi-Dirac may be derived from the statistics of classical (i.e. independent) particles by means of a signed mixture of multinomial distributions.},
  langid = {english},
  keywords = {de Finetti’s theorem,Exchangeable variables,extreme points,finite exchangeable sequence,Primary: 60B05,Secondary: 60E99,Secondary: 62E99,signed measure},
  file = {/Users/lhydave/Zotero/storage/K6D44M3V/Kerns和Székely - 2006 - Definetti’s Theorem for Abstract Finite Exchangeable Sequences.pdf},
  author = {Kerns, G. {\relax Jay}. and Székely, Gábor J.}
}

@misc{kingmaAutoEncodingVariationalBayes2022,
  title = {Auto-{{Encoding Variational Bayes}}},
  year = {2022},
  month = dec,
  number = {arXiv:1312.6114},
  eprint = {1312.6114},
  primaryclass = {stat},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1312.6114},
  url = {http://arxiv.org/abs/1312.6114},
  urldate = {2025-02-13},
  abstract = {How can we perform efficient inference and learning in directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case. Our contributions are two-fold. First, we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Second, we show that for i.i.d. datasets with continuous latent variables per datapoint, posterior inference can be made especially efficient by fitting an approximate inference model (also called a recognition model) to the intractable posterior using the proposed lower bound estimator. Theoretical advantages are reflected in experimental results.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/lhydave/Zotero/storage/7HX99FIA/Kingma和Welling - 2022 - Auto-Encoding Variational Bayes.pdf;/Users/lhydave/Zotero/storage/HKSPUKSJ/1312.html},
  author = {Kingma, Diederik P. and Welling, Max}
}

@inproceedings{kingmaSemisupervisedLearningDeep2014,
  title = {Semi-Supervised {{Learning}} with {{Deep Generative Models}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  year = {2014},
  volume = {27},
  publisher = {Curran Associates, Inc.},
  url = {https://papers.nips.cc/paper_files/paper/2014/hash/d523773c6b194f37b938d340d5d02232-Abstract.html},
  urldate = {2025-02-14},
  abstract = {The ever-increasing size of modern data sets combined with the difficulty of obtaining label information has made semi-supervised learning one of the problems of significant practical importance in modern data analysis. We revisit the approach to semi-supervised learning with generative models and develop new models that allow for effective generalisation from small labelled data sets to large unlabelled ones. Generative approaches have thus far been either inflexible, inefficient or non-scalable. We show that deep generative models and approximate Bayesian inference exploiting recent advances in variational methods can be used to provide significant improvements, making generative approaches highly competitive for semi-supervised learning.},
  file = {/Users/lhydave/Zotero/storage/USEHLKES/Kingma 等 - 2014 - Semi-supervised Learning with Deep Generative Models.pdf},
  author = {Kingma, Durk P and Mohamed, Shakir and Jimenez Rezende, Danilo and Welling, Max}
}

@incollection{kuhnNonlinearProgramming1951,
  title = {Nonlinear {{Programming}}},
  booktitle = {Proceedings of the {{Second Berkeley Symposium}} on {{Mathematical Statistics}} and {{Probability}}},
  year = {1951},
  month = jan,
  volume = {2},
  pages = {481--493},
  publisher = {University of California Press},
  url = {https://projecteuclid.org/ebooks/berkeley-symposium-on-mathematical-statistics-and-probability/Proceedings-of-the-Second-Berkeley-Symposium-on-Mathematical-Statistics-and/chapter/Nonlinear-Programming/bsmsp/1200500249},
  urldate = {2025-02-15},
  file = {/Users/lhydave/Zotero/storage/JT7HEPGZ/Kuhn和Tucker - 1951 - Nonlinear Programming.pdf},
  author = {Kuhn, H. W. and Tucker, A. W.}
}

@article{kullbackInformationSufficiency1951,
  title = {On {{Information}} and {{Sufficiency}}},
  year = {1951},
  journal = {The Annals of Mathematical Statistics},
  volume = {22},
  number = {1},
  eprint = {2236703},
  eprinttype = {jstor},
  pages = {79--86},
  publisher = {Institute of Mathematical Statistics},
  issn = {0003-4851},
  url = {https://www.jstor.org/stable/2236703},
  urldate = {2023-07-10},
  author = {Kullback, S. and Leibler, R. A.}
}

@book{leeIntroductionSmoothManifolds2012,
  title = {Introduction to {{Smooth Manifolds}}},
  year = {2012},
  series = {Graduate {{Texts}} in {{Mathematics}}},
  volume = {218},
  publisher = {Springer},
  address = {New York, NY},
  doi = {10.1007/978-1-4419-9982-5},
  url = {https://link.springer.com/10.1007/978-1-4419-9982-5},
  urldate = {2025-02-14},
  copyright = {https://www.springernature.com/gp/researchers/text-and-data-mining},
  isbn = {978-1-4419-9981-8 978-1-4419-9982-5},
  langid = {english},
  keywords = {de Rham cohomology,differential forms,first-order partial differential equations,foliations,Frobenius theorem,immersed and embedded submanifolds,Lie group,Sard’s theorem,smooth manifolds,Smooth structures,Stokes's theorem,Tangent vectors and covectors,tensors,vector bundles,vector fields and flows,Whitney approximation theorem,Whitney embedding theorem},
  file = {/Users/lhydave/Zotero/storage/2HD6MA9C/Lee - 2012 - Introduction to Smooth Manifolds.pdf},
  author = {Lee, John M.}
}

@book{levinMarkovChainsMixing2008,
  title = {Markov {{Chains}} and {{Mixing Times}}},
  year = {2008},
  edition = {第 1st 版},
  publisher = {American Mathematical Society},
  address = {Providence, Rhode Island},
  abstract = {This book is an introduction to the modern approach to the theory of Markov chains. The main goal of this approach is to determine the rate of convergence of a Markov chain to the stationary distribution as a function of the size and geometry of the state space. The authors develop the key tools for estimating convergence times, including coupling, strong stationary times, and spectral methods. Whenever possible, probabilistic methods are emphasized. The book includes many examples and provides brief introductions to some central models of statistical mechanics. Also provided are accounts of random walks on networks, including hitting and cover times, and analyses of several methods of shuffling cards. As a prerequisite, the authors assume a modest understanding of probability theory and linear algebra at an undergraduate level. Markov Chains and Mixing Times is meant to bring the excitement of this active area of research to a wide audience.},
  isbn = {978-0-8218-4739-8},
  author = {Levin, David A. and Peres, Yuval and Wilmer, Elizabeth L.}
}

@misc{lewisBARTDenoisingSequencetoSequence2019,
  title = {{{BART}}: {{Denoising Sequence-to-Sequence Pre-training}} for {{Natural Language Generation}}, {{Translation}}, and {{Comprehension}}},
  shorttitle = {{{BART}}},
  year = {2019},
  month = oct,
  number = {arXiv:1910.13461},
  eprint = {1910.13461},
  primaryclass = {cs, stat},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/1910.13461},
  urldate = {2023-07-10},
  abstract = {We present BART, a denoising autoencoder for pretraining sequence-to-sequence models. BART is trained by (1) corrupting text with an arbitrary noising function, and (2) learning a model to reconstruct the original text. It uses a standard Tranformer-based neural machine translation architecture which, despite its simplicity, can be seen as generalizing BERT (due to the bidirectional encoder), GPT (with the left-to-right decoder), and many other more recent pretraining schemes. We evaluate a number of noising approaches, finding the best performance by both randomly shuffling the order of the original sentences and using a novel in-filling scheme, where spans of text are replaced with a single mask token. BART is particularly effective when fine tuned for text generation but also works well for comprehension tasks. It matches the performance of RoBERTa with comparable training resources on GLUE and SQuAD, achieves new state-of-the-art results on a range of abstractive dialogue, question answering, and summarization tasks, with gains of up to 6 ROUGE. BART also provides a 1.1 BLEU increase over a back-translation system for machine translation, with only target language pretraining. We also report ablation experiments that replicate other pretraining schemes within the BART framework, to better measure which factors most influence end-task performance.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning,Statistics - Machine Learning},
  author = {Lewis, Mike and Liu, Yinhan and Goyal, Naman and Ghazvininejad, Marjan and Mohamed, Abdelrahman and Levy, Omer and Stoyanov, Ves and Zettlemoyer, Luke}
}

@book{liIntroductionKolmogorovComplexity2019,
  title = {An {{Introduction}} to {{Kolmogorov Complexity}} and {{Its Applications}}},
  year = {2019},
  series = {Texts in {{Computer Science}}},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-11298-1},
  url = {http://link.springer.com/10.1007/978-3-030-11298-1},
  urldate = {2025-02-13},
  copyright = {http://www.springer.com/tdm},
  isbn = {978-3-030-11297-4 978-3-030-11298-1},
  langid = {english},
  keywords = {algorithms,artificial intelligence,communication,complexity,computer,computer science,information,information theory,intelligence,learning,learning theory,logic,Shannon,statistics,Symbol},
  file = {/Users/lhydave/Zotero/storage/3L8GZ2WP/Li和Vitányi - 2019 - An Introduction to Kolmogorov Complexity and Its Applications.pdf},
  author = {Li, Ming and Vitányi, Paul}
}

@article{liSurveyAlgorithmsNash2024,
  title = {A Survey on Algorithms for {{Nash}} Equilibria in Finite Normal-Form Games},
  year = {2024},
  month = feb,
  journal = {Computer Science Review},
  volume = {51},
  pages = {100613},
  issn = {1574-0137},
  doi = {10.1016/j.cosrev.2023.100613},
  url = {https://www.sciencedirect.com/science/article/pii/S1574013723000801},
  urldate = {2025-02-15},
  abstract = {Nash equilibrium is one of the most influential solution concepts in game theory. With the development of computer science and artificial intelligence, there is an increasing demand on Nash equilibrium computation, especially for Internet economics and multi-agent learning. This paper reviews various algorithms computing the Nash equilibrium and its approximation solutions in finite normal-form games from both theoretical and empirical perspectives. For the theoretical part, we classify algorithms in the literature and present basic ideas on algorithm design and analysis. For the empirical part, we present a comprehensive comparison on the algorithms in the literature over different kinds of games. Based on these results, we provide practical suggestions on implementations and uses of these algorithms. Finally, we present a series of open problems from both theoretical and practical considerations.},
  keywords = {Approximation algorithms,Game theory,Nash equilibrium},
  file = {/Users/lhydave/Zotero/storage/7PLAR5EC/Li 等 - 2024 - A survey on algorithms for Nash equilibria in finite normal-form games.pdf;/Users/lhydave/Zotero/storage/MVF7WT2P/S1574013723000801.html},
  author = {Li, Hanyu and Huang, Wenhan and Duan, Zhijian and Mguni, David Henry and Shao, Kun and Wang, Jun and Deng, Xiaotie}
}

@inproceedings{littmanComplexitySolvingMarkov1995,
  title = {On the Complexity of Solving {{Markov}} Decision Problems},
  booktitle = {Proceedings of the {{Eleventh}} Conference on {{Uncertainty}} in Artificial Intelligence},
  year = {1995},
  month = aug,
  series = {{{UAI}}'95},
  pages = {394--402},
  publisher = {Morgan Kaufmann Publishers Inc.},
  address = {San Francisco, CA, USA},
  urldate = {2025-02-13},
  abstract = {Markov decision problems (MDPs) provide the foundations for a number of problems of interest to AI researchers studying automated planning and reinforcement learning. In this paper, we summarize results regarding the complexity of solving MDPs and the running time of MDP solution algorithms. We argue that, although MDPs can be solved efficiently in theory, more study is needed to reveal practical algorithms for solving large problems quickly. To encourage future research, we sketch some alternative methods of analysis that rely on the structure of MDPs.},
  isbn = {978-1-55860-385-1},
  file = {/Users/lhydave/Zotero/storage/5F6ZUYIN/Littman 等 - 1995 - On the complexity of solving Markov decision problems.pdf},
  author = {Littman, Michael L. and Dean, Thomas L. and Kaelbling, Leslie Pack}
}

@book{LiXianPingGaiLuLunJiChu2010,
  title = {{概率论基础}},
  year = {2010},
  publisher = {高等教育出版社},
  urldate = {2023-07-10},
  isbn = {978-7-04-028890-2},
  langid = {chinese},
  author = {李贤平}
}

@book{luenbergerLinearNonlinearProgramming2021,
  title = {Linear and {{Nonlinear Programming}}},
  year = {2021},
  series = {International {{Series}} in {{Operations Research}} \& {{Management Science}}},
  volume = {228},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-85450-8},
  url = {https://link.springer.com/10.1007/978-3-030-85450-8},
  urldate = {2025-02-14},
  copyright = {https://www.springer.com/tdm},
  isbn = {978-3-030-85449-2 978-3-030-85450-8},
  langid = {english},
  keywords = {convergence speed analysis,Data Science and Machine Learning,Farkas’ lemma,Frank-Wolf method,Linear Programming,Luenberger,Markov Decision Process,Mathematical Programming,online linear programming,Operations Research,Optimization Models,Semidefinite Programming},
  file = {/Users/lhydave/Zotero/storage/WR9LQZN9/Luenberger和Ye - 2021 - Linear and Nonlinear Programming.pdf},
  author = {Luenberger, David G. and Ye, Yinyu}
}

@article{mcmillanBasicTheoremsInformation1953,
  title = {The {{Basic Theorems}} of {{Information Theory}}},
  year = {1953},
  month = jun,
  journal = {The Annals of Mathematical Statistics},
  volume = {24},
  number = {2},
  pages = {196--219},
  publisher = {Institute of Mathematical Statistics},
  issn = {0003-4851, 2168-8990},
  doi = {10.1214/aoms/1177729028},
  url = {https://projecteuclid.org/journals/annals-of-mathematical-statistics/volume-24/issue-2/The-Basic-Theorems-of-Information-Theory/10.1214/aoms/1177729028.full},
  urldate = {2023-07-10},
  abstract = {This paper describes briefly the current mathematical models upon which communication theory is based, and presents in some detail an exposition and partial critique of C. E. Shannon's treatment of one such model. It then presents a general limit theorem in the theory of discrete stochastic processes, suggested by a result of Shannon's.},
  author = {McMillan, Brockway}
}

@book{milnorTopologyDifferentiableViewpoint1997,
  title = {Topology from the {{Differentiable Viewpoint}}},
  year = {1997},
  month = nov,
  edition = {Revised edition},
  publisher = {Princeton University Press},
  address = {Princeton, N.J},
  abstract = {This elegant book by distinguished mathematician John Milnor, provides a clear and succinct introduction to one of the most important subjects in modern mathematics. Beginning with basic concepts such as diffeomorphisms and smooth manifolds, he goes on to examine tangent spaces, oriented manifolds, and vector fields. Key concepts such as homotopy, the index number of a map, and the Pontryagin construction are discussed. The author presents proofs of Sard's theorem and the Hopf theorem.},
  isbn = {978-0-691-04833-8},
  langid = {english},
  author = {Milnor, John Willard}
}

@inproceedings{mirInformationTheoreticFoundationsDifferential2012,
  title = {Information-{{Theoretic}} Foundations of Differential Privacy},
  booktitle = {Proceedings of the 5th International Conference on {{Foundations}} and {{Practice}} of {{Security}}},
  year = {2012},
  month = oct,
  series = {{{FPS}}'12},
  pages = {374--381},
  publisher = {Springer-Verlag},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-37119-6_25},
  url = {https://doi.org/10.1007/978-3-642-37119-6_25},
  urldate = {2025-02-13},
  abstract = {We examine the information-theoretic foundations of the increasingly popular notion of differential privacy. We establish a connection between differential private mechanisms and the rate-distortion framework. Additionally, we also show how differentially private distributions arise out of the application of the Maximum Entropy Principle. This helps us locate differential privacy within the wider framework of information-theory and helps formalize some intuitive aspects of our understanding of differential privacy.},
  isbn = {978-3-642-37118-9},
  author = {Mir, Darakhshan J.}
}

@article{nashEquilibriumPointsNperson1950,
  title = {Equilibrium Points in N-Person Games},
  year = {1950},
  month = jan,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {36},
  number = {1},
  pages = {48--49},
  publisher = {Proceedings of the National Academy of Sciences},
  doi = {10.1073/pnas.36.1.48},
  url = {https://www.pnas.org/doi/full/10.1073/pnas.36.1.48},
  urldate = {2025-02-15},
  file = {/Users/lhydave/Zotero/storage/8N9L6RZ6/Nash - 1950 - Equilibrium points in n-person games.pdf},
  author = {Nash, John F.}
}

@article{nashNonCooperativeGames1951,
  title = {Non-{{Cooperative Games}}},
  year = {1951},
  journal = {Annals of Mathematics},
  volume = {54},
  number = {2},
  eprint = {1969529},
  eprinttype = {jstor},
  pages = {286--295},
  publisher = {Annals of Mathematics},
  issn = {0003486X},
  url = {http://www.jstor.org/stable/1969529},
  urldate = {2023-01-10},
  author = {Nash, John}
}

@book{nerodeLogicApplications1997,
  title = {Logic for {{Applications}}},
  year = {1997},
  publisher = {Springer},
  address = {New York, NY},
  doi = {10.1007/978-1-4612-0649-1},
  url = {http://link.springer.com/10.1007/978-1-4612-0649-1},
  urldate = {2025-02-13},
  copyright = {http://www.springer.com/tdm},
  isbn = {978-1-4612-6855-0 978-1-4612-0649-1},
  keywords = {Algorithms,Automat,automation,cardinality,cardinals,computability,computer,forcing,predicate logic,programming,proving,semantics,set theory,Syntax,theorem proving},
  author = {Nerode, Anil and Shore, Richard A.}
}

@book{nesterovIntroductoryLecturesConvex2004,
  title = {Introductory {{Lectures}} on {{Convex Optimization}}},
  year = {2004},
  series = {Applied {{Optimization}}},
  volume = {87},
  publisher = {Springer US},
  address = {Boston, MA},
  doi = {10.1007/978-1-4419-8853-9},
  url = {http://link.springer.com/10.1007/978-1-4419-8853-9},
  urldate = {2025-02-14},
  copyright = {http://www.springer.com/tdm},
  isbn = {978-1-4613-4691-3 978-1-4419-8853-9},
  keywords = {complexity,complexity theory,graphs,mathematical programming,optimization},
  file = {/Users/lhydave/Zotero/storage/EYBMZZJA/Nesterov - 2004 - Introductory Lectures on Convex Optimization.pdf},
  author = {Nesterov, Yurii},
  editor = {Pardalos, Panos M. and Hearn, Donald W.}
}

@book{norrisMarkovChains1997,
  title = {Markov {{Chains}}},
  year = {1997},
  series = {Cambridge {{Series}} in {{Statistical}} and {{Probabilistic Mathematics}}},
  publisher = {Cambridge University Press},
  address = {Cambridge},
  doi = {10.1017/CBO9780511810633},
  url = {https://www.cambridge.org/core/books/markov-chains/A3F966B10633A32C8F06F37158031739},
  urldate = {2025-02-13},
  abstract = {Markov chains are central to the understanding of random processes. This is not only because they pervade the applications of random processes, but also because one can calculate explicitly many quantities of interest. This textbook, aimed at advanced undergraduate or MSc students with some background in basic probability theory, focuses on Markov chains and quickly develops a coherent and rigorous theory whilst showing also how actually to apply it. Both discrete-time and continuous-time chains are studied. A distinguishing feature is an introduction to more advanced topics such as martingales and potentials in the established context of Markov chains. There are applications to simulation, economics, optimal control, genetics, queues and many other topics, and exercises and examples drawn both from theory and practice. It will therefore be an ideal text either for elementary courses on random processes or those that are more oriented towards applications.},
  isbn = {978-0-521-63396-3},
  file = {/Users/lhydave/Zotero/storage/6AIU2NSD/A3F966B10633A32C8F06F37158031739.html},
  author = {Norris, J. R.}
}

@book{NumericalOptimization2006,
  title = {Numerical {{Optimization}}},
  year = {2006},
  series = {Springer {{Series}} in {{Operations Research}} and {{Financial Engineering}}},
  publisher = {Springer New York},
  doi = {10.1007/978-0-387-40065-5},
  url = {http://link.springer.com/10.1007/978-0-387-40065-5},
  urldate = {2025-02-14},
  copyright = {http://www.springer.com/tdm},
  isbn = {978-0-387-30303-1},
  langid = {english},
  keywords = {algorithms,Calculus of Variations,linear optimization,nonlinear optimization,operations research,optimization,quadratic programming,Quasi-Newton method},
  file = {/Users/lhydave/Zotero/storage/PBK77UWW/2006 - Numerical Optimization.pdf}
}

@book{osborneCourseGameTheory1994,
  title = {A {{Course}} in {{Game Theory}}},
  year = {1994},
  month = jul,
  edition = {First Edition},
  publisher = {The MIT Press},
  address = {Cambridge, Mass.},
  abstract = {A Course in Game Theory presents the main ideas of game theory at a level suitable for graduate students and advanced undergraduates, emphasizing the theory's foundations and interpretations of its basic concepts. The authors provide precise definitions and full proofs of results, sacrificing generalities and limiting the scope of the material in order to do so. The text is organized in four parts: strategic games, extensive games with perfect information, extensive games with imperfect information, and coalitional games. It includes over 100 exercises.},
  isbn = {978-0-262-65040-3},
  langid = {english},
  author = {Osborne, Martin J. and Rubinstein, Ariel}
}

@misc{pacuitReasoningHumansClear,
  title = {Reasoning for {{Humans}}: {{Clear Thinking}} in an {{Uncertain World}}},
  journal = {PHIL 171},
  url = {https://phil171.org/},
  urldate = {2025-02-13},
  abstract = {Reasoning for Humans: Clear Thinking in an Uncertain World},
  langid = {american},
  file = {/Users/lhydave/Zotero/storage/A6SHYNTE/phil171.org.html},
  note = {(accessed 2025-02-13)},
  howpublished = {\url{https://phil171.org/}},
  author = {Pacuit, Eric}
}

@inproceedings{pavlovicSemanticalApproachEquilibria2009,
  title = {A {{Semantical Approach}} to {{Equilibria}} and {{Rationality}}},
  booktitle = {Algebra and {{Coalgebra}} in {{Computer Science}}},
  year = {2009},
  pages = {317--334},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-03741-2_22},
  abstract = {Game theoretic equilibria are mathematical expressions of rationality. Rational agents are used to model not only humans and their software representatives, but also organisms, populations, species and genes, interacting with each other and with the environment. Rational behaviors are achieved not only through conscious reasoning, but also through spontaneous stabilization at equilibrium points.},
  isbn = {978-3-642-03741-2},
  langid = {english},
  keywords = {Game Theory,Monoidal Category,Nash Equilibrium,Response Distribution,Semantical Approach},
  file = {/Users/lhydave/Zotero/storage/WPSFURUA/Pavlovic - 2009 - A Semantical Approach to Equilibria and Rationality.pdf},
  author = {Pavlovic, Dusko},
  editor = {Kurz, Alexander and Lenisa, Marina and Tarlecki, Andrzej}
}

@article{perronZurTheorieMatrices1907,
  title = {{Zur Theorie der Matrices}},
  year = {1907},
  month = jun,
  journal = {Mathematische Annalen},
  volume = {64},
  number = {2},
  pages = {248--263},
  issn = {1432-1807},
  doi = {10.1007/BF01449896},
  url = {https://doi.org/10.1007/BF01449896},
  urldate = {2025-02-15},
  langid = {ngerman},
  file = {/Users/lhydave/Zotero/storage/N7T4GHTB/Perron - 1907 - Zur Theorie der Matrices.pdf},
  author = {Perron, Oskar}
}

@misc{ProofGeometricLanglands,
  title = {Proof of the Geometric {{Langlands}} Conjecture},
  url = {https://people.mpim-bonn.mpg.de/gaitsgde/GLC/},
  urldate = {2025-02-15},
  file = {/Users/lhydave/Zotero/storage/RDBVUH7T/GLC.html},
  note = {(accessed 2025-02-15)},
  howpublished = {\url{https://people.mpim-bonn.mpg.de/gaitsgde/GLC/}}
}

@article{radfordImprovingLanguageUnderstanding,
  title = {Improving {{Language Understanding}} by {{Generative Pre-Training}}},
  abstract = {Natural language understanding comprises a wide range of diverse tasks such as textual entailment, question answering, semantic similarity assessment, and document classification. Although large unlabeled text corpora are abundant, labeled data for learning these specific tasks is scarce, making it challenging for discriminatively trained models to perform adequately. We demonstrate that large gains on these tasks can be realized by generative pre-training of a language model on a diverse corpus of unlabeled text, followed by discriminative fine-tuning on each specific task. In contrast to previous approaches, we make use of task-aware input transformations during fine-tuning to achieve effective transfer while requiring minimal changes to the model architecture. We demonstrate the effectiveness of our approach on a wide range of benchmarks for natural language understanding. Our general task-agnostic model outperforms discriminatively trained models that use architectures specifically crafted for each task, significantly improving upon the state of the art in 9 out of the 12 tasks studied. For instance, we achieve absolute improvements of 8.9\% on commonsense reasoning (Stories Cloze Test), 5.7\% on question answering (RACE), and 1.5\% on textual entailment (MultiNLI).},
  langid = {english},
  file = {/Users/lhydave/Zotero/storage/56FY8FVV/Radford 等 - Improving Language Understanding by Generative Pre-Training.pdf},
  author = {Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya}
}

@book{robertm.fanoTransmissionInformation1949,
  title = {The {{Transmission}} of {{Information}}},
  year = {1949},
  month = mar,
  url = {http://archive.org/details/fano-tr65.7z},
  urldate = {2023-07-10},
  abstract = {Fano's conception of information theory, including Shannon-Fano coding},
  langid = {english},
  keywords = {information theory},
  author = {{Robert M. Fano}}
}

@book{rockafellarConvexAnalysis1970,
  title = {Convex Analysis},
  year = {1970},
  publisher = {Princeton, N.J., Princeton University Press},
  url = {http://archive.org/details/convexanalysis0000rock},
  urldate = {2025-02-14},
  abstract = {xviii, 451 p. 24 cm; Bibliography: p. 433-446},
  isbn = {978-0-691-08069-7},
  langid = {english},
  keywords = {Mathematical analysis},
  author = {Rockafellar, R. Tyrrell},
  collaborator = {{Internet Archive}}
}

@article{rothRoleInformationBargaining1982,
  title = {The {{Role}} of {{Information}} in {{Bargaining}}: {{An Experimental Study}}},
  shorttitle = {The {{Role}} of {{Information}} in {{Bargaining}}},
  year = {1982},
  journal = {Econometrica},
  volume = {50},
  number = {5},
  eprint = {1911866},
  eprinttype = {jstor},
  pages = {1123--1142},
  publisher = {[Wiley, Econometric Society]},
  issn = {0012-9682},
  doi = {10.2307/1911866},
  url = {https://www.jstor.org/stable/1911866},
  urldate = {2025-02-15},
  abstract = {A fundamental assumption in much of game theory and economics is that all the relevant information for determining the rational play of a game is contained in its structural description. Recent experimental studies of bargaining have demonstrated effects due to information not included in the classical models of games of complete information. The goal of the experiment reported here is to separate these effects into components that can be attributed to the possession of specific information by specific bargainers, and to assess the extent to which the observed behavior can be characterized as equilibrium behavior. The results of the experiment permit us to identify such component effects, in equilibrium, including effects that depend on whether certain information is common knowledge or not. The paper closes with some speculation on the causes of these effects.},
  file = {/Users/lhydave/Zotero/storage/D7LWRFV3/Roth和Murnighan - 1982 - The Role of Information in Bargaining An Experimental Study.pdf},
  author = {Roth, Alvin E. and Murnighan, J. Keith}
}

@article{rubinsteinElectronicMailGame1989,
  title = {The {{Electronic Mail Game}}: {{Strategic Behavior Under}} "{{Almost Common Knowledge}}"},
  shorttitle = {The {{Electronic Mail Game}}},
  year = {1989},
  journal = {The American Economic Review},
  volume = {79},
  number = {3},
  eprint = {1806851},
  eprinttype = {jstor},
  pages = {385--391},
  publisher = {American Economic Association},
  issn = {0002-8282},
  url = {https://www.jstor.org/stable/1806851},
  urldate = {2025-02-15},
  abstract = {The paper addresses a paradoxical game-theoretic example which is closely related to the coordinated attack problem. Two players have to play one of two possible coordination games. Only one of them receives information about the coordination game to be played. It is shown that the situation with "almost common knowledge" is very different from when the coordination game played is common knowledge.},
  file = {/Users/lhydave/Zotero/storage/HD8TRBEG/Rubinstein - 1989 - The Electronic Mail Game Strategic Behavior Under Almost Common Knowledge.pdf},
  author = {Rubinstein, Ariel}
}

@incollection{rumelhartLearningInternalRepresentations1986,
  title = {Learning Internal Representations by Error Propagation},
  booktitle = {Parallel Distributed Processing: Explorations in the Microstructure of Cognition, Vol. 1: Foundations},
  year = {1986},
  month = jan,
  pages = {318--362},
  publisher = {MIT Press},
  address = {Cambridge, MA, USA},
  urldate = {2023-07-09},
  isbn = {978-0-262-68053-0},
  author = {Rumelhart, D. E. and Hinton, G. E. and Williams, R. J.}
}

@article{saffranStatisticalLearning8MonthOld1996,
  title = {Statistical {{Learning}} by 8-{{Month-Old Infants}}},
  year = {1996},
  month = dec,
  journal = {Science},
  volume = {274},
  number = {5294},
  pages = {1926--1928},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/science.274.5294.1926},
  url = {https://www.science.org/doi/10.1126/science.274.5294.1926},
  urldate = {2025-02-13},
  abstract = {Learners rely on a combination of experience-independent and experience-dependent mechanisms to extract information from the environment. Language acquisition involves both types of mechanisms, but most theorists emphasize the relative importance of experience-independent mechanisms. The present study shows that a fundamental task of language acquisition, segmentation of words from fluent speech, can be accomplished by 8-month-old infants based solely on the statistical relationships between neighboring speech sounds. Moreover, this word segmentation was based on statistical learning from only 2 minutes of exposure, suggesting that infants have access to a powerful mechanism for the computation of statistical properties of the language input.},
  author = {Saffran, Jenny R. and Aslin, Richard N. and Newport, Elissa L.}
}

@article{samuelsonModelingKnowledgeEconomic2004,
  title = {Modeling {{Knowledge}} in {{Economic Analysis}}},
  year = {2004},
  month = jun,
  journal = {Journal of Economic Literature},
  volume = {42},
  number = {2},
  pages = {367--403},
  issn = {0022-0515},
  doi = {10.1257/0022051041409057},
  url = {https://www.aeaweb.org/articles?id=10.1257/0022051041409057},
  urldate = {2025-02-15},
  abstract = {This paper provides an introduction to how knowledge is modeled in economic contexts and the role played by the concepts of knowledge and common knowledge in economic analysis.},
  langid = {english},
  keywords = {Belief,Communication,Information and Knowledge,Learning,Search},
  author = {Samuelson, Larry}
}

@article{schrittwieserMasteringAtariGo2020,
  title = {Mastering {{Atari}}, {{Go}}, Chess and Shogi by Planning with a Learned Model},
  year = {2020},
  month = dec,
  journal = {Nature},
  volume = {588},
  number = {7839},
  pages = {604--609},
  publisher = {Nature Publishing Group},
  issn = {1476-4687},
  doi = {10.1038/s41586-020-03051-4},
  url = {https://www.nature.com/articles/s41586-020-03051-4},
  urldate = {2024-05-01},
  abstract = {Constructing agents with planning capabilities has long been one of the main challenges in the pursuit of artificial intelligence. Tree-based planning methods have enjoyed huge success in challenging domains, such as chess1 and Go2, where a perfect simulator is available. However, in real-world problems, the dynamics governing the environment are often complex and unknown. Here we present the MuZero algorithm, which, by combining a tree-based search with a learned model, achieves superhuman performance in a range of challenging and visually complex domains, without any knowledge of their underlying dynamics. The MuZero algorithm learns an iterable model that produces predictions relevant to planning: the action-selection policy, the value function and the reward. When evaluated on 57 different Atari games3—the canonical video game environment for testing artificial intelligence techniques, in which model-based planning approaches have historically struggled4—the MuZero algorithm achieved state-of-the-art performance. When evaluated on Go, chess and shogi—canonical environments for high-performance planning—the MuZero algorithm matched, without any knowledge of the game dynamics, the superhuman performance of the AlphaZero algorithm5 that was supplied with the rules of the game.},
  copyright = {2020 The Author(s), under exclusive licence to Springer Nature Limited},
  langid = {english},
  keywords = {/unread,Computational science,Computer science,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/lhydave/Zotero/storage/BRM5CRN7/Schrittwieser et al. - 2020 - Mastering Atari, Go, chess and shogi by planning with a learned model.pdf;/Users/lhydave/Zotero/storage/PRVR6YZ5/Schrittwieser et al. - 2020 - Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model.pdf;/Users/lhydave/Zotero/storage/QDGEQWRL/1911.html},
  author = {Schrittwieser, Julian and Antonoglou, Ioannis and Hubert, Thomas and Simonyan, Karen and Sifre, Laurent and Schmitt, Simon and Guez, Arthur and Lockhart, Edward and Hassabis, Demis and Graepel, Thore and Lillicrap, Timothy and Silver, David}
}

@article{sellittoMyopicDiscountingFuture2010,
  title = {Myopic {{Discounting}} of {{Future Rewards}} after {{Medial Orbitofrontal Damage}} in {{Humans}}},
  year = {2010},
  month = dec,
  journal = {Journal of Neuroscience},
  volume = {30},
  number = {49},
  pages = {16429--16436},
  publisher = {Society for Neuroscience},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.2516-10.2010},
  url = {https://www.jneurosci.org/content/30/49/16429},
  urldate = {2024-08-04},
  abstract = {Choices are often intertemporal, requiring tradeoff of short-term and long-term outcomes. In such contexts, humans may prefer small rewards delivered immediately to larger rewards delivered after a delay, reflecting temporal discounting (TD) of delayed outcomes. The medial orbitofrontal cortex (mOFC) is consistently activated during intertemporal choice, yet its role remains unclear. Here, patients with lesions in the mOFC (mOFC patients), control patients with lesions outside the frontal lobe, and healthy individuals chose hypothetically between small-immediate and larger-delayed rewards. The type of reward varied across three TD tasks, including both primary (food) and secondary (money and discount vouchers) rewards. We found that damage to mOFC increased significantly the preference for small-immediate over larger-delayed rewards, resulting in steeper TD of future rewards in mOFC patients compared with the control groups. This held for both primary and secondary rewards. All participants, including mOFC patients, were more willing to wait for delayed money and discount vouchers than for delayed food, suggesting that mOFC patients' (impatient) choices were not due merely to poor motor impulse control or consideration of the goods at stake. These findings provide the first evidence in humans that mOFC is necessary for valuation and preference of delayed rewards for intertemporal choice.},
  chapter = {Articles},
  copyright = {Copyright © 2010 the authors 0270-6474/10/3016429-08\$15.00/0},
  langid = {english},
  pmid = {21147982},
  file = {/Users/lhydave/Zotero/storage/GV5CM4EB/Sellitto 等 - 2010 - Myopic Discounting of Future Rewards after Medial Orbitofrontal Damage in Humans.pdf},
  author = {Sellitto, Manuela and Ciaramelli, Elisa and di Pellegrino, Giuseppe}
}

@article{shannonMathematicalTheoryCommunication1948,
  title = {A Mathematical Theory of Communication},
  year = {1948},
  month = jul,
  journal = {The Bell System Technical Journal},
  volume = {27},
  number = {3},
  pages = {379--423},
  issn = {0005-8580},
  doi = {10.1002/j.1538-7305.1948.tb01338.x},
  abstract = {The recent development of various methods of modulation such as PCM and PPM which exchange bandwidth for signal-to-noise ratio has intensified the interest in a general theory of communication. A basis for such a theory is contained in the important papers of Nyquist1 and Hartley2 on this subject. In the present paper we will extend the theory to include a number of new factors, in particular the effect of noise in the channel, and the savings possible due to the statistical structure of the original message and due to the nature of the final destination of the information.},
  author = {Shannon, C. E.}
}

@book{shaoMathematicalStatistics2003,
  title = {Mathematical {{Statistics}}},
  year = {2003},
  series = {Springer {{Texts}} in {{Statistics}}},
  publisher = {Springer},
  address = {New York, NY},
  doi = {10.1007/b97553},
  url = {http://link.springer.com/10.1007/b97553},
  urldate = {2025-02-14},
  copyright = {http://www.springer.com/tdm},
  isbn = {978-0-387-95382-3 978-0-387-21718-5},
  keywords = {likelihood,Markov chain,Mathematica,mathematical statistics,Mathematical Statistics,probability,probability theory,statistical theory,Statistical Theory,statistics},
  file = {/Users/lhydave/Zotero/storage/5ACGW7SF/Shao - 2003 - Mathematical Statistics.pdf},
  author = {Shao, Jun},
  editor = {Casella, G. and Fienberg, S. and Olkin, I.}
}

@article{shapleyStochasticGames1953,
  title = {Stochastic {{Games}}},
  year = {1953},
  month = oct,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {39},
  number = {10},
  pages = {1095--1100},
  publisher = {Proceedings of the National Academy of Sciences},
  doi = {10.1073/pnas.39.10.1095},
  url = {https://www.pnas.org/doi/10.1073/pnas.39.10.1095},
  urldate = {2025-02-15},
  file = {/Users/lhydave/Zotero/storage/G8HCM9VS/Shapley - 1953 - Stochastic Games.pdf},
  author = {Shapley, L. S.}
}

@book{shiryaevProbability1996,
  title = {Probability},
  year = {1996},
  series = {Graduate {{Texts}} in {{Mathematics}}},
  volume = {95},
  publisher = {Springer},
  address = {New York, NY},
  doi = {10.1007/978-1-4757-2539-1},
  url = {http://link.springer.com/10.1007/978-1-4757-2539-1},
  urldate = {2023-07-10},
  isbn = {978-1-4757-2541-4 978-1-4757-2539-1},
  keywords = {Ergodic theory,Markov chain,Martingale,Probability theory,Random variable,random walk,stochastic process,Stochastic processes},
  author = {Shiryaev, A. N.}
}

@book{siegelBargainingGroupDecision1960,
  title = {Bargaining and Group Decision Making: {{Experiments}} in Bilateral Monopoly},
  shorttitle = {Bargaining and Group Decision Making},
  year = {1960},
  series = {Bargaining and Group Decision Making: {{Experiments}} in Bilateral Monopoly},
  pages = {132},
  publisher = {McGraw-Hill},
  address = {New York, NY, US},
  abstract = {Most economic models about bilateral monopoly (1 seller sells 1 product to 1 buyer) predict that the amount sold will be determinate at the amount which maximizes joint payoff, but that the price will be indeterminate. Pairs of Ss bargained over prices and quantities of a hypothetical commodity with real payoffs contingent on success in bargaining. The theoretical prediction was confirmed. In spite of severe restrictions on communication, most Ss arrived at prices which produced a 50-50 division of the maximum joint payoff. Variance of prices was reduced as information increased. The member of a bargaining pair with more information was at a disadvantage, because he arrived more quickly at the equitable offer and so was handicapped in subsequent bargaining. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  file = {/Users/lhydave/Zotero/storage/2EELTQLM/1961-01746-000.html},
  author = {Siegel, Sidney and Fouraker, Lawrence E.}
}

@article{silverMasteringGameGo2016,
  title = {Mastering the Game of {{Go}} with Deep Neural Networks and Tree Search},
  year = {2016},
  month = jan,
  journal = {Nature},
  volume = {529},
  number = {7587},
  pages = {484--489},
  issn = {0028-0836, 1476-4687},
  doi = {10.1038/nature16961},
  url = {https://www.nature.com/articles/nature16961},
  urldate = {2023-09-04},
  langid = {english},
  keywords = {/unread},
  file = {/Users/lhydave/Zotero/storage/UZD7H74E/Silver et al. - 2016 - Mastering the game of Go with deep neural networks and tree search.pdf},
  author = {Silver, David and Huang, Aja and Maddison, Chris J. and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and Dieleman, Sander and Grewe, Dominik and Nham, John and Kalchbrenner, Nal and Sutskever, Ilya and Lillicrap, Timothy and Leach, Madeleine and Kavukcuoglu, Koray and Graepel, Thore and Hassabis, Demis}
}

@article{silverMasteringGameGo2017,
  title = {Mastering the Game of {{Go}} without Human Knowledge},
  year = {2017},
  month = oct,
  journal = {Nature},
  volume = {550},
  number = {7676},
  pages = {354--359},
  issn = {0028-0836, 1476-4687},
  doi = {10.1038/nature24270},
  url = {https://www.nature.com/articles/nature24270},
  urldate = {2023-09-04},
  langid = {english},
  keywords = {/unread},
  file = {/Users/lhydave/Zotero/storage/3JN73HCQ/Silver et al. - 2017 - Mastering the game of Go without human knowledge.pdf},
  author = {Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and Chen, Yutian and Lillicrap, Timothy and Hui, Fan and Sifre, Laurent and Van Den Driessche, George and Graepel, Thore and Hassabis, Demis}
}

@article{simonInformationprocessingModelsCognition1981,
  title = {Information-Processing Models of Cognition},
  year = {1981},
  journal = {Journal of the American Society for Information Science},
  volume = {32},
  number = {5},
  pages = {364--377},
  issn = {1097-4571},
  doi = {10.1002/asi.4630320517},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/asi.4630320517},
  urldate = {2025-02-13},
  abstract = {This article reviews recent progress in modeling human cognitive processes. Particular attention is paid to the use of computer programming languages as a formalism for modeling, and to computer simulation of the behavior of the systems modeled. Theories of human cognitive processes can be attempted at several levels: at the level of neural processes, at the level of elementary information processes (e.g., retrieval from memory, scanning down lists in memory, comparing simple symbols, etc.), or at the level of higher mental processes (e.g., problem solving, concept attainment). This article will not deal at all with neural models; it focuses mainly upon higher mental processes, but not without some attention to modeling the elementary processes and especially to the relationships between elementary and complex processes.},
  copyright = {Copyright © 1981 Wiley Periodicals, Inc., A Wiley Company},
  langid = {english},
  file = {/Users/lhydave/Zotero/storage/WI5P6VSV/Simon - 1981 - Information-processing models of cognition.pdf;/Users/lhydave/Zotero/storage/6G76MRB5/asi.html},
  author = {Simon, Herbert A.}
}

@article{simpsonInterpretationInteractionContingency1951,
  title = {The {{Interpretation}} of {{Interaction}} in {{Contingency Tables}}},
  year = {1951},
  journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
  volume = {13},
  number = {2},
  eprint = {2984065},
  eprinttype = {jstor},
  pages = {238--241},
  publisher = {[Royal Statistical Society, Oxford University Press]},
  issn = {0035-9246},
  url = {https://www.jstor.org/stable/2984065},
  urldate = {2025-02-13},
  abstract = {The definition of second order interaction in a (2 × 2 × 2) table given by Bartlett is accepted, but it is shown by an example that the vanishing of this second order interaction does not necessarily justify the mechanical procedure of forming the three component 2 × 2 tables and testing each of these for significance by standard methods.},
  file = {/Users/lhydave/Zotero/storage/WGELRZ9V/Simpson - 1951 - The Interpretation of Interaction in Contingency Tables.pdf},
  author = {Simpson, E. H.}
}

@book{skyrmsChoiceChanceIntroduction1975,
  title = {Choice and Chance : An Introduction to Inductive Logic},
  shorttitle = {Choice and Chance},
  year = {1975},
  publisher = {Encino, Calif. : Dickenson Pub. Co.},
  url = {http://archive.org/details/choicechanceintr0000skyr},
  urldate = {2025-02-13},
  abstract = {220 pages : 23 cm; Includes bibliographical references and index; I: Probability and induction -- Arguments -- Logic -- Inductive versus deductive logic -- The general and the specific -- Epistemic probability -- Probability and the problems of inductive logic -- II: The traditional problem of induction -- Hume's argument -- The inductive justification of induction -- The pragmatic justification of induction -- An attempted dissolution of the traditional problem of induction -- III: The Goodman paradox and the new riddle of induction -- Regularities and projection -- The Goodman paradox -- The Goodman paradox, regularity, and the principle of the uniformity of nature -- IV: Mill's methods of experimental inquiry and the nature of causality -- The structure of simple statements -- The structure of complex statements -- Simple and complex properties -- Causality and necessary and sufficient conditions -- Mill's methods -- The direct method of agreement -- The inverse method of agreement -- The method of difference -- The combined methods -- The application of Mill's methods -- Sufficient conditions and functional relationships -- Lawlike and accidental conditions -- V: The probability calculus -- Probability, arguments, statements, and properties -- Disjunction and negation rules -- Conjunction rules and conditional probability -- Expected value of a gamble -- Rational decision making and probability as a guide to life -- Bayes' theorem},
  isbn = {978-0-8221-0134-5},
  langid = {english},
  keywords = {Induction (Logic)},
  author = {Skyrms, Brian},
  collaborator = {{Internet Archive}}
}

@inproceedings{sohl-dicksteinDeepUnsupervisedLearning2015,
  title = {Deep {{Unsupervised Learning}} Using {{Nonequilibrium Thermodynamics}}},
  booktitle = {Proceedings of the 32nd {{International Conference}} on {{Machine Learning}}},
  year = {2015},
  month = jun,
  pages = {2256--2265},
  publisher = {PMLR},
  issn = {1938-7228},
  url = {https://proceedings.mlr.press/v37/sohl-dickstein15.html},
  urldate = {2025-02-13},
  abstract = {A central problem in machine learning involves modeling complex data-sets using highly flexible families of probability distributions in which learning, sampling, inference, and evaluation are still analytically or computationally tractable. Here, we develop an approach that simultaneously achieves both flexibility and tractability. The essential idea, inspired by non-equilibrium statistical physics, is to systematically and slowly destroy structure in a data distribution through an iterative forward diffusion process. We then learn a reverse diffusion process that restores structure in data, yielding a highly flexible and tractable generative model of the data. This approach allows us to rapidly learn, sample from, and evaluate probabilities in deep generative models with thousands of layers or time steps, as well as to compute conditional and posterior probabilities under the learned model. We additionally release an open source reference implementation of the algorithm.},
  langid = {english},
  file = {/Users/lhydave/Zotero/storage/5SP4JQTK/Sohl-Dickstein 等 - 2015 - Deep Unsupervised Learning using Nonequilibrium Thermodynamics.pdf},
  author = {{Sohl-Dickstein}, Jascha and Weiss, Eric and Maheswaranathan, Niru and Ganguli, Surya}
}

@incollection{songGenerativeModelingEstimating2019,
  title = {Generative Modeling by Estimating Gradients of the Data Distribution},
  booktitle = {Proceedings of the 33rd {{International Conference}} on {{Neural Information Processing Systems}}},
  year = {2019},
  month = dec,
  number = {1067},
  pages = {11918--11930},
  publisher = {Curran Associates Inc.},
  address = {Red Hook, NY, USA},
  urldate = {2025-02-13},
  abstract = {We introduce a new generative model where samples are produced via Langevin dynamics using gradients of the data distribution estimated with score matching. Because gradients can be ill-defined and hard to estimate when the data resides on low-dimensional manifolds, we perturb the data with different levels of Gaussian noise, and jointly estimate the corresponding scores, i.e., the vector fields of gradients of the perturbed data distribution for all noise levels. For sampling, we propose an annealed Langevin dynamics where we use gradients corresponding to gradually decreasing noise levels as the sampling process gets closer to the data manifold. Our framework allows flexible model architectures, requires no sampling during training or the use of adversarial methods, and provides a learning objective that can be used for principled model comparisons. Our models produce samples comparable to GANs on MNIST, CelebA and CIFAR-10 datasets, achieving a new state-of-the-art inception score of 8.87 on CIFAR-10. Additionally, we demonstrate that our models learn effective representations via image inpainting experiments.},
  file = {/Users/lhydave/Zotero/storage/VYC75GNH/Song和Ermon - 2019 - Generative modeling by estimating gradients of the data distribution.pdf},
  author = {Song, Yang and Ermon, Stefano}
}

@article{spiegelhalterWhyProbabilityProbably2024,
  title = {Why Probability Probably Doesn’t Exist (but It Is Useful to Act like It Does)},
  year = {2024},
  month = dec,
  journal = {Nature},
  volume = {636},
  number = {8043},
  pages = {560--563},
  publisher = {Nature Publishing Group},
  issn = {1476-4687},
  doi = {10.1038/d41586-024-04096-5},
  url = {https://www.nature.com/articles/d41586-024-04096-5},
  urldate = {2025-02-13},
  abstract = {All of statistics and much of science depends on probability — an astonishing achievement, considering no one’s really sure what it is.},
  copyright = {2024 Springer Nature Limited},
  langid = {english},
  keywords = {History,Mathematics and computing,Society},
  annotation = {Bandiera\_abtest: a\\
Cg\_type: Essay\\
Subject\_term: Mathematics and computing, History, Society},
  file = {/Users/lhydave/Zotero/storage/TZBCJRWR/Spiegelhalter - 2024 - Why probability probably doesn’t exist (but it is useful to act like it does).pdf;/Users/lhydave/Zotero/storage/URYL4ULK/d41586-024-04096-5.html},
  author = {Spiegelhalter, David}
}

@book{steinFunctionalAnalysisIntroduction2011,
  title = {Functional {{Analysis}}: {{Introduction}} to {{Further Topics}} in {{Analysis}}},
  shorttitle = {Functional {{Analysis}}},
  year = {2011},
  month = sep,
  publisher = {Princeton University Press},
  address = {Princeton},
  abstract = {This is the fourth and final volume in the Princeton Lectures in Analysis, a series of textbooks that aim to present, in an integrated manner, the core areas of analysis. Beginning with the basic facts of functional analysis, this volume looks at Banach spaces, Lp spaces, and distribution theory, and highlights their roles in harmonic analysis. The authors then use the Baire category theorem to illustrate several points, including the existence of Besicovitch sets. The second half of the book introduces readers to other central topics in analysis, such as probability theory and Brownian motion, which culminates in the solution of Dirichlet's problem. The concluding chapters explore several complex variables and oscillatory integrals in Fourier analysis, and illustrate applications to such diverse areas as nonlinear dispersion equations and the problem of counting lattice points. Throughout the book, the authors focus on key results in each area and stress the organic unity of the subject. A comprehensive and authoritative text that treats some of the main topics of modern analysis  A look at basic functional analysis and its applications in harmonic analysis, probability theory, and several complex variables  Key results in each area discussed in relation to other areas of mathematics  Highlights the organic unity of large areas of analysis traditionally split into subfields  Interesting exercises and problems illustrate ideas  Clear proofs provided},
  isbn = {978-0-691-11387-6},
  langid = {english},
  author = {Stein, Elias M. and Shakarchi, Rami}
}

@incollection{steinInadmissibilityUsualEstimator1956,
  title = {Inadmissibility of the {{Usual Estimator}} for the {{Mean}} of a {{Multivariate Normal Distribution}}},
  booktitle = {Proceedings of the {{Third Berkeley Symposium}} on {{Mathematical Statistics}} and {{Probability}}, {{Volume}} 1: {{Contributions}} to the {{Theory}} of {{Statistics}}},
  year = {1956},
  month = jan,
  volume = {3.1},
  pages = {197--207},
  publisher = {University of California Press},
  url = {https://projecteuclid.org/ebooks/berkeley-symposium-on-mathematical-statistics-and-probability/Proceedings-of-the-Third-Berkeley-Symposium-on-Mathematical-Statistics-and/chapter/Inadmissibility-of-the-Usual-Estimator-for-the-Mean-of-a/bsmsp/1200501656},
  urldate = {2025-02-14},
  file = {/Users/lhydave/Zotero/storage/2482GTRM/Stein - 1956 - Inadmissibility of the Usual Estimator for the Mean of a Multivariate Normal Distribution.pdf},
  author = {Stein, Charles}
}

@book{steinRealAnalysisMeasure2005,
  title = {Real {{Analysis}}: {{Measure Theory}}, {{Integration}}, and {{Hilbert Spaces}}},
  shorttitle = {Real {{Analysis}}},
  year = {2005},
  month = apr,
  edition = {First Edition},
  publisher = {Princeton University Press},
  address = {Princeton (N.J.)},
  abstract = {Real Analysis is the third volume in the Princeton Lectures in Analysis, a series of four textbooks that aim to present, in an integrated manner, the core areas of analysis. Here the focus is on the development of measure and integration theory, differentiation and integration, Hilbert spaces, and Hausdorff measure and fractals. This book reflects the objective of the series as a whole: to make plain the organic unity that exists between the various parts of the subject, and to illustrate the wide applicability of ideas of analysis to other fields of mathematics and science. After setting forth the basic facts of measure theory, Lebesgue integration, and differentiation on Euclidian spaces, the authors move to the elements of Hilbert space, via the L2 theory. They next present basic illustrations of these concepts from Fourier analysis, partial differential equations, and complex analysis. The final part of the book introduces the reader to the fascinating subject of fractional-dimensional sets, including Hausdorff measure, self-replicating sets, space-filling curves, and Besicovitch sets. Each chapter has a series of exercises, from the relatively easy to the more complex, that are tied directly to the text. A substantial number of hints encourage the reader to take on even the more challenging exercises. As with the other volumes in the series, Real Analysis is accessible to students interested in such diverse disciplines as mathematics, physics, engineering, and finance, at both the undergraduate and graduate levels. Also available, the first two volumes in the Princeton Lectures in Analysis:},
  isbn = {978-0-691-11386-9},
  langid = {english},
  author = {Stein, Elias M. and Shakarchi, Rami}
}

@inproceedings{suDifferentiallyPrivateKMeans2016,
  title = {Differentially {{Private K-Means Clustering}}},
  booktitle = {Proceedings of the {{Sixth ACM Conference}} on {{Data}} and {{Application Security}} and {{Privacy}}},
  year = {2016},
  month = mar,
  pages = {26--37},
  publisher = {ACM},
  address = {New Orleans Louisiana USA},
  doi = {10.1145/2857705.2857708},
  url = {https://dl.acm.org/doi/10.1145/2857705.2857708},
  urldate = {2025-02-14},
  isbn = {978-1-4503-3935-3},
  langid = {english},
  file = {/Users/lhydave/Zotero/storage/TMIGDYZM/Su 等 - 2016 - Differentially Private K-Means Clustering.pdf},
  author = {Su, Dong and Cao, Jianneng and Li, Ninghui and Bertino, Elisa and Jin, Hongxia}
}

@misc{SuRangRenLiangTanDeJohnsonLindenstraussYinLiLiLunPian,
  title = {{让人惊叹的Johnson-Lindenstrauss引理：理论篇}},
  url = {https://kexue.fm/archives/8679},
  urldate = {2025-02-14},
  abstract = {通过必应的智能搜索，可以更轻松地快速查找所需内容并获得奖励。},
  langid = {chinese},
  file = {/Users/lhydave/Zotero/storage/EIDR7JWJ/search.html},
  note = {(accessed 2025-02-14)},
  howpublished = {\url{https://kexue.fm/archives/8679}},
  author = {苏, 剑林}
}

@misc{SuRangRenLiangTanDeJohnsonLindenstraussYinLiYingYongPian,
  title = {{{让人惊叹的Johnson-Lindenstrauss引理}}：应用篇},
  url = {https://kexue.fm/archives/8706},
  urldate = {2025-02-14},
  file = {/Users/lhydave/Zotero/storage/AP4N5TYB/8706.html},
  note = {(accessed 2025-02-14)},
  howpublished = {\url{https://kexue.fm/archives/8706}},
  author = {苏, 剑林}
}

@book{suttonReinforcementLearningIntroduction2018,
  title = {Reinforcement Learning: An Introduction},
  shorttitle = {Reinforcement Learning},
  year = {2018},
  series = {Adaptive Computation and Machine Learning Series},
  edition = {Second edition},
  publisher = {The MIT Press},
  address = {Cambridge, Massachusetts},
  abstract = {"Reinforcement learning, one of the most active research areas in artificial intelligence, is a computational approach to learning whereby an agent tries to maximize the total amount of reward it receives while interacting with a complex, uncertain environment. In Reinforcement Learning, Richard Sutton and Andrew Barto provide a clear and simple account of the field's key ideas and algorithms."--},
  isbn = {978-0-262-03924-6},
  langid = {english},
  lccn = {Q325.6 .R45 2018},
  keywords = {/unread,Reinforcement learning},
  author = {Sutton, Richard S. and Barto, Andrew G.}
}

@misc{SuZuiXiaoShangYuanLiLiuCiXiangLiangDeWeiDuYingGaiZenMeXuanZe,
  title = {最小熵原理（六）：词向量的维度应该怎么选择？},
  url = {https://kexue.fm/archives/7695},
  urldate = {2025-02-14},
  file = {/Users/lhydave/Zotero/storage/LM55P7SM/7695.html},
  note = {(accessed 2025-02-14)},
  howpublished = {\url{https://kexue.fm/archives/7695}},
  author = {苏, 剑林}
}

@misc{taoHahnBanachTheoremMengers2007,
  title = {The {{Hahn-Banach}} Theorem, {{Menger}}’s Theorem, and {{Helly}}’s Theorem},
  year = {2007},
  month = dec,
  journal = {What's new},
  url = {https://terrytao.wordpress.com/2007/11/30/the-hahn-banach-theorem-mengers-theorem-and-hellys-theorem/},
  urldate = {2025-02-15},
  abstract = {In the previous post, I discussed how an induction on dimension approach could establish Hilbert’s nullstellensatz, which we interpreted as a result describing all the obstructions to solving…},
  langid = {english},
  file = {/Users/lhydave/Zotero/storage/KD2AC8HQ/the-hahn-banach-theorem-mengers-theorem-and-hellys-theorem.html},
  author = {Tao, Terence}
}

@article{tingAmountInformation1962,
  title = {On the {{Amount}} of {{Information}}},
  year = {1962},
  month = jan,
  journal = {Theory of Probability \& Its Applications},
  volume = {7},
  number = {4},
  pages = {439--447},
  publisher = {{Society for Industrial and Applied Mathematics}},
  issn = {0040-585X},
  doi = {10.1137/1107041},
  url = {https://epubs.siam.org/doi/abs/10.1137/1107041},
  urldate = {2023-07-09},
  abstract = {In this paper it is proved that the condition on the information stability of a sequence of channels is not only sufficient, but also necessary for the validity of Feinstein’s lemma and Shannon’s theorem.},
  author = {Ting, Hu Kuo}
}

@book{tolmanPrinciplesStatisticalMechanics2010,
  title = {The {{Principles}} of {{Statistical Mechanics}}},
  year = {2010},
  publisher = {Dover Publications},
  address = {New York, NY},
  abstract = {Referred to by every later author, used by thousands of students in the over forty years since publication, and recommended with great enthusiasm by those same students who are now professors, The Principles of Statistical Mechanics is widely recognized as the classic treatment of a subject essential to contemporary physics. It is the definitive treatise on the fundamentals of statistical mechanics, and because it deals with the fundamentals, the material is as useful today as forty years ago.After a brief introduction, the text begins with a concise exposition of classical statistical mechanics, including such topics as Hamilton's principle, the Lagrangian function, canonical equations of motion, the fundamental theorem of Liouville, conditions for statistical equilibrium, the Maxwell-Boltzmann distribution law, collisions as a mechanism of change with time, and Boltzmann's H-theorem. There follows a thorough elucidation of quantum statistical mechanics: historical remarks, the postulates, theorems illustrating the nature of quantum mechanics, transformation theory, applications, statistical ensembles, the Maxwell-Boltzmann, Einstein-Bose, and Fermi-Dirac distributions, the change in quantum mechanical systems with time, and the quantum mechanical H-theorem. (The self-contained treatment of quantum mechanics is almost a book within a book!) The final two chapters, illuminating one of the greatest achievements of physics, discuss the application of statistical mechanics to the problem of obtaining a mechanical explanation for the phenomena of thermodynamic behavior.Professor Richard C. Tolman was a distinguished physicist who taught at the California Institute of Technology. In the course of preparing this book he consulted with many eminent colleagues including Pauling, Fowler, and Pauli, and he discussed all parts of the book with J. Robert Oppenheimer. Scholars interested in the history of science can readily appreciate the importance of this book; but since it is so totally authoritative, and so elegantly written, every student and professor of statistical mechanics will find it equally valuable.},
  isbn = {978-0-486-63896-6},
  author = {Tolman, Richard C.}
}

@book{tomaselloEvolutionAgency2022,
  title = {The {{Evolution}} of {{Agency}}},
  year = {2022},
  month = sep,
  publisher = {The MIT Press},
  url = {https://book.douban.com/subject/35852463/},
  urldate = {2025-02-13},
  isbn = {978-0-262-04700-5},
  author = {Tomasello, Michael}
}

@article{tverskyExtensionalIntuitiveReasoning1983,
  title = {Extensional versus Intuitive Reasoning: {{The}} Conjunction Fallacy in Probability Judgment},
  shorttitle = {Extensional versus Intuitive Reasoning},
  year = {1983},
  journal = {Psychological Review},
  volume = {90},
  number = {4},
  pages = {293--315},
  publisher = {American Psychological Association},
  address = {US},
  issn = {1939-1471},
  doi = {10.1037/0033-295X.90.4.293},
  abstract = {Perhaps the simplest and the most basic qualitative law of probability is the conjunction rule: The probability of a conjunction, P(A\&B), cannot exceed the probabilities of its constituents, P(A) and P(B), because the extension (or the possibility set) of the conjunction is included in the extension of its constituents. Judgments under uncertainty, however, are often mediated by intuitive heuristics that are not bound by the conjunction rule. A conjunction can be more representative that one of its constituents, and instances of a specific category can be easier to imagine or to retrieve than instances of a more inclusive category. The representativeness and availability heuristics therefore can make a conjunction appear more probable than one of its constituents. This phenomenon is demonstrated in a variety of contexts, including estimation of word frequency, personality judgment, medical prognosis, decision under risk, suspicion of criminal acts, and political forecasting. Systematic violations of the conjunction rule are observed in judgments of lay people and of experts in both between- and within-Ss comparisons. Alternative interpretations of the conjunction fallacy are discussed, and attempts to combat it are explored. (48 ref) (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Errors,Intuition,Probability Judgment,Reasoning},
  file = {/Users/lhydave/Zotero/storage/SZR59DPN/Tversky和Kahneman - 1983 - Extensional versus intuitive reasoning The conjunction fallacy in probability judgment.pdf;/Users/lhydave/Zotero/storage/7FUUK8IV/1984-03110-001.html},
  author = {Tversky, Amos and Kahneman, Daniel}
}

@article{tverskyJudgmentUncertaintyHeuristics1974,
  title = {Judgment under {{Uncertainty}}: {{Heuristics}} and {{Biases}}},
  shorttitle = {Judgment under {{Uncertainty}}},
  year = {1974},
  month = sep,
  journal = {Science},
  volume = {185},
  number = {4157},
  pages = {1124--1131},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/science.185.4157.1124},
  url = {https://www.science.org/doi/10.1126/science.185.4157.1124},
  urldate = {2025-02-13},
  abstract = {This article described three heuristics that are employed in making judgments under uncertainty: (i) representativeness, which is usually employed when people are asked to judge the probability that an object or event A belongs to class or process B; (ii) availability of instances or scenarios, which is often employed when people are asked to assess the frequency of a class or the plausibility of a particular development; and (iii) adjustment from an anchor, which is usually employed in numerical prediction when a relevant value is available. These heuristics are highly economical and usually effective, but they lead to systematic and predictable errors. A better understanding of these heuristics and of the biases to which they lead could improve judgments and decisions in situations of uncertainty.},
  author = {Tversky, Amos and Kahneman, Daniel}
}

@incollection{uffinkBoltzmannsWorkStatistical2022,
  title = {Boltzmann’s {{Work}} in {{Statistical Physics}}},
  booktitle = {The {{Stanford Encyclopedia}} of {{Philosophy}}},
  year = {2022},
  edition = {Summer 2022},
  publisher = {Metaphysics Research Lab, Stanford University},
  url = {https://plato.stanford.edu/archives/sum2022/entries/statphys-Boltzmann/},
  urldate = {2023-07-10},
  abstract = {Ludwig Boltzmann (1844–1906) is generally acknowledged as one ofthe most important physicists of the nineteenth century. Particularlyfamous is his statistical explanation of the second law ofthermodynamics. The celebrated formula S=klogWS=klog⁡WS = k \textbackslash log W, expressing arelation between entropy SSS and probability WWW has been engravedon his tombstone (even though he never actually wrote this formuladown). Boltzmann's views on statistical physics continue to play animportant role in contemporary debates on the foundations of thattheory.},
  keywords = {Boltzmann Ludwig,Mach Ernst,physics: intertheory relations in,probability interpretations of,statistical physics: philosophy of statistical mechanics},
  author = {Uffink, Jos},
  editor = {Zalta, Edward N.}
}

@misc{UnderstandingSteinsParadox,
  title = {Understanding {{Stein}}'s Paradox},
  journal = {Joe Antognini},
  url = {https://joe-antognini.github.io/machine-learning/steins-paradox},
  urldate = {2025-02-14},
  abstract = {An intuitive explanation of the James-Stein estimator.},
  langid = {english},
  file = {/Users/lhydave/Zotero/storage/YC6TWFU7/steins-paradox.html},
  note = {(accessed 2025-02-14)},
  howpublished = {\url{https://joe-antognini.github.io/machine-learning/steins-paradox}}
}

@book{vandalenLogicStructure2013,
  title = {Logic and {{Structure}}},
  year = {2013},
  series = {Universitext},
  publisher = {Springer},
  address = {London},
  doi = {10.1007/978-1-4471-4558-5},
  url = {https://link.springer.com/10.1007/978-1-4471-4558-5},
  urldate = {2024-03-31},
  copyright = {https://www.springernature.com/gp/researchers/text-and-data-mining},
  isbn = {978-1-4471-4557-8 978-1-4471-4558-5},
  langid = {english},
  keywords = {Basic model theory,First-order logic with natural deduction,Goedel's theorem,Intuitionistic logic and semantics,Normalisation of first-order logic,Recursive functions,Second order logic},
  author = {Van Dalen, Dirk}
}

@inproceedings{vapnikSupportVectorMethod1997,
  title = {The {{Support Vector}} Method},
  booktitle = {Artificial {{Neural Networks}} — {{ICANN}}'97},
  year = {1997},
  pages = {261--271},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/BFb0020166},
  abstract = {The Support Vector (SV) method is a new general method of function estimation which does not depend explicitly on the dimensionality of input space. It was applied for pattern recognition, regression estimation, and density estimation problems as well as for problems of solving linear operator equations. In this article we describe the general idea of the SV method and present theorems demonstrating that the generalization ability of the SV method is based on factors which classical statistics do not take into account. We also describe the SV method for density estimation in a set of functions defined by a mixture of an infinite number of Gaussians.},
  isbn = {978-3-540-69620-9},
  langid = {english},
  keywords = {Generalization Ability,Kernel Representation,Optimal Hyperplane,Pattern Recognition Problem,Support Vector},
  author = {Vapnik, Vladimir N.},
  editor = {Gerstner, Wulfram and Germond, Alain and Hasler, Martin and Nicoud, Jean-Daniel}
}

@book{vershyninHighDimensionalProbabilityIntroduction2018,
  title = {High-{{Dimensional Probability}}: {{An Introduction}} with {{Applications}} in {{Data Science}}},
  shorttitle = {High-{{Dimensional Probability}}},
  year = {2018},
  series = {Cambridge {{Series}} in {{Statistical}} and {{Probabilistic Mathematics}}},
  publisher = {Cambridge University Press},
  address = {Cambridge},
  doi = {10.1017/9781108231596},
  url = {https://www.cambridge.org/core/books/highdimensional-probability/797C466DA29743D2C8213493BD2D2102},
  urldate = {2025-02-14},
  abstract = {High-dimensional probability offers insight into the behavior of random vectors, random matrices, random subspaces, and objects used to quantify uncertainty in high dimensions. Drawing on ideas from probability, analysis, and geometry, it lends itself to applications in mathematics, statistics, theoretical computer science, signal processing, optimization, and more. It is the first to integrate theory, key tools, and modern applications of high-dimensional probability. Concentration inequalities form the core, and it covers both classical results such as Hoeffding's and Chernoff's inequalities and modern developments such as the matrix Bernstein's inequality. It then introduces the powerful methods based on stochastic processes, including such tools as Slepian's, Sudakov's, and Dudley's inequalities, as well as generic chaining and bounds based on VC dimension. A broad range of illustrations is embedded throughout, including classical and modern results for covariance estimation, clustering, networks, semidefinite programming, coding, dimension reduction, matrix completion, machine learning, compressed sensing, and sparse regression.},
  isbn = {978-1-108-41519-4},
  author = {Vershynin, Roman}
}

@article{vinyalsGrandmasterLevelStarCraft2019,
  title = {Grandmaster Level in {{StarCraft II}} Using Multi-Agent Reinforcement Learning},
  year = {2019},
  month = nov,
  journal = {Nature},
  volume = {575},
  number = {7782},
  pages = {350--354},
  publisher = {Nature Publishing Group},
  issn = {1476-4687},
  doi = {10.1038/s41586-019-1724-z},
  url = {https://www.nature.com/articles/s41586-019-1724-z},
  urldate = {2023-10-09},
  abstract = {Many real-world applications require artificial agents to compete and coordinate with other agents in complex environments. As a stepping stone to this goal, the domain of StarCraft has emerged as an important challenge for artificial intelligence research, owing to its iconic and enduring status among the most difficult professional esports and its relevance to the real world in terms of its raw complexity and multi-agent challenges. Over the course of a decade and numerous competitions1–3, the strongest agents have simplified important aspects of the game, utilized superhuman capabilities, or employed hand-crafted sub-systems4. Despite these advantages, no previous agent has come close to matching the overall skill of top StarCraft players. We chose to address the challenge of StarCraft using general-purpose learning methods that are in principle applicable to other complex domains: a multi-agent reinforcement learning algorithm that uses data from both human and agent games within a diverse league of continually adapting strategies and counter-strategies, each represented by deep neural networks5,6. We evaluated our agent, AlphaStar, in the full game of StarCraft II, through a series of online games against human players. AlphaStar was rated at Grandmaster level for all three StarCraft races and above 99.8\% of officially ranked human players.},
  copyright = {2019 The Author(s), under exclusive licence to Springer Nature Limited},
  langid = {english},
  keywords = {/unread,Computer science,Statistics},
  file = {/Users/lhydave/Zotero/storage/D2Y3CJFY/Vinyals et al. - 2019 - Grandmaster level in StarCraft II using multi-agent reinforcement learning.pdf},
  author = {Vinyals, Oriol and Babuschkin, Igor and Czarnecki, Wojciech M. and Mathieu, Michaël and Dudzik, Andrew and Chung, Junyoung and Choi, David H. and Powell, Richard and Ewalds, Timo and Georgiev, Petko and Oh, Junhyuk and Horgan, Dan and Kroiss, Manuel and Danihelka, Ivo and Huang, Aja and Sifre, Laurent and Cai, Trevor and Agapiou, John P. and Jaderberg, Max and others}
}

@article{viterbiErrorBoundsConvolutional1967,
  title = {Error Bounds for Convolutional Codes and an Asymptotically Optimum Decoding Algorithm},
  year = {1967},
  month = apr,
  journal = {IEEE Transactions on Information Theory},
  volume = {13},
  number = {2},
  pages = {260--269},
  issn = {1557-9654},
  doi = {10.1109/TIT.1967.1054010},
  url = {https://ieeexplore.ieee.org/document/1054010},
  urldate = {2025-02-13},
  abstract = {The probability of error in decoding an optimal convolutional code transmitted over a memoryless channel is bounded from above and below as a function of the constraint length of the code. For all but pathological channels the bounds are asymptotically (exponentially) tight for rates aboveR\_0, the computational cutoff rate of sequential decoding. As a function of constraint length the performance of optimal convolutional codes is shown to be superior to that of block codes of the same length, the relative improvement increasing with rate. The upper bound is obtained for a specific probabilistic nonsequential decoding algorithm which is shown to be asymptotically optimum for rates aboveR\_0and whose performance bears certain similarities to that of sequential decoding algorithms.},
  file = {/Users/lhydave/Zotero/storage/Z3SECMI9/Viterbi - 1967 - Error bounds for convolutional codes and an asymptotically optimum decoding algorithm.pdf;/Users/lhydave/Zotero/storage/L2CEGKIW/1054010.html},
  author = {Viterbi, A.}
}

@article{vongGroundedLanguageAcquisition2024,
  title = {Grounded Language Acquisition through the Eyes and Ears of a Single Child},
  year = {2024},
  month = feb,
  journal = {Science},
  volume = {383},
  number = {6682},
  pages = {504--511},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/science.adi1374},
  url = {https://www.science.org/doi/10.1126/science.adi1374},
  urldate = {2025-02-13},
  abstract = {Starting around 6 to 9 months of age, children begin acquiring their first words, linking spoken words to their visual counterparts. How much of this knowledge is learnable from sensory input with relatively generic learning mechanisms, and how much requires stronger inductive biases? Using longitudinal head-mounted camera recordings from one child aged 6 to 25 months, we trained a relatively generic neural network on 61 hours of correlated visual-linguistic data streams, learning feature-based representations and cross-modal associations. Our model acquires many word-referent mappings present in the child’s everyday experience, enables zero-shot generalization to new visual referents, and aligns its visual and linguistic conceptual systems. These results show how critical aspects of grounded word meaning are learnable through joint representation and associative learning from one child’s input.},
  file = {/Users/lhydave/Zotero/storage/VSBVMA84/Vong 等 - 2024 - Grounded language acquisition through the eyes and ears of a single child.pdf},
  author = {Vong, Wai Keen and Wang, Wentao and Orhan, A. Emin and Lake, Brenden M.}
}

@incollection{vonneumannTheoryGamesEconomic2007,
  title = {Theory of Games and Economic Behavior},
  booktitle = {Theory of Games and Economic Behavior},
  year = {2007},
  publisher = {Princeton university press},
  author = {Von Neumann, John and Morgenstern, Oskar}
}

@article{walkComparativeAnalyticalStudy1961,
  title = {A Comparative and Analytical Study of Visual Depth Perception},
  year = {1961},
  journal = {Psychological Monographs: General and Applied},
  volume = {75},
  number = {15},
  pages = {1--44},
  publisher = {American Psychological Association},
  address = {US},
  issn = {0096-9753},
  doi = {10.1037/h0093827},
  abstract = {The experiments which have been described made use of an optical testing situation which permitted comparative studies, and which allowed the same essential stimulus variables to be applied to a number of different animals. The apparatus designed for the present experiments, which we named the "visual cliff," uses the principle of a drop-off or graduated heights, but gives the animal a choice between a short drop-off on one side of a center board and a long drop-off on the other side. All of the animals studied gave some evidence of discriminating depth at an edge. Even the aquatic turtles tended in general to avoid the deep side, though the preference was not as pronounced as in the other species tested, all of which were terrestrial. The discrimination of depth may be less important for some species than for others, and also less acute in some species than in others. The results in general support a hypothesis of innate depth perception, though the presence of a certain kind of environment during growth may be important for late maturing animals. Furthermore, it has been shown that innate mechanisms for discriminating depth may be supplemented by the acquisition of a learned cue. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Animals,Depth Perception,Stimulus Variability,Visual Perception},
  file = {/Users/lhydave/Zotero/storage/7J2XZ9B7/2011-17803-001.html},
  author = {Walk, Richard D. and Gibson, Eleanor J.}
}

@article{warnerRandomizedResponseSurvey1965,
  title = {Randomized {{Response}}: {{A Survey Technique}} for {{Eliminating Evasive Answer Bias}}},
  shorttitle = {Randomized {{Response}}},
  year = {1965},
  month = mar,
  journal = {Journal of the American Statistical Association},
  volume = {60},
  number = {309},
  pages = {63--69},
  publisher = {ASA Website},
  issn = {0162-1459},
  doi = {10.1080/01621459.1965.10480775},
  url = {https://www.tandfonline.com/doi/abs/10.1080/01621459.1965.10480775},
  urldate = {2025-02-14},
  abstract = {For various reasons individuals in a sample survey may prefer not to confide to the interviewer the correct answers to certain questions. In such cases the individuals may elect not to reply at all or to reply with incorrect answers. The resulting evasive answer bias is ordinarily difficult to assess. In this paper it is argued that such bias is potentially removable through allowing the interviewee to maintain privacy through the device of randomizing his response. A randomized response method for estimating a population proportion is presented as an example. Unbiased maximum likelihood estimates are obtained and their mean square errors are compared with the mean square errors of conventional estimates under various assumptions about the underlying population.},
  pmid = {12261830},
  author = {Warner, Stanley L.}
}

@phdthesis{watkinsLearningDelayedRewards1989,
  title = {Learning from Delayed Rewards},
  year = {1989},
  url = {https://www.academia.edu/download/50360235/Learning_from_delayed_rewards_20161116-28282-v2pwvq.pdf},
  urldate = {2025-02-13},
  school = {King's College, Cambridge United Kingdom},
  file = {/Users/lhydave/Zotero/storage/U9KZYRX4/Watkins - 1989 - Learning from delayed rewards.pdf},
  author = {Watkins, Christopher John Cornish Hellaby}
}

@article{wolpertNoFreeLunch1997,
  title = {No Free Lunch Theorems for Optimization},
  year = {1997},
  month = apr,
  journal = {IEEE Transactions on Evolutionary Computation},
  volume = {1},
  number = {1},
  pages = {67--82},
  issn = {1941-0026},
  doi = {10.1109/4235.585893},
  url = {https://ieeexplore.ieee.org/document/585893},
  urldate = {2025-02-14},
  abstract = {A framework is developed to explore the connection between effective optimization algorithms and the problems they are solving. A number of "no free lunch" (NFL) theorems are presented which establish that for any algorithm, any elevated performance over one class of problems is offset by performance over another class. These theorems result in a geometric interpretation of what it means for an algorithm to be well suited to an optimization problem. Applications of the NFL theorems to information-theoretic aspects of optimization and benchmark measures of performance are also presented. Other issues addressed include time-varying optimization problems and a priori "head-to-head" minimax distinctions between optimization algorithms, distinctions that result despite the NFL theorems' enforcing of a type of uniformity over all algorithms.},
  keywords = {Algorithm design and analysis,Bayesian methods,Evolutionary computation,Information theory,Iron,Minimax techniques,Performance analysis,Probability distribution,Simulated annealing},
  file = {/Users/lhydave/Zotero/storage/Y5SZ3GK6/Wolpert和Macready - 1997 - No free lunch theorems for optimization.pdf;/Users/lhydave/Zotero/storage/8BJ6CVJW/585893.html},
  author = {Wolpert, D.H. and Macready, W.G.}
}

@inproceedings{zermeloUberAnwendungMengenlehre1913,
  title = {Über Eine {{Anwendung}} Der {{Mengenlehre}} Auf Die {{Theorie}} Des {{Schachspiels}}},
  booktitle = {Proceedings of the Fifth International Congress of Mathematicians},
  year = {1913},
  volume = {2},
  pages = {501--504},
  publisher = {Cambridge University Press Cambridge},
  author = {Zermelo, Ernst}
}

@book{zorichMathematicalAnalysis2015,
  title = {Mathematical {{Analysis I}}},
  year = {2015},
  series = {Universitext},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-662-48792-1},
  url = {http://link.springer.com/10.1007/978-3-662-48792-1},
  urldate = {2025-02-14},
  copyright = {http://www.springer.com/tdm},
  isbn = {978-3-662-48790-7 978-3-662-48792-1},
  keywords = {calculus,differential equations,functions,integral calculus,limits,real numbers},
  file = {/Users/lhydave/Zotero/storage/DJX3WQZD/Zorich - 2015 - Mathematical Analysis I.pdf},
  author = {Zorich, Vladimir A.}
}

@book{zorichMathematicalAnalysisII2016,
  title = {Mathematical {{Analysis II}}},
  year = {2016},
  series = {Universitext},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-662-48993-2},
  url = {http://link.springer.com/10.1007/978-3-662-48993-2},
  urldate = {2025-02-14},
  copyright = {http://www.springer.com/tdm},
  isbn = {978-3-662-48991-8 978-3-662-48993-2},
  keywords = {calculus,differential equations,functions,integral calculus,limits,real numbers},
  file = {/Users/lhydave/Zotero/storage/A6UVENT2/Zorich - 2016 - Mathematical Analysis II.pdf},
  author = {Zorich, Vladimir A.}
}
