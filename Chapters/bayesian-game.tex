\chapter{共同知识，Bayes博弈，Aumann知识算子}\label{chap:bayesian-game}

真实世界是一个巨大的游戏，参与者之间的信息不对称是一个普遍存在的现象，这些不对称往往形成了“丛林法则”。“丛林法则”从来不是一个书面的规则。刚来美国旅游的人可能会非常担心自己被抢劫；然而，“盗亦有道”，绝大部分时候，抢劫犯只会抢二十美元，以便吃一顿饭。如果坏了规矩，反而会被惩罚。

我们可以考虑一个看似非常疯狂的想法：既然有丛林法则，何不把“一次抢劫最多二十美元”写入法律，这会有什么区别呢？抛开道德和法律的问题，这样做似乎不无道理。

1982年，经济学家Alvin E. Roth和J. Keith Murnighan对讨价还价这一经典的市场博弈现象进行了同样的实验。实验中，有两个玩家，他们可能会收到特定价值的奖品，每个玩家的奖品价值可以不同。然而玩家并不总是能获得奖品，他有一个概率获得这一奖品。他们需要在规定的时间内就他们各自获得奖品的概率进行讨价还价。

具体来说，玩家其实在商讨如何分配一张100\%概率的“彩票券”，这个券决定了每个玩家赢得奖品的概率。例如，甲如果获得40\%的彩票券，就有40\%的概率赢得奖品，60\%的概率一无所获；而乙则完全相反，有60\%的概率赢得奖品，40\%的概率一无所获。

然而，如果在规定时间内未能达成协议，那么所有玩家都将一无所获。因此，只有在双方就彩票券的分配达成了协议，并且该玩家在随后的抽奖中中奖时，玩家才能获得相应的奖品。否则，他将得不到任何奖励。我们将这种每个玩家只有两种可能金钱收益的游戏称为“二元彩票游戏”。

在实际的实验中，玩家甲的奖品价值20美元，玩家乙的奖品价值为5美元，谈判时间限制为12分钟。在实验开始前，实验人员会公开告知甲乙完整的游戏规则，包括奖品价值和谈判时间限制。实验人员还会公开告知甲乙关于他们私有信息的情况，例如，
\begin{quotation}
    “在游戏开始后，你们奖品的价值会被告诉对方。”

    “在游戏开始后，甲的奖品价值会被告诉乙，但乙的不会被告诉甲。”
\end{quotation}
实验人员也可以选择不告知这些信息。

实验开始后，实验人员会告知甲乙他们各自的奖品价值，并且选择性地告知甲（或乙）乙（或甲）的奖品价值，这些信息要和实验开始前的信息保持一致。然后，甲乙开始商讨如何分配彩票券。如果在规定时间内达成了协议，那么他们将按照协议分配彩票券。如果未能达成协议，那么他们将一无所获。

上面的实验设置中，在游戏开始前是否公开宣告双方的信息结构，和上面那个疯狂的想法是一样的。然而，在讨价还价的情景下，我们似乎不会觉得这有什么区别。然而，实验结果却显示，在信息不对称的情况下，双方信息结构的公开宣告会对博弈结果产生显著的影响。

谈判过程展现出了明显的策略性行为。例如，甲（20美元的玩家）通常不会提及自己奖品的价值；但如果游戏开始前宣布过“乙（5美元的玩家）不清楚甲的奖品价值”，20美元的玩家往往会虚报自己的奖品。一个典型的例子是：“我知道你的奖品是5美元。我的只有2美元。所以我应该得到超过50\%的份额。”另一方面，当乙知道甲的奖品价值时，往往会透露信息。这两种策略通常都不被对方相信。

更重要的是，实验结果显示，当实验人员在游戏开始前宣布双方的信息结构时，玩家变得更加没有策略性，博弈的结果很可能没有达到Nash均衡：当只有20美元的玩家知道两个奖品时，其总体平均收益（包括达成协议和未达成协议的情况）为34.9，显著低于5美元玩家的相应收益53.6。

另一方面，当双方的信息结构在游戏开始前不被公开宣告时，玩家表现出更多的策略性。在这种情况下，因为他们不能确定对手是否不知道自己的奖品，所以玩家无法像前一种情况那样自由地谎报自己的奖品价值。然而，因为玩家都不知道对方是否指导双方奖品的价值，所以，如果一个玩家知道两个奖品的价值，他完全可以假装自己只知道自己的奖品价值。由于更复杂的策略性行为，博弈的结果往往达到Nash均衡！

上面的故事告诉我们，信息结构（也就是我们\emph{知道}什么）是否被公开宣告，对于博弈的结果有着重要的影响。实际上，这一问题是一个关于\emph{共同知识}的问题。

在本章，我们将更系统地讨论共同知识，并定义\emph{Bayes博弈}，它是我们研究博弈论中信息结构的基本语言。最后，我们将介绍\emph{Aumann知识算子}，它是从Bayes博弈中起源的，一个关于“知识”的数学模型。


\section{“泥泞的孩童”谜题}

我们先从一个经典的谜题开始。有$n$个孩子在玩泥巴，他们互相泼泥巴. 母亲告诉孩子们，如果他们脸上沾上了泥巴，会受到严厉的惩罚. 孩子们不能看到自己的脸，但是可以看到其他所有人的脸. 所有孩子都希望保持自己的脸干净，但是弄脏别人的脸. 

此时，孩子的父亲出现了，于是，孩子们停止泼泥巴. 孩子们互相不说话. 父亲看到了$k$（$k\geq 1$）个人脸上有泥巴，于是宣布：“\emph{你们至少有一个人脸上沾了泥巴.}” 之后，父亲会公开地问若干轮如下问题： “\emph{你们知道自己脸上有泥巴了吗？}” 孩子们回答“知道”或者“不知道”. 

假设孩子们观察力敏锐、聪慧且诚实，并且每一轮他们都同时回答. 接下来会发生什么？乍一看，似乎大家每次都会回答“不知道”，因为他们不能从这句话知道自己脸上有泥巴. 但是，这个谜题远比想象的要复杂。读者可以先不看后文，先自己试一试。

假设有$k$个孩子脸上有泥巴. 这个问题的谜底是：在前$k-1$轮中，所有孩子都会说“不知道”，在第$k$轮中，所有脸上有泥巴的孩子都会说“知道”. 

这一结论的论证来源于对较小$k$的归纳总结：
\begin{itemize}
    \item 当$k=1$时，脸上沾满泥巴的孩子看到其他人都没有泥巴. 既然他知道至少有一个孩子的脸上有泥巴，他就能推出那个人肯定是他自己. 
    \item 现在假设$k=2$，脸上沾满泥巴的孩子是$a$和$b$. 一开始，因为他们分别看到了对方的脸上有泥巴，所以他们每个人都回答“不知道”. 
    
    但是，当$b$回答“不知道”时，$a$可以代入$b$的角色，意识到$b$看到了$a$脸上有泥巴. 否则，$b$在第一轮中就会知道泥巴在$b$的脸上，并回答“知道”. 因此，$a$在第二轮回答“知道”. $b$也会通过同样的推理得出相同的结论. 

    \item 现在假设$k=3$，脸上沾满泥巴的孩子分别是$a$，$b$和$c$. 孩子$a$的论证如下. 假设我没有泥巴落在脸上. 根据$k=2$的情况，$b$和$c$在第二轮都会回答“是”. 他们没有这样做，我意识到假设是错误的，我的脸上也有泥巴. 因此在第三轮我会回答“知道”. $b$和$c$的论证也是类似的.
\end{itemize}
容易看出，$k=3$的论证具有一般性，对一般的$k$也成立.

\begin{remark}
“泥泞的孩童”还有其他流行的陈述方式，比如“蓝眼睛红眼睛”. 一个岛上有100个人，其中有5个红眼睛，95个蓝眼睛. 这个岛有三个奇怪的宗教规则.
    \begin{enumerate}
        \item 他们不能照镜子，不能看自己眼睛的颜色. 
        \item 他们不能告诉别人对方的眼睛是什么颜色. 
        \item 一旦有人知道了自己的眼睛是红色，他就必须在当天夜里自杀.
    \end{enumerate}
岛民不知道具体有几个红眼睛. 

某天，有个旅行者到了这个岛上. 由于不知道这里的规矩，所以他在和全岛人一起狂欢的时候，一不留神说了一句话：“\emph{你们这里有红眼睛的人. }”假设这个岛上的人足够聪明，每个人都可以做出缜密的逻辑推理. 请问这个岛上将会发生什么？
\end{remark}

谜题就解到这里。然而，一个好的谜题，知道答案之后一定会带来更多的谜题。为什么迷题的答案是这样的呢？比如，如果$k>1$，那么所有人本来就都知道$p$：“至少有一个人脸上有泥巴”. 那么父亲说这句话的意义是什么？

我们可以设想，如果父亲没有说$p$，会发生什么？容易发现，无论父亲问多少轮，所有孩子都只会回答“不知道”！（见习题\lhysays{出一下}）。因此，这里会产生极其反直觉的事实：即便大家都知道$p$，父亲说不说$p$，会导致完全不同的结果. 为什么会这样？

我们重新审视这一问题的过程。
\begin{itemize}
    \item 
    假设$k=2$，脸上沾满泥巴的孩子是$a$和$b$. 在父亲宣布$p$之前，$a$和$b$都知道$p$. 然而，他们并不知道对方知道$p$. $a$可能会有两种想法：
        \begin{itemize}
            \item 我的脸上有泥巴，所以$b$知道$p$.
            \item 我的脸上没有泥巴，$b$是唯一一个有泥巴的，$b$看不到其他人脸上有泥巴，所以$b$不知道$p$.
        \end{itemize}
    当父亲宣布$p$之后，\emph{$a$知道了$b$知道$p$}. 当第一轮$b$回答“不知道”之后，$a$可以用“$b$知道$p$”这一事实排除第二种情况，从而推出自己脸上有泥巴.    
    \item 假设$k=3$，脸上沾满泥巴的孩子是$a$，$b$和$c$. 在父亲宣布$p$之前，$a$，$b$和$c$不仅知道$p$，而且知道彼此知道$p$. 比如说，以$a$的视角看，$b$能看到$c$脸上有泥巴，所以$a$知道$b$知道$p$. 
    
    但是，$a$不知道$b$知道$c$知道$p$，因为此时有两种情况：
    \begin{itemize}
        \item $a$脸上有泥巴，$b$能看到$c$和$a$脸上有泥巴，所以$b$知道$c$能看到$a$脸上有泥巴，从而知道$c$知道$p$.
        \item $a$脸上没有泥巴，$b$能看到$c$脸上有泥巴，$a$脸上没有泥巴，但因为$b$不知道自己脸上有没有泥巴，所以$c$不一定知道$p$，$b$不知道$c$知道$p$.
    \end{itemize}
    更一般地，\emph{$a$，$b$，$c$都不知道所有人知道所有人知道$p$}！然而，当父亲宣布$p$之后，$a$，$b$，$c$都\emph{知道了所有人知道所有人知道$p$}.
\end{itemize}

用$E^m p$表示所有人知道所有人知道……所有人知道（$m$次）$p$. 在一般情况下，父亲没有宣布$p$之前，$E^k p$并不成立. 父亲宣布了$p$之后，对任意$m\geq 1$，$E^m p$都成立！因此，父亲宣布$p$带来了\emph{共同知识}. 有了共同知识，这一谜题就可以按照我们所讨论的方式进行下去.

我们曾经假设过所有人“观察力敏锐、聪慧且诚实”. 然而，这一假设并不足够. 上面的论证其实暗含了，所有人都知道所有人“观察力敏锐、聪慧且诚实”，所有人都知道所有人都知道所有人“观察力敏锐、聪慧且诚实”，……换言之，我们需要假设“所有人观察力敏锐、聪慧且诚实”是共同知识. 

如果没有这样的假设，上面的论证都将不成立。例如，还是只有两个孩子$a,b$脸上有泥巴. 假如$a$不知道$b$是诚实的，即便$b$回答了“不知道”，$a$也无法从$b$的回答中得到任何额外的知识！

除了假设“所有人观察力敏锐、聪慧且诚实”是共同知识，我们还需要假设以下陈述是共同知识：
    \begin{itemize}
        \item 每个人都能看到所有除自己外的人.
        \item 每个人都听到了父亲说的话.
        \item 父亲是诚实的.
        \item 每个人都在每一轮进行了充分的推理.
        \item ……
    \end{itemize}
任何假设的破坏都会导致之前的讨论失效. 那么，为什么父亲宣布$p$就可以让$p$变成共同知识呢？

所有人都\emph{听到}父亲说$p$并不能产生共同知识. 假如父亲只是对每一个孩子单独宣布$p$. 所有人并不知道所有人都知道$p$，因而仅仅可以做到$E p$，没有共同知识。

那么，所有人都\emph{知道}所有人听到父亲说$p$会如何呢？进一步假设每个孩子给每一个孩子都安装了窃听器，每个人都能够偷听每个人与父亲的谈话内容. 所有人并不知道所有人都知道所有人都知道$p$，因而仅仅有$E^2 p$. 

所以关键在于，父亲宣布$p$的过程是\emph{公开的}，每个人都可以仔细观察别人有没有听到父亲说$p$，也可以观察到别人有没有观察到别人有没有听到父亲说$p$，等等. 此时对每一个$m$都有$E^m p$.

“泥泞的孩童”谜题足以表明，关于“知道”的讨论远比想象的复杂. 关于“知道”和知识的研究在哲学中划归为\emph{知识论}. 我们将介绍处理知识的两种数学模型：
\begin{itemize}
    \item 一种源自Aumann，Harsanyi和Rubinstein等人，以Bayes概率论为基础，是偏经济学的学术风格；
    \item 另一种源自Kripke，Hintikka和Halpern等人，以模态逻辑为基础，是偏计算机科学和哲学的学术风格。
\end{itemize}
在这一章，我们主要讨论Bayes概率论的方法.

\section{不完全信息博弈（Bayes博弈）}

接下来，我们介绍讨论“知识”的博弈论语言。我们先从正则形式博弈和Nash均衡开始说起。正则形式博弈隐含了一个重要的假设：所有玩家对整个世界有一致、完全的共同知识. Nash均衡建立在这一假设之上：每个玩家可以在博弈结束后，根据其他玩家的策略，确定自己的最优反应. 

然而，现实世界中，玩家对世界的认识是有限的，不能获得完全的信息. 比如，我们可能不知道对手的收益函数，然而这在现实中极其普遍. 

另一个问题是，Nash均衡只有假设\emph{混合策略}的情况下才能保证存在. 我们在现实中并不真的在选择混合策略：所有的交易其实都是“一锤子买卖”，绝对不可能有人说“我今天以0.5的概率花一块钱买你的苹果，0.5的概率花5块钱买你的苹果”. 英语也有一句谚语：
\begin{quotation}
“Decision makers do not flip coins in the real world.”
\end{quotation}

相比之下，纯策略Nash均衡更加符合实际。然而，即便是纯策略Nash均衡也可能是不合理的状态. 考虑如下的二人博弈：
\[\begin{pmatrix}
1,1&0,0\\
0,0&0,0
\end{pmatrix}.\]
显然，两个人玩家都选择第二策略就达到了纯策略Nash均衡.

然而，当行玩家对列玩家的选择有任意小的不确定性时，他都更倾向于选择第一个策略. 因此，我们给出的这个纯策略Nash均衡实际上描述了一种不太可能出现的状态.

因此，一种Nash均衡的修正概念被提出：\emph{颤抖的手完美化}，它指的是，$s$是一个纯策略Nash均衡，并且当对手玩家的策略有任何微小不确定性的时候，$s$中的策略依然是最优反应.

“颤抖的手”给了我们一个例子，说明对对手的不确定性会影响玩家的决策. 因此，进一步的问题是，如何量化对对手的不确定性？Harsanyi给出了一个现在已经是“标准答案”的解决方案：引入玩家的“类型”（可能世界）以及其他玩家的对此的先验的\emph{信念}. 他的采用了Bayes解释的概率论，信念在数学上被建模为对可能世界的概率分布.

我们先给出不完全信息博弈的定义：

\begin{definition}[不完全信息博弈，Bayes博弈]
    一个\textbf{不完全信息博弈}（\textbf{Bayes博弈}）包含了以下组成部分：
\begin{itemize}
    \item 玩家集合：$I$.
    \item 行动空间：$A=(A_i)_{i\in I}$，$A_i$表示玩家$A_i$的所有可能行动.
    \item 类型空间：$\Theta=(\Theta_i)_{i\in I}$，$\Theta_i$表示玩家$i$的所有可能类型.
    \item 收益函数：$u_i:A\times\Theta\to\R$，当所有人的行动和类型都确定的时候，玩家$i$能拿到的收益.
\end{itemize}
所有玩家的行动$a=(a_i)_{i\in I}$形成了一个\textbf{行动组合}，所有玩家的类型$\theta=(\theta_i)_{i\in I}$形成了一个\textbf{类型组合}.
\end{definition}

$P_i\in\Delta(\Theta_i)$是玩家$i$类型的概率分布. 比较不直观的一点是，$P_i$表示了\emph{其他玩家}对玩家$i$类型的信念. 因此，Bayes博弈其实做了简化：
\begin{itemize}
    \item 不论哪个玩家，对特定玩家$i$的信念是一致的.
    \item 所有$P_i$是相互独立的，因此玩家的类型之间不会有相互的关联。
\end{itemize}
因此，玩家$i$在博弈中的\emph{全部}不确定性都来自其他玩家的类型，他对此的信念是
\[P_{-i}=\prod_{j\neq i}P_j.\]

最后，我们假设玩家$i$知道自己的类型.

更进一步，在一般情况下，玩家$i$对这个世界的信念应该包含：
\begin{itemize}
    \item 博弈中其他玩家都有谁，
    \item 自己的可能行动，
    \item 自己的类型，
    \item 自己的收益函数,
    \item ……
\end{itemize}
在一个真实的博弈中，以上信息都会是不确定的：对手可以藏在暗处，我们会不知道自己本来拥有的选择，我们可以不了解自己的性格，我们甚至也不知道自己究竟在追求什么。尽管有很多的不确定性最终都可以归结为“类型”（见后面正文的若干例子和习题\lhysays{出一下}），Bayes博弈依然是一个高度理想化的模型. 

然而，Bayes博弈的成功，正如Robert Aumann所说，不在于多么贴合实践，而是给了一种系统的方法，让我们可以建模不确定性和信念，从而理解这些概念在博弈中的作用：
\begin{quotation}
    “一个典型的例子是 Roth 和 Murnighan（1982）在完全信息和不完全信息讨价还价方面的实验工作\footnote{也就是本章开头讲的故事。}……他们将这些结果与早期 Fouraker 和 Siegel（1960）的实验进行了比较。

    “Fouraker 和 Siegel 进行了类似的实验，但由于缺乏 Harsanyi 的模型，只能将不完全信息的情况描述为双方都没有被告知对方的收益。
    
    “然而，Roth 和 Murnighan 则从类型的角度详细阐述了不完全信息，并明确考虑了博弈的共同知识方面。”
\end{quotation}

接下来，我们看一个Bayes博弈的例子。

\begin{example}[“工作还是偷懒”博弈]
    在这个博弈中，有两个玩家，他们共同完成一个项目。两个玩家的行动都是“工作”（$W$）或“偷懒”（$S$）. 行玩家的类型集合是单点集，列玩家的类型是“勤奋”（$D$）或“懒惰”（$L$）.收益矩阵为
    \[\begin{array}{c|cc}
        \multicolumn{3}{l}{\theta_2=D,}\\
         &W&S  \\\hline
         W&3,3&-1,0\\
         S&2,1&0,0\\
    \end{array}\qquad \begin{array}{c|cc}
        \multicolumn{3}{l}{\theta_2=L,}\\
         &W&S  \\\hline
         W&1,1&-1,2\\
         S&2,-1&0,0\\
    \end{array}\]
    换言之，我们其实不确定的只有玩家$2$是喜欢偷懒还是努力工作，但他具体是什么人又会影响双方的收益，从而影响双方的决策。
\end{example}

至此，我们已经建立了博弈的语言，下一任务就是定义一个玩家的\emph{策略}。和\Cref{chap:game}的博弈极为不同，Bayes博弈中的玩家要面对不确定性。这给我们定义策略带来了一定的困难。为此，我们先要讨论清楚，究竟什么是“不确定性”。

设想如下的情景：你选了一门课，期末要考试。于是，你认真学习，并且把往年题c都找出来，认真做完，老师也划定了考纲和难度：你对这个考试胸有成竹。真正上场考试的时候，你的心理有一个对难度和考点的预期，因此，你在考试时候面对的是具有明确\emph{风险}的不确定性。

然而，当你考的不是期末考，而是英语四级考试的时候，你可能就会变得非常随性：挂了还可以重新考，所以考前根本没有学习，甚至连题型都不知道有什么。这个时候，你甚至连四级总分是多少都不知道，所以，你甚至连考试结果的预期都没有。这个时候，你面对的是\emph{模糊}的不确定性。

还有一种情景，你现在不是考四级，而是考GRE，这是上机考试。GRE的每道题的难度都不一样，题目是随机出现的，难度分布极其不均匀，并且他会根据你答题情况来自动调整题目的难度。此时，你面对的是\emph{不稳定}的不确定性。

上面讲到了三种不确定性。那么，Bayes博弈是他们中的是哪一种呢？显然，在Bayes博弈中，玩家依然只能做一次行动，所以不是不稳定的不确定性。此外，Bayes博弈中，所有玩家的类型集是固定的，甚至连类型的似然也是确定的，因此，这是具有明确风险的不确定性。

接下来，我们可以定义玩家的策略和理性了。注意，玩家知道自己的类型，但不知道其他人的类型，所以，玩家只能根据自己的类型来决定自己的行为。因此，我们应该定义玩家的策略如下：

\begin{definition}[策略]
    玩家$i$的\textbf{策略}是一个映射
    \[s_i:\Theta_i\to A_i,\]
    其中$\Theta_i$是玩家$i$的类型集合，$A_i$是玩家$i$的行动集合. $s_i(\theta_i)$表示玩家$i$在类型$\theta_i$下的行动.
\end{definition}

\begin{remark}
    自然，我们也可以定义\emph{混合策略}，此时，$s_i$是一个$\Theta_i$到$\Delta(A_i)$的映射. 不过，在Bayes博弈中，混合策略会让情况（不论概念上还是计算上）变得复杂，所以我们避免混合策略的讨论.
\end{remark}

当面对具有明确风险（似然）不确定性的时候，我们可以遵循von Neumann-Morgenstern的期望效用理论，定义玩家的理性。首先，我们定义玩家的\emph{事中期望收益}：

\begin{definition}[事中期望收益]
    玩家$i$在类型$\theta_i$下，采取策略$s_i$，对手的策略是$s_{-i}$时，$i$的\textbf{事中期望收益}为
    \[\tilde u_i(s_i,\theta_i,s_{-i})=\E_{\theta_{-i}\sim P_{-i}}[u_i(s_i(\theta_i),s_{-i}(\theta_{-i}),\theta_i,\theta_{-i})].\]
\end{definition}

于是，按照期望理论，玩家的\emph{事中理性}就是在知道对手的策略之后，会最大化自己的事中期望收益。

据此，我们就可以定义最优反应：

\begin{definition}[事中最优反应]
    考虑玩家$i$的策略$s_i$，对手的策略是$s_{-i}$，如果对任意的其他策略$s'_i$和任意类型$\theta_i$，都有t
    \[\tilde u_i(s_i,\theta_i,s_{-i})\geq \tilde u_i(s'_i,\theta_i,s_{-i}),\]
    那么$s_i$是玩家$i$的\textbf{事中最优反应}.
\end{definition}

用最优反应，我们可以很容易定义Bayes Nash均衡：

\begin{definition}[Bayes Nash均衡，BNE]
    考虑策略组合$s=(s_i)_{i\in I}$，如果对任意$i,\theta_i,a_i$都有
    \[\tilde u_i(s(\theta_i),\theta_i,s_{-i})\geq \tilde u_i(a_i,\theta_i,s_{-i}),\]
    那么$s$是一个\textbf{Bayes Nash均衡}（\textbf{BNE}）.
\end{definition}

接下里，我们来看一个BNE的例子。

\begin{example}[猜硬币游戏]
    考虑经典的猜硬币游戏（见\Cref{ex:matching-pennies}），这是一个正则形式博弈，收益矩阵为
    \[
    \begin{array}{c|cc}
         &H&T  \\\hline
         H&1,-1 &-1,1\\
         T&-1,1&1,-1\\
    \end{array}
    \]
    如果两个人都出$H$的时候收益有独立微小的扰动，我们就得到了一个Bayes博弈：
    \[
    \begin{array}{c|cc}
         &H&T  \\\hline
         H&1+\epsilon\theta_1,-1+\epsilon\theta_2 &-1,1\\
         T&-1,1&1,-1\\
    \end{array}
    \]
    其中$\theta_i\sim\mathcal U[-1,1]$且相互独立，这就是玩家$i$的类型。

    那么，这个博弈的BNE会是什么呢？我们可以猜一个。考虑策略：$s_i:[-1,1]\to\{H,T\}$满足
    
    \[s_i(\theta_i)=\begin{cases}
    H,&\theta_i\in[0,1],\\
    T,&\theta_i\in[-1,0).
    \end{cases}\]
    我们来验证，这的确是一个BNE.

    固定列玩家的策略$s_2$，我们来计算行玩家的最优反应。对于行玩家来说，不论他的类型是什么，他面对的是一个$50\%$的概率选择$H$和$T$的对手，因此，如果选择$H$，行玩家的期望收益是
    \[\frac{1}{2}\cdot (1+\epsilon\theta_1)+\frac{1}{2}\cdot(-1)=\frac{\epsilon\theta_1}{2}. \]
    如果选择$T$，行玩家的期望收益是
    \[\frac{1}{2}\cdot(-1)+\frac{1}{2}\cdot(1)=0. \]
    因此，如果$\theta_1>0$，行玩家应该选择$H$，如果$\theta_1<0$，行玩家应该选择$T$，这是一个最优反应，恰好是我们猜测的策略.

    对于列玩家的最优反应，我们可以做类似的计算，也可以得到，$s_2$是列玩家的最优反应. 因此，$(s_1,s_2)$是一个BNE.
\end{example}

以上例子有极其特殊的含义：策略$(s_1,s_2)$导致的结果实际上是，每个玩家计算最优反应的时候，面对的对手其实仿佛是一个混合策略玩家，他以等概率选择$H$和$T$. 注意，当$\epsilon\to 0$，这个博弈收益矩阵回到了原始博弈. 因此，Bayes博弈里行动概率分布其实可以被视作原始博弈的混合策略.

猜硬币游戏的例子其实说明，正则形式博弈的混合策略Nash均衡被理解为：当不确定性趋于消失时候，BNE形成的行动概率分布. 这不是偶然的，实际上，所有的正则形式博弈的混合策略均衡都可以用一系列Bayes博弈的BNE\emph{纯化}.

下面我们把猜硬币游戏的过程一般化。考虑一个正则形式博弈$(I,A,u)$，其中$I$是玩家集合，$A$是行动空间，$u$是收益函数. 我们可以定义一个Bayes博弈，被称为\emph{扰动博弈}：
\begin{itemize}
\item 给定一个扰动参数$\epsilon>0$，定义类型组合为$\theta=(\theta_i)_{i\in I}$，$\theta_i\in[-1,1]$，然后，将收益扰动为：
    \[u_i'(s,\theta)=u_i(s)+\epsilon\theta_i.\]
    \item 假设$\theta_i\sim F_i$，相互独立，$F_i$是具有连续可微密度的分布.
\end{itemize}

定义一个从Bayes博弈策略到正则形式博弈混合策略的映射$\phi$，给定一个Bayes博弈的策略组合$s$，$\phi(s)$是一个混合策略，满足
\[\phi(s)_i(a_i)=\Pr_{\theta_i\sim F_i}[s_i(\theta_i)=a_i].\]
换言之，在原本的Bayes博弈中，概率定义在了玩家的类型上，这个映射的作用是将这个概率转化为了玩家的行动上.

接下来，我们可以正式给出纯化定理的表述：

\begin{theorem}[Harsanyi纯化定理]
给定玩家集$I$和行动空间$A$. 对于一般的收益函数$u$和连续分布族$\{F_i\}_{i\in I}$，对任意完全信息正则形式博弈$(I,A,u)$的混合策略Nash均衡$\sigma$，存在一列扰动博弈纯策略BNE $s_\epsilon$，当扰动参数$\epsilon\to 0$，$\phi(s_\epsilon)\to \sigma$.
\end{theorem}
这一定理的证明比较长，并且需要用到较为复杂的数学技巧。由于证明本身与本章的讨论无关，所以这里略去.

这一定理给了Nash均衡（也即混合策略）一种新的解释：混合策略定义的Nash均衡可以被看作不确定性趋于消失的时候的（纯策略）BNE。

尽管我们说，“Decision makers do not flip coins in the real world.”然而，如果玩家对自己的收益有微小的不确定性，他的行为就会仿佛在抛硬币. 这就是混合策略的\emph{似然解释}.

注意，在Bayes博弈中，玩家对自己的类型是确定的，所以玩家在决策时不应该对自己的收益有微小的不确定，因而上面这一解释并不完全正确。然而，我们可以重新定义理性的概念，它会产生等价的BNE定义，但是玩家此时要面对自己类型的不确定性。

为了说明这一理性的概念，我们先看一个例子。假如你是一个顶尖斗地主玩家，知道自己拿到身份、拿到手牌之后要如何行动，这是你一贯的策略。当然，在游戏开始前，你其实并不知道自己的身份和手牌，这是你对自己的不确定性。不过，这并不影响你评估自己的胜率：你只需要知道其他玩家的水平，你就可以大概估计一个总体的胜率。

上面的例子里，玩家其实在博弈开始前就已经选好了一个类型到行动的策略，但是他要面临自己类型的不确定性。此时，我们计算的胜率其实是\emph{事前}期望收益：

\begin{definition}[事前期望收益]
    给定玩家集$I$、行动空间$A$和类型上的联合分布$P$，如果玩家$i$的策略是$s_i$，对手的策略是$s_{-i}$，那么$i$的\textbf{事前期望收益}为
\[\hat u_i(s_i,s_{-i})=\E_{\theta\sim P}[u_i(s_i(\theta_i),s_{-i}(\theta_{-i}),\theta_i,\theta_{-i})].\]
\end{definition}

在Bayes博弈中，\emph{事前理性}指的就是，玩家在不知道自己的类型的情况下，最大化自己的事前期望收益. 根据事前期望收益，我们可以定义事前最优反应：

\begin{definition}[事前最优反应]
    考虑玩家$i$的策略$s_i$，对手的策略是$s_{-i}$，如果对任意的其他策略$s'_i$和任意类型$\theta_i$，都有
    \[\hat u_i(s_i,s_{-i})\geq \hat u_i(s'_i,s_{-i}),\]
    那么$s_i$是玩家$i$的\textbf{事前最优反应}.
\end{definition}

注意，事前理性和事中理性考虑的都是同样的策略，但是玩家面对的不确定性是不同的。然而，事前理性和事中理性其实是等价的：

\begin{theorem}
    给定玩家集$I，$行动空间$A$，类型空间$\Theta$、收益函数$u$和类型空间的联合分布$P$，考虑策略组合$s=(s_i)_{i\in I}$，对任意玩家$i$，$s_i$是$s_{-i}$的事前最优反应当且仅当$s_i$是$s_{-i}$的事中最优反应.
\end{theorem}
这一定理的证明类似正则形式博弈的无差别原理（\Cref{thm:indifference-principle}）的证明，见习题\lhysays{出一下}.

这一定理其实有一些反直觉：在Bayes博弈中，如果玩家面对的仅仅只是具有确定风险的不确定性，那么他是否不确定自己的类型并不会影响他的理性决策. 这其实是因为，玩家面对的仅仅是\emph{具有确定风险的不确定性}，而不是更加复杂的不确定性，因此，无论博弈如何进行，他在开始前就已经可以确定自己的最优策略.

这一定理的直接推论是，我们可以根据事前最优反应来定义BNE：
     \[\hat u_i(s_i,s_{-i})\geq u_i(s'_i,s_{-i})\]
对任意$i$和任意策略$s_i'$成立.

当所有的不确定性都消失的时候，我们得到的收益是真实的，被称为\emph{事后收益}，此时不再有任何的概率，因此博弈退化为了正则形式博弈. 事前、事中、事后分别表明了信息的确定（披露）程度。

\section{电子邮件博弈}\label{sec:emailing-game}

作为一个例子，接下来我们使用Bayes博弈来研究知识的性质。这个例子由Ariel Rubinstein给出，它说明在二人正则形式博弈中，共同知识对到底实现哪一个Nash均衡非常关键.

考虑两个玩家和两个可能的收益矩阵：
\begin{table}[ht]
    \centering
\begin{tabular}{c|cc}
&$A$ & $B$ \\
\hline
$A$ & $(0, 0)$ & $(-10, 1)$ \\
$B$ & $(1, -10)$ & $(8, 8)$ \\
\end{tabular}
\qquad
\begin{tabular}{c|cc}
&$A$ & $B$ \\
\hline
$A$ & $(8, 8)$ & $(-10, 1)$ \\
$B$ & $(1, -10)$ & $(0, 0)$ \\
\end{tabular}
\end{table}

在左边的矩阵中，$(B,B)$是唯一的Nash均衡. 在右边的矩阵中有多个Nash均衡：$(A,A)$和$(B,B)$. $(A,A)$给出比$(B,B)$更高的收益，但行动$A$比$B$更有风险.

左边矩阵是真实矩阵概率是$p>1/2$. 玩家$1$知道真实的矩阵，而玩家$2$不知道. 如果选择了右边矩阵，玩家$1$会给玩家$2$发送一条消息. 如果玩家$2$收到了消息，他会回复. 如果玩家$1$收到了回复，他会发送第二条消息来确认他收到了玩家$2$的回复. 以此类推.  每条消息都以$\epsilon$的概率独立等可能丢失.\footnote{注意：发送电子邮件不是一个行动，而是一个规则.}  

以上传信的过程可以用Bayes博弈的类型来刻画. 具体来说，两个玩家的类型集合为$\Theta_i = \{\theta_i^0, \theta_i^1, \theta_i^2, \dots\}$. $\theta_i^m$表示玩家$i$发了$m$封邮件. $\theta_i^m$有直观的含义. 例如，类型$\theta_1^0$表示真实收益矩阵是左边的.  而类型$\theta_1^1$表示真实收益矩阵是右边的，$1$发送了一封电子邮件，但$2$没有收到. 

实际上，$\theta$包含了所有可能的情况：
\begin{itemize}
\item $(\theta_1^0, \theta_2^0)$：真实收益矩阵是左边的. 
\item $(\theta_1^1, \theta_2^0)$：真实收益矩阵是右边的，$1$发送了一封电子邮件，但$2$没有收到. 
\item $(\theta_1^1, \theta_2^1)$：真实收益矩阵是右边的，$2$收到了第一封电子邮件，但$1$没有收到$2$的回复. 
\item ……
\end{itemize}

我们可以算出来，当真实矩阵为左边矩阵时，每个类型出现的概率. 首先，以概率$p$选择左边的矩阵，而且没有人发送消息. 因此，$(\theta_1^0,\theta_2^0)$的概率是$p$，其他项概率都是$0$. 我们得到如下的概率表：
\[\begin{array}{c|cccc}
\text{左}& \theta_2^0 & \theta_2^1 & \theta_2^2 & \cdots \\
\hline
\theta_1^0 & p & 0 & 0 & \cdots \\
\theta_1^1 & 0 & 0 & 0 & \cdots \\
\theta_1^2 & 0 & 0 & 0 & \cdots \\
\vdots & \vdots & \vdots & \vdots & \ddots
\end{array}
\]

同样可以算出来，当真实矩阵为右边矩阵时，每个类型出现的概率. 首先，以概率$1 - p$选择右边的矩阵，玩家$1$发送一条消息，它会以概率$\epsilon$丢失. 因此，$(\theta_1^1,\theta_2^0)$的概率是$\epsilon(1 - p)$. 以此类推，可以得到计算. 我们得到如下的概率表：
\[
\begin{array}{c|cccc}
\text{右} & \theta_2^0 & \theta_2^1 & \theta_2^2 & \cdots \\
\hline
\theta_1^0 & 0 & 0 & 0 & \cdots \\
\theta_1^1 & \epsilon(1 - p) & \epsilon(1 - \epsilon)(1 - p) & 0 & \cdots \\
\theta_1^2 & 0 & \epsilon(1 - \epsilon)^2(1 - p) & \epsilon(1 - \epsilon)^3(1 - p) & \cdots \\
\theta_1^3 & 0 & 0 & \epsilon(1 - \epsilon)^4(1 - p) & \cdots \\
\vdots & \vdots & \vdots & \vdots & \ddots
\end{array}
\]


容易看出来，当真实类型为$\theta_i^m$时，收益矩阵是到第$m$层的共同知识，即$E^m$. 所以对于很大的$m$，收益矩阵是“几乎公共知识”. 所以，这个模型在研究的问题是：如果收益矩阵是”几乎共同知识“，那么Nash均衡是什么？为此，我们需要求出来这个Bayes博弈的BNE.

我们需要弄清楚对每个类型$\theta_i^m$，玩家会做什么. 假设玩家$1$的类型为$\theta_1^0$. 玩家$1$知道$(\theta_1^0,\theta_2^0)$是真实的类型，所以左边的矩阵被选择. 据此推理：玩家$1$选择占优策略$B$.

假设玩家$2$的类型为$\theta_2^0$. 我们对玩家$1$的所有可能类型分类讨论：
\begin{itemize}
    \item 如果玩家$1$的类型为$\theta_1^0$，那么左边的矩阵被选择，对于玩家$2$来说，这种情况的概率为
    \[\Pr(\theta_1^0|\theta_2^0) = \frac{p}{p+\epsilon(1-p)} := \mu_2^0.\] 
    \item 如果玩家$1$的类型为$\theta_1^1$，那么右边的矩阵被选择，对于玩家$2$来说，这种情况的概率为
    \[\Pr(\theta_1^1|\theta_2^0) = 1 - \mu_2^0.\]
\end{itemize}

现在我们来分析玩家$2$的两种选择：$A$和$B$.
\begin{itemize}
    \item 选择$B$的期望收益至少是$8\mu_2^0$. 推理如下：
    \begin{itemize}
        \item 玩家$1$的类型是$\theta_1^0$时，这是左边的矩阵，玩家$1$肯定选择$B$，此时玩家$2$选择$B$的收益是$8$.
        \item 玩家$1$的类型是$\theta_1^1$时，这是右边的矩阵，无论玩家$1$怎么选，此时玩家$2$选择$B$的收益至少是$0$.
    \end{itemize}
    因此，按照全概率公式计算，$B$的期望收益至少是$8\mu_2^0$.
    \item 选择$A$的期望收益至多是$-10\mu_2^0 + 8(1 - \mu_2^0)$. 推理如下：
    \begin{itemize}
        \item 玩家$1$的类型是$\theta_1^0$时，这是左边的矩阵，玩家$1$肯定选择$B$，此时玩家$2$选择$A$的收益是$-10$.
        \item 玩家$1$的类型是$\theta_1^1$时，这是右边的矩阵，无论玩家$1$怎么选，此时玩家$2$选择$A$的收益至多是$8$.
    \end{itemize}
    因此，按照全概率公式计算，$A$的期望收益至多是$-10\mu_2^0 + 8(1 - \mu_2^0)$.
\end{itemize}

注意，
\begin{align*}
    &8\mu_2^0-(-10\mu_2^0 + 8(1 - \mu_2^0))\\
    =& 10\mu_2^0 - 8\\
    =& \frac{10p-8(p+\epsilon(1-p))}{p+\epsilon(1-p)}\\
    =& \frac{(2+\epsilon)p-8\epsilon}{p+\epsilon(1-p)}\\
    >& \frac{1-8\epsilon}{p+\epsilon(1-p)}.
\end{align*}
对充分小的$\epsilon>0$，这个值是正的. 因此，$B$更好.

假设玩家$1$的类型为$\theta_1^1$，于是，右边的矩阵被选择. 同样，对玩家$2$的类型分类：
\begin{itemize}
    \item 如果玩家$2$的类型为$\theta_2^0$，对于玩家$1$来说，这种情况的概率为
    \[\Pr(\theta_2^0|\theta_1^1) = \frac{\epsilon(1-p)}{\epsilon(1-p)+\epsilon(1-\epsilon)(1-p)} := \mu_2^1.\]
    \item 如果玩家$2$的类型为$\theta_2^1$，对于玩家$1$来说，这种情况的概率为
    \[\Pr(\theta_2^1|\theta_1^1) = 1 - \mu_2^1.\]
\end{itemize}
同样可以计算玩家$1$的两种选择的期望收益：
\begin{itemize}
    \item 选择$B$的期望收益至少为$0$. 推理如下：玩家$2$是类型$\theta_2^0$时肯定选择$B$（上面已经证明），因此最坏的情况是玩家一类型为$\theta_2^1$. 
    \item 选择$A$的期望收益至多为$-10\mu_2^1 + 8(1 - \mu_2^1)$. 推理如下：玩家$2$是类型$\theta_2^0$时肯定选择$B$（上面已经证明），因此最好的情况是玩家一类型为$\theta_1^2$.
\end{itemize}

综合两方面，$B$更好，因为对于所有$\epsilon$，$\mu_1^1 > 1/2$. 

逐步迭代上述过程，我们发现，在唯一的BNE中，所有玩家在所有类型下都选择$B$. 

然而，如果右边的矩阵是共同知识，$(A,A)$也是一个真正的Nash均衡，然而，因为对于收益矩阵的不确定性，即便收益矩阵是“几乎共同知识”，这个均衡也不会被实现！这个例子说明了，共同知识对于均衡的实现是非常关键的. 我们在习题\lhysays{出一下}中会进一步讨论Nash均衡与共同知识的关系.

\section{Aumann知识算子}

在上一节中，我们给了一个非常具体的例子探讨共同知识和Nash均衡的关系. 上面的例子看起来太特定，那是不是说明，用Bayes博弈研究知识，就是得具体问题具体建模呢？这个问题的答案，是也不是。一方面，用具体的Bayes博弈去说明具体的道理往往简洁且富有内涵；另一方面，我们也可以用更加抽象的方式去研究知识. 这一节，我们将介绍Aumann的知识算子，它是一种抽象的方式去研究知识.

首先，我们需要\Cref{chap:plausible-reasoning}的观点：概率论（或者似然）理解世界的方式基于“事件”. 我们只能感知事件的发生与否，而不能具体知道是哪个样本点. 用事件的方式理解认知，得到的结构被称为\emph{Aumann结构}. 下面，我们具体介绍这一数学模型。

考虑全集$\Omega$，它的含义有多种多样，比如可以理解为样本空间（概率论视角）、状态空间（动态博弈视角）或者可能世界（信念的视角出发）的全体. 我们就具体考虑为，从一个罐子里抽球，$\Omega$是这次抽到球的颜色。

对于最后一种关于$\Omega$的理解，我们可以再多解释一些。当我们面对不确定性的时候，我们会有一些信念，比如“这个球是红色的”、“这个球是蓝色的”等等. 实际上，这些不同信念背后对应了一个不同的“世界”。比如，我们考试的时候，我们可能会幻想考试通过时的场景，也可能幻想考试不通过时的场景. 他们代表了这个现实世界在未来不同的走向，因而被称为\emph{可能世界}.

注意，上面的解释容易引起误会，实际上，可能世界完全可以不是未来的世界。例如，我们常常会做\emph{反事实因果}的推理，比如“如果我当时不天天吃油炸食品，那么我现在就不需要减肥了”. 这个“如果”引导我们进入了一个可能世界，这个可能世界甚至存在于过去，而不是未来.

我们不再过多讨论$\Omega$的具体含义，而是专注于罐子的例子。\emph{事件}$e\subseteq \Omega$是样本点的集合，它表示了某些性质的发生. 例如，$e$可能是“抽到了红球”，或者“抽到的不是白色”等等. 一次\emph{观测}会产生一个具体的颜色，这个颜色对应了$\Omega$中的一个元素$\omega$，事件$e$发生当且仅当$\omega\in e$.

接下来，我们进入博弈的部分。我们会有集合$I$的玩家，每个玩家$i$都有一个关于$\Omega$的\emph{知识}。例如，色觉正常的人会\emph{知道}红色和绿色是不同的，而红绿色盲的人可能不知道。因此，每个人会有不一样的知识。如何用数学语言来描述这种知识呢？

实际上，知道一件事$e$发生与否意味着这个玩家有能力\emph{区分}一个样本点$\omega$是否属于$e$. 所以，我们可以先定义玩家知道的“基础知识”，即他能够感知到的最基本（原子）事件. 数学上，我们给如下的定义：

\begin{definition}[信息集]
    对于每一个玩家$i$，他的\textbf{信息集}是$\Omega$的一个划分
    \[\mathcal P_i = \{\Omega_j\}_j.\]
    划分的含义是，$\Omega_j$满足
    \begin{itemize}
        \item $\Omega_j\neq \varnothing$，
        \item 对所有$j\neq k$，$\Omega_j\cap\Omega_k=\varnothing$，并且
        \item $\bigcup_j\Omega_j=\Omega$.
    \end{itemize}
    此外，$\mathcal P_i(\omega)$被定义为$\omega$所属于的那个信息集.
\end{definition}

对于玩家$i$来说，他无法区分$\Omega_j$中元素，这就是原子性的含义。换言之，如果他能区分，就说明这个$\Omega_j$还不够小，因为它还是包含了可区分的不同元素。

接下来，我们来定义知识中最基本的陈述，即“玩家$i$知道事件$e$”。我们还是用红绿色盲作为例子。显然，红绿色盲不知道事件$e$：“这个球是红色的”。这是因为，他的信息集中没有单独的红色，只有“红色或绿色”这一集合。

上面的例子说明，玩家$i$知道事件$e$，说明对于这一个特定的观测$\omega$，玩家$i$能够完全确定$e$发生了. 注意，此时玩家$i$能够观察到的最基本事件是$\mathcal P_i(\omega)$，因此，这说明
\[\mathcal P_i(\omega)\subseteq e.\]

我们可以把所有能够完全确定$e$发生的$\omega$收集起来，在这些$\omega$上，玩家$i$充分必要地知道$e$发生。因此，我们有如下的定义：

\begin{definition}[Aumann知识算子]
    对于每一个玩家$i$，我们定义\textbf{Aumann知识算子}$K_i:2^\Omega\to 2^\Omega$为
    \[K_i(e):=\{\omega\in\Omega:\mathcal P_i(\omega)\subseteq e\}.\]
    因此$K_i(e)$是一个事件，表示“个体$i$知道事件$e$”. 不引起混乱的时候我们也省略括号，写作$K_ie$.
\end{definition}

Aumann知识算子的想法很清晰，它把所有关于知识的讨论转化为关于事件的讨论. 在\Cref{chap:plausible-reasoning}似然的讨论中，我们建立了集合论和逻辑的对应关系.
    \[\begin{array}{c|c}
        \text{事件}&\text{命题}  \\\hline
        \Omega & \T\\
        \varnothing & \F\\
        \sim A & \neg A\\
        A\cap B& A\wedge B\\
        A\cup B& A\vee B\\
        A\subseteq B& A\to B\\
        A=B&A\leftrightarrow B
    \end{array}\]
这里，我们依然可以用一样的对应关系，来实现复杂的表达. 例如，我们可以用$K_i(e\cap f)$来表示“个体$i$知道事件$e$和事件$f$同时发生”.

更进一步，我们可以将多个玩家的知识结合起来，定义共同知识算子：

\begin{definition}[共同知识算子]
定义“所有人都知道”算子$E:2^\Omega\to 2^\Omega$为
\[E(e)=\bigcap_{i=1}^n K_i(e).\]
然后，我们可以定义\textbf{共同知识算子}$C:2^\Omega\to 2^\Omega$为
\[C(e)=\bigcap_{k=1}^\infty E^k(e).\]
\end{definition}

接下来，我们讨论知识的一些基本性质。这里，我们只讨论知识本身的性质，而不关心不同玩家之间知识的交互，因此，我们都把$K_i$写作$K$.

\begin{proposition}[意识公理]
    \begin{equation}
        K(\Omega)=\Omega.\tag{K0}\label{eq:K0-awareness}
    \end{equation}
\end{proposition}
\begin{proof}
    显然成立。
\end{proof}

意识公理意味着，每个人知道他在某一个状态（可能世界）中. 尽管是一个显然的公理，我们依然可以考虑“意识不到自己处于某个状态”的情况，见习题\lhysays{出一下}.

\begin{proposition}
    \begin{equation}
        K(e\cap f)=K(e)\cap K(f).\tag{K1}\label{eq:K1-intersection}
    \end{equation}
\end{proposition}
\begin{proof}
    我们证明两边相互包含。
    \begin{itemize}
        \item $\subseteq$：设$\omega\in K(e\cap f)$，则
        \[\mathcal P(\omega)\subseteq e\cap f.\]
        因此，同时成立
        \[\mathcal P(\omega)\subseteq e,\quad \mathcal P(\omega)\subseteq f.\]
        因此，根据知识算子的定义，
        \[\omega\in K(e),\quad \omega\in K(f).\]
        因此，
        \[\omega\in K(e)\cap K(f).\]
        \item $\supseteq$：将上面的证明倒着写一遍即可。
    \end{itemize}
\end{proof}

这条性质意味着，一个人知道事件$e$和事件$f$，当且仅当他知道事件$e\cap f$. 考虑$e\cap f=f$的特殊情况，我们可以得到
\[e\subseteq f\implies K(e)\subseteq K(f).\]
换言之，如果客观事实上$e$可以推出$f$（即$e\subseteq f$），那么个体知道$e$就可以推出他知道$f$. 这条性质意味着玩家是\emph{逻辑全知}的，他可以对知识做任意复杂的逻辑推理. 特别地，他甚至可以做关于知识的逻辑推理！接下来，我们很快就会看到这会带来多么复杂的情况。

\begin{proposition}[知识公理，真理公理]
    \begin{equation}
        K(e)\subseteq e.\tag{K2}\label{eq:K2-knowledge}
    \end{equation}
\end{proposition}
知识公理意味着，知道的一定是真的. 在知识论中，这一要求实际上反映了“拥有知识”需要付出努力、值得一定的奖励. 与此相对应地，\emph{信念}则是更加主观、随意的，因而并不具有真理性。我们可以通过下面两句话来体会这两者的区别：
    \begin{itemize}
        \item 我考试挂了，但不知道我考试挂了.
        \item 我考试挂了，但我不相信我考试挂了.
    \end{itemize}

\begin{proposition}[正内省公理]
    \begin{equation}
        K(e)\subseteq K(K(e)).\tag{K3}\label{eq:K3-positive-introspection}
    \end{equation}
\end{proposition}

\begin{proposition}[负内省公理]
    \begin{equation}
        \sim K(e)\subseteq K(\sim K(e)).\tag{K4}\label{eq:K4-negative-introspection}
    \end{equation}
\end{proposition}

这两条内省公理意味着，个体会通过内省来知道自己的处境，特别是“我知道什么”和“我不知道什么”，通过内省，个体可以产生更高层级的知识：“我知道自己知道什么”或者“我知道自己不知道什么”. 

值得注意的是，内省这样的能力是灵长类动物区别于其他动物的重要特征. 例如，实验人员给黑猩猩若干工具，只有其中一种工具可以解决问题. 黑猩猩在没有任何提示的情况下，第一次就能够选出正确的工具. 科学家认为，这表明黑猩猩有能力内省，即知道自己知道什么（特别是物理世界的因果关系），并且利用这些知识来解决问题. 然而，诸如松鼠这样的哺乳动物，就没有这样的能力.

相比正内省公理，负内省公理可能会引起一些争议. 例如，在数学界有一个“著名”的猜想，叫\emph{几何Langlands猜想}。这个猜想是一个非常复杂的数学问题，最近，一个由 9 位数学家组成的团队成功证明了这个猜想. 这样专门的数学猜想，对于非数学爱好者来说，确实是不知道的。然而，如果负内省公理是成立的，那么他们就应该\emph{知道自己不知道}这个猜想. 这显然是不合理的. 更多讨论见习题\lhysays{出一下}.

上面的很多命题我们都会称呼为“公理”，这是因为他们反映了知识的基本性质，是我们对知识的直觉认识. 实际上，我们可以反过来，从这些公理出发，推导出Aumann知识算子的定义. 
于知识的逻辑推理！

\begin{theorem}\label{thm:Aumann-operator-iff}
考虑一个映射$K:2^\Omega\to 2^\Omega$，那么，以下两条等价：
\begin{itemize}
    \item $K$满足 \eqref{eq:K0-awareness}--\eqref{eq:K4-negative-introspection}.
    \item 存在一个信息集划分$\mathcal P$，使得$K$是由这个信息集划分定义的Aumann知识算子.
\end{itemize}
\end{theorem}

这一定理的证明类似于上面公理的证明，见习题\lhysays{出一下}.

诚然，Aumann知识算子的定义（在接受了之后）是非常直观且自然的。然而，\Cref{thm:Aumann-operator-iff} 告诉我们，这样定义的知识算子，必须要承认很多不是特别合理的性质，例如负内省公理或者逻辑全知。这似乎是一个两难的选择。

因此，回到本节开头的问题，用Bayes博弈研究知识，是不是得具体问题具体建模呢？Aumann知识算子给了一个很好的回答：如果过分一般，就会过分简化知识的概念，引入很多不合理的性质\footnote{实际上，直到今天，做知识论的哲学家普遍持有这样的观点：知识是一个无法被严格定义的哲学概念！因此，当知识被更进一步形式化成数学模型，我们更不能迷信它的普适性.}. 因此，既需要具体问题具体建模，也需要对知识的一般性质有所了解.

至此，在Aumann结构下，我们已经给\emph{知识}一个清晰的定义，作为本节的结束，我们给出Aumann结构中\emph{信念}的定义。同样，回忆\Cref{chap:plausible-reasoning}的思想，在基于事件的认知理论中，我们很容易通过概率（似然）来定义信念. 

玩家$i$可以对信息集$\mathcal P_i(\omega)$中的状态形成信念. 设$\rho_i$为集合$\Omega$上的概率分布，它代表$i$的\emph{先验}信念，即在没有任何额外信息的情况下他会持有的信念. 如果$\rho_i(\mathcal P_A(\omega)) > 0$，那么$i$在状态$\omega$处对世界状态的信念由以下概率分布给出
\[\rho_i(e|\omega)=\rho_i(e|\mathcal P_A(\omega)) = \frac{\rho_i(e\cap\mathcal P_A(\omega))}{\rho_i(\mathcal P_A(\omega))}.\]

接下来，我们对这一定义做几点说明。

首先，这一定义是良定义的，因为对于所有的$\omega'\in\mathcal P_A(\omega)$，$\rho_i(e|\omega')$都是一样的.

其次，直观上说，这一定义相当于\emph{后验}信念：每个人根据自己知道的信息做了Bayes更新.

最后，这个定义与Aumann知识算子是相容的. 事实上，我们可以定义“知道”是“具有必然的信念”：
\[K_i(e)=\{\omega\in\Omega:\rho_i(e|\omega) = 1\}.\]

\section{习题}

    {关于均衡的进一步思考}
\begin{itemize}
    \item 用$Nash(x)$表示“$x$是Nash均衡”，那么$\exists x C(Nash(x))$和$C(\exists x C(Nash(x)))$的含义是否一样？
    \item 如果不引入不确定性，在完全信息下，实现特定的Nash均衡是否还需要共同知识？
    \item 如果玩家不是逻辑全知的，或者说他的推理、计算能力是有限的，那么Nash均衡还是否会达到？是否可接近？
\end{itemize}

\begin{itemize}
    \item 如果我们写一个算子$U(e)$表示“个体意识不到事件$e$”，它应该有性质如下两个性质. 
    \item $\sim KU(e)=\Omega$：他不知道他不能意识到他不能意识到的事件.
    \item $U(e)\subseteq \sim K(\sim K(U(e)))$：如果他不能意识到事件$e$，那么他不知道他不知道他不能意识到事件$e$.
    \item 思考：这样的算子$U$存在吗？
\end{itemize}

\section{章末注记}